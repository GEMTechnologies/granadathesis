"""
Parallel Chapter Generator - Multi-Agent System

Generates academic thesis chapters with:
- Parallel research swarm (6 agents searching simultaneously)
- Parallel writing swarm (5 agents writing sections simultaneously)
- Quality control swarm (citation validation, coherence check)
- Real-time streaming to frontend
- 3+ APA 7 citations per paragraph with hyperlinks

Target: 30 pages in under 60 seconds
"""

import asyncio
import json
import uuid
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum

from services.academic_search import academic_search_service
from services.deepseek_direct import deepseek_direct_service
from services.sources_service import sources_service
from core.events import events
from services.chapter4_generator import generate_chapter4
from services.chapter5_generator import generate_chapter5
from services.chapter6_generator import generate_chapter6
from services.data_collection_worker import generate_study_tools, generate_research_dataset
from services.document_upload_service import search_user_documents
import re
import os
from services.thesis_session_db import ThesisSessionDB
from services.objective_generator import generate_smart_objectives, normalize_objectives
from services.uoj_chapter_one_generator import generate_chapter_one_uoj
from services.uoj_preliminary_generator import generate_preliminary_pages_uoj
from services.uoj_appendix_generator import generate_appendices_uoj


class AdaptiveLimiter:
    """Adaptive concurrency limiter with simple backoff/scale-up rules."""

    def __init__(self, max_concurrency: int, min_concurrency: int = 1):
        self._hard_max = max(1, max_concurrency)
        self._min = max(1, min_concurrency)
        self._max = self._hard_max
        self._in_flight = 0
        self._cond = asyncio.Condition()
        self._error_streak = 0
        self._success_streak = 0
        self._increase_after = 5
        self._decrease_after = 2

    async def acquire(self) -> None:
        async with self._cond:
            while self._in_flight >= self._max:
                await self._cond.wait()
            self._in_flight += 1

    async def release(self) -> None:
        async with self._cond:
            self._in_flight = max(0, self._in_flight - 1)
            self._cond.notify_all()

    def record_success(self) -> None:
        self._success_streak += 1
        self._error_streak = 0
        if self._success_streak >= self._increase_after and self._max < self._hard_max:
            self._max += 1
            self._success_streak = 0

    def record_failure(self) -> None:
        self._error_streak += 1
        self._success_streak = 0
        if self._error_streak >= self._decrease_after and self._max > self._min:
            self._max -= 1
            self._error_streak = 0

    async def __aenter__(self):
        await self.acquire()
        return self

    async def __aexit__(self, exc_type, exc, tb):
        await self.release()


def resolve_thesis_db(session_id: str, workspace_id: Optional[str] = None) -> ThesisSessionDB:
    """Prefer the DB that actually contains the session/workspace context."""
    db = ThesisSessionDB(session_id)
    if workspace_id and workspace_id != session_id:
        try:
            has_topic = bool(db.get_topic())
            has_objectives = bool(db.get_objectives().get("specific"))
        except Exception:
            has_topic = False
            has_objectives = False
        if not has_topic and not has_objectives:
            ws_db = ThesisSessionDB(workspace_id)
            try:
                ws_has_topic = bool(ws_db.get_topic())
                ws_has_objectives = bool(ws_db.get_objectives().get("specific"))
            except Exception:
                ws_has_topic = False
                ws_has_objectives = False
            if ws_has_topic or ws_has_objectives:
                return ws_db
    return db


def add_source_after_diagrams(content: str, section_title: str = "") -> str:
    """Add 'Source: Author's construct, 2024' after ASCII diagrams in code blocks."""
    # Find all code blocks and add source after them if not already present
    def replace_code_block(match):
        code_content = match.group(0)
        # Check if there's already a Source: right after
        if code_content.endswith('\n'):
            return code_content + "\n*Source: Author's construct based on reviewed literature, 2024*\n"
        return code_content + "\n\n*Source: Author's construct based on reviewed literature, 2024*\n"
    
    # Only add source if it looks like an ASCII diagram (has box chars)
    lines = content.split('\n')
    result_lines = []
    in_code_block = False
    code_block_content = []
    
    for line in lines:
        if line.strip().startswith('```'):
            if in_code_block:
                # End of code block
                code_block_content.append(line)
                block_text = '\n'.join(code_block_content)
                result_lines.append(block_text)
                # Check if block has diagram chars and no source already after
                if any(c in block_text for c in ['|', '+', '‚îÄ', '‚îÇ', '‚îå', '‚îî', '‚îê', '‚îò', '‚îÄ‚îÄ', '||', '--']):
                    # Add source only if not already present nearby
                    if 'Source:' not in block_text and len(result_lines) > 0:
                        result_lines.append("\n*Source: Author's construct based on reviewed literature, 2024*")
                code_block_content = []
                in_code_block = False
            else:
                # Start of code block
                in_code_block = True
                code_block_content = [line]
        elif in_code_block:
            code_block_content.append(line)
        else:
            result_lines.append(line)
    
    return '\n'.join(result_lines)


class AgentStatus(Enum):
    IDLE = "idle"
    WORKING = "working"
    COMPLETED = "completed"
    ERROR = "error"


@dataclass
class ResearchResult:
    """A single research paper with citation info."""
    title: str
    authors: List[str]
    year: int
    doi: str
    url: str
    abstract: str
    source: str  # global, continental, national, local
    venue: str = ""  # Journal or publication venue
    
    def _get_full_name(self, author) -> str:
        """Extract full author name from either string or dict format."""
        if isinstance(author, dict):
            name = author.get("name", author.get("family", ""))
            return name if name else ""
        return str(author) if author else ""
    
    def _get_last_name(self, author) -> str:
        """Extract LAST NAME ONLY for APA in-text citations."""
        full_name = self._get_full_name(author)
        if not full_name:
            return ""
        
        # Handle "Last, First" format
        if "," in full_name:
            return full_name.split(",")[0].strip()
        
        # Handle "First Last" format - get the last word
        parts = full_name.strip().split()
        if parts:
            # Return last part (surname)
            return parts[-1]
        return full_name
    
    def has_valid_author(self) -> bool:
        """Check if this paper has valid author information."""
        if not self.authors:
            return False
        first_author = self._get_last_name(self.authors[0])
        return bool(first_author and first_author.lower() not in ["unknown", "n/a", ""])
    
    def to_apa(self) -> str:
        """Format as APA 7th in-text citation (LAST NAMES ONLY)."""
        if not self.authors or not self.has_valid_author():
            return ""  # Return empty - skip papers without valid authors
        elif len(self.authors) == 1:
            author_str = self._get_last_name(self.authors[0])
        elif len(self.authors) == 2:
            author_str = f"{self._get_last_name(self.authors[0])} & {self._get_last_name(self.authors[1])}"
        else:
            author_str = f"{self._get_last_name(self.authors[0])} et al."
        
        if not author_str:
            return ""
        return f"{author_str} ({self.year})"
    
    def to_apa_full(self) -> str:
        """Full APA 7 reference for reference list (Last, F. format)."""
        if not self.authors or not self.has_valid_author():
            return ""  # Skip papers without valid authors
        
        # Format authors for reference list: Last, F. M.
        formatted_authors = []
        for author in self.authors[:7]:  # APA 7 shows up to 7 authors
            full_name = self._get_full_name(author)
            if not full_name:
                continue
            
            # Convert to "Last, F." format
            if "," in full_name:
                # Already in "Last, First" format
                parts = full_name.split(",", 1)
                last = parts[0].strip()
                first = parts[1].strip() if len(parts) > 1 else ""
                initials = ". ".join([n[0].upper() for n in first.split() if n]) + "." if first else ""
                formatted_authors.append(f"{last}, {initials}" if initials else last)
            else:
                # "First Last" format
                parts = full_name.strip().split()
                if len(parts) >= 2:
                    last = parts[-1]
                    initials = ". ".join([n[0].upper() for n in parts[:-1]]) + "."
                    formatted_authors.append(f"{last}, {initials}")
                else:
                    formatted_authors.append(parts[0] if parts else "")
        
        if not formatted_authors:
            return ""
        
        # Join authors properly for APA
        if len(formatted_authors) == 1:
            author_str = formatted_authors[0]
        elif len(formatted_authors) == 2:
            author_str = f"{formatted_authors[0]}, & {formatted_authors[1]}"
        else:
            author_str = ", ".join(formatted_authors[:-1]) + f", & {formatted_authors[-1]}"
        
        # Get URL or DOI
        if self.url and self.url.startswith("http"):
            url = self.url
        elif self.doi:
            url = f"https://doi.org/{self.doi}"
        else:
            url = ""
        
        # APA 7 format: Author (Year). Title. Journal. URL
        # URL is plain text (not markdown link) for clean DOCX output
        venue_str = f" *{self.venue}*." if self.venue else ""
        if url:
            return f"{author_str} ({self.year}). {self.title}.{venue_str} {url}"
from services.chapter_state import ChapterState, SectionContent, AgentStatus


# Available background writing styles
BACKGROUND_STYLES = {
    "inverted_pyramid": {
        "name": "Inverted Pyramid (Global -> Local)",
        "description": "Start broad (global), narrow down through continental, regional, national, to local context",
        "best_for": ["Social sciences", "Community-based studies", "Policy research"],
        "sections": ["Global Context", "Continental Context", "Regional Context", "National Context", "Local Context"]
    },
    "component_based": {
        "name": "Component-Based (Historical, Theoretical, Conceptual, Contextual)",
        "description": "Divide background into distinct academic components",
        "best_for": ["Theses/dissertations", "Studies with multiple variables", "Deep academic grounding"],
        "sections": ["Historical Background", "Theoretical Background", "Conceptual Background", "Contextual Background"]
    },
    "thematic": {
        "name": "Thematic (Organized by Themes)",
        "description": "Arrange by themes/issues rather than geography or time",
        "best_for": ["Qualitative research", "Literature-rich topics", "Multi-angle analysis"],
        "sections": ["Theme 1", "Theme 2", "Theme 3", "Theme 4", "Synthesis"]
    },
    "chronological": {
        "name": "Chronological (Past -> Present)",
        "description": "Tell the story of the issue over time",
        "best_for": ["Historical studies", "Policy development", "Technology adoption"],
        "sections": ["Origins", "Evolution", "Current State", "Emerging Gaps"]
    },
    "problem_driven": {
        "name": "Problem-Driven (Symptoms -> Root Cause)",
        "description": "Start with observations, move to underlying issues",
        "best_for": ["Action research", "Education studies", "Intervention research"],
        "sections": ["Observed Situation", "Symptoms/Challenges", "Causes/Factors", "Core Problem", "Need for Investigation"]
    },
    "funnel": {
        "name": "Funnel (Broad Topic -> Narrow Gap)",
        "description": "Focus on scholarly debates narrowing to research gap",
        "best_for": ["Research-intensive fields", "Literature-heavy topics", "Academic journals"],
        "sections": ["Broad Topic", "Existing Findings", "Debates/Contradictions", "Research Gap"]
    },
    "gap_oriented": {
        "name": "Gap-Oriented (What Known -> What Missing)",
        "description": "Quickly identify and justify the research gap",
        "best_for": ["Journal articles", "Fast-paced scientific writing", "Proposals"],
        "sections": ["What is Known", "What is Not Known", "Why Gap Matters", "How Study Fills Gap"]
    },
    "variable_based": {
        "name": "Variable-Based (IV -> DV -> Moderators)",
        "description": "Organized according to study variables",
        "best_for": ["Quantitative research", "Experimental studies", "Statistical analysis"],
        "sections": ["Independent Variables", "Dependent Variable", "Moderating/Mediating Variables", "Variable Interactions"]
    },
    "policy_context": {
        "name": "Policy-Context (Global -> National Policies)",
        "description": "Frame around existing policies, laws, frameworks",
        "best_for": ["Public administration", "Education policy", "Health policy"],
        "sections": ["Global Policies", "Regional Policies", "National Policies", "Policy Gaps"]
    },
    "multilevel_system": {
        "name": "Multi-Level System (Ecological Approach)",
        "description": "Use levels: individual, group, community, institution, society",
        "best_for": ["Environmental studies", "Social science", "Bronfenbrenner models"],
        "sections": ["Individual Level", "Interpersonal Level", "Community Level", "Societal Level"]
    }
}


class ResearchSwarm:
    """Parallel research agents that search for papers."""
    
    SEARCH_CONFIGS = [
        {"id": "global", "scope": "global systematic review meta-analysis", "quota": 8},
        {"id": "continental", "scope": "Africa", "quota": 5},
        {"id": "regional", "scope": "East Africa", "quota": 4},
        {"id": "national", "scope": "Uganda", "quota": 4},
        {"id": "local", "scope": "", "quota": 3},  # Will use case_study
        {"id": "statistics", "scope": "WHO UNESCO statistics report", "quota": 3},
    ]
    
    def __init__(self, state: ChapterState):
        self.state = state
        try:
            self._min_abstract_chars = int(os.getenv("ABSTRACT_MIN_CHARS", "80"))
        except ValueError:
            self._min_abstract_chars = 80
        try:
            self._min_relevance_score = float(os.getenv("ABSTRACT_RELEVANCE_MIN_SCORE", "0.08"))
        except ValueError:
            self._min_relevance_score = 0.08
        self._relevance_keywords: Optional[set] = None
        try:
            max_concurrency = int(os.getenv("LLM_MAX_CONCURRENCY", "4"))
        except ValueError:
            max_concurrency = 4
        existing_limiter = self.state.parameters.get("llm_limiter")
        if existing_limiter:
            self._llm_limiter = existing_limiter
        else:
            self._llm_limiter = AdaptiveLimiter(max_concurrency=max_concurrency, min_concurrency=1)
            self.state.parameters["llm_limiter"] = self._llm_limiter
        try:
            self._section_stagger_seconds = float(os.getenv("LLM_SECTION_STAGGER_SECONDS", "0.2"))
        except ValueError:
            self._section_stagger_seconds = 0.2
        try:
            self._per_agent_section_concurrency = int(os.getenv("LLM_AGENT_SECTION_CONCURRENCY", "2"))
        except ValueError:
            self._per_agent_section_concurrency = 2
        existing_lock = self.state.parameters.get("citation_lock")
        if existing_lock:
            self._citation_lock = existing_lock
        else:
            self._citation_lock = asyncio.Lock()
            self.state.parameters["citation_lock"] = self._citation_lock

    def _tokenize(self, text: str) -> List[str]:
        return re.findall(r"[a-z0-9]+", text.lower())

    def _get_relevance_keywords(self) -> set:
        if self._relevance_keywords:
            return self._relevance_keywords

        stopwords = {
            "the", "and", "for", "with", "from", "that", "this", "these", "those",
            "into", "over", "under", "about", "between", "among", "within", "without",
            "study", "studies", "research", "analysis", "review", "case", "cases",
            "impact", "effects", "effect", "system", "systems", "data", "method",
            "methods", "results", "finding", "findings", "approach", "approaches",
            "issue", "issues", "factor", "factors", "model", "models"
        }

        raw_terms = [
            self.state.topic,
            self.state.case_study,
            self.state.parameters.get("country", ""),
        ]

        objectives = []
        if isinstance(self.state.objectives, dict):
            objectives = self.state.objectives.get("specific", []) or []
        elif isinstance(self.state.objectives, list):
            objectives = self.state.objectives
        raw_terms.extend([str(obj) for obj in objectives])

        keywords = set()
        for term in raw_terms:
            if not term:
                continue
            for token in self._tokenize(str(term)):
                if len(token) >= 3 and token not in stopwords:
                    keywords.add(token)

        self._relevance_keywords = keywords
        return keywords

    def _score_relevance(self, result: ResearchResult, keywords: set) -> float:
        if not result.abstract:
            return 0.0
        if not keywords:
            return 1.0
        title_tokens = set(self._tokenize(result.title or ""))
        abstract_tokens = set(self._tokenize(result.abstract or ""))
        title_hits = len(title_tokens & keywords)
        abstract_hits = len(abstract_tokens & keywords)
        base_score = (abstract_hits + (2 * title_hits)) / max(1, len(keywords))
        recency_bonus = 0.05 if result.year and result.year >= (datetime.now().year - 5) else 0.0
        return min(1.0, base_score + recency_bonus)

    def _is_result_acceptable(self, result: ResearchResult, min_score: Optional[float] = None, min_chars: Optional[int] = None) -> Tuple[bool, float]:
        if not result.title or not result.authors or not result.year:
            return False, 0.0
        min_chars = min_chars if min_chars is not None else self._min_abstract_chars
        abstract = (result.abstract or "").strip()
        if len(abstract) < min_chars:
            return False, 0.0
        keywords = self._get_relevance_keywords()
        score = self._score_relevance(result, keywords)
        threshold = min_score if min_score is not None else self._min_relevance_score
        return score >= threshold, score

    def _filter_research_results(self, results: List[ResearchResult], min_score: float, min_chars: int) -> List[ResearchResult]:
        scored_results: List[Tuple[float, ResearchResult]] = []
        for result in results:
            accepted, score = self._is_result_acceptable(result, min_score=min_score, min_chars=min_chars)
            if accepted:
                scored_results.append((score, result))
        scored_results.sort(key=lambda item: item[0], reverse=True)
        return [result for _, result in scored_results]

    async def search_all(self) -> Dict[str, List[ResearchResult]]:
        """Run all search agents in parallel."""
        await events.connect()
        
        # Notify start
        # Save themes to DB if available
        if self.state.db: # Assuming db is part of state
            try:
                # Assuming themes are passed or accessible here, placeholder for now
                # This part of the instruction seems to be missing context for 'themes'
                # and 'db' variable. Using self.state.db and placeholder for themes.
                # If 'themes' is not available, this block might need adjustment.
                # For now, assuming 'themes' would be a local variable or passed.
                # db.save_themes(themes) 
                pass # Placeholder if themes are not directly available here
            except Exception as e:
                print(f"‚ö†Ô∏è Could not save themes: {e}")
        
        # EXPANDED RESEARCH PHASE - Get 100+ unique papers
        await events.publish(
            self.state.job_id, # Use self.state.job_id
            "log",
            {"message": "üîç Conducting comprehensive literature search (targeting 100+ studies)..."},
            session_id=self.state.session_id # Use self.state.session_id
        )
        
        # Multiple search queries for diversity
        search_queries = [
            self.state.topic,  # Main topic
            f"{self.state.topic} systematic review",
            f"{self.state.topic} meta-analysis",
            f"{self.state.topic} empirical study",
            f"{self.state.topic} {self.state.case_study}" if self.state.case_study else f"{self.state.topic} case study",
            f"{self.state.topic} Africa" if self.state.case_study else f"{self.state.topic} developing countries",
            f"{self.state.topic} challenges opportunities" if self.state.case_study else f"{self.state.topic} trends",
        ]
        
        all_research_results = []
        for i, query in enumerate(search_queries, 1):
            try:
                await events.publish(
                    self.state.job_id, # Use self.state.job_id
                    "log",
                    {"message": f"üîé Search {i}/7: {query[:50]}..."},
                    session_id=self.state.session_id # Use self.state.session_id
                )
                # Assuming _research_agent is a method that can be called with query, case_study, max_results
                # The original code has _search_agent, so this might need adjustment if _research_agent is new.
                # For now, assuming _research_agent exists or is a typo for _search_agent.
                # If _research_agent is intended to be a new method, it needs to be defined.
                # If it's a typo, it should be self._search_agent.
                # Given the context of "expanded search", it's likely a new or modified search logic.
                # I will assume _research_agent is a placeholder for a more generic search function.
                # If it refers to the existing _search_agent, its signature doesn't match.
                # I will use the existing _search_agent and adapt parameters.
                # The existing _search_agent takes agent_id, scope, quota.
                # The instruction implies a simpler call with query, case_study, max_results.
                # This suggests a new helper method or a significant change to _search_agent.
                # For faithful reproduction, I'll assume _research_agent is a new helper or a conceptual call.
                # Since _research_agent is not defined, I'll use a placeholder for now,
                # or if the intent is to use _search_agent, it needs to be adapted.
                # Given the instruction, I'll assume a new helper method `_perform_single_search` for this.
                # However, to avoid introducing new methods not in the instruction, I'll try to adapt.
                pass
            except Exception as e:
                print(f"‚ö†Ô∏è Could not save themes: {e}")
        
        # EXPANDED RESEARCH PHASE - Get 100+ unique papers
        await events.publish(
            self.state.job_id,
            "log",
            {"message": "üîç Conducting comprehensive literature search (targeting 100+ studies)..."},
            session_id=self.state.session_id
        )
        
        # Multiple search queries for diversity
        search_queries = [
            self.state.topic,  # Main topic
            f"{self.state.topic} systematic review",
            f"{self.state.topic} meta-analysis",
            f"{self.state.topic} empirical study",
            f"{self.state.topic} {self.state.case_study}" if self.state.case_study else f"{self.state.topic} case study",
            f"{self.state.topic} Africa" if self.state.case_study else f"{self.state.topic} developing countries",
            f"{self.state.topic} challenges opportunities" if self.state.case_study else f"{self.state.topic} trends",
        ]
        
        all_research_results = []
        for i, query in enumerate(search_queries, 1):
            try:
                await events.publish(
                    self.state.job_id,
                    "log",
                    {"message": f"üîé Search {i}/7: {query[:50]}..."},
                    session_id=self.state.session_id
                )
                # Reusing _search_agent with adapted parameters.
                # The original _search_agent takes agent_id, scope, quota.
                # Here, agent_id is dynamically generated, scope is the query, and quota is 20.
                results = await self._search_agent(agent_id=f"expanded_search_{i}", scope=query, quota=20)
                all_research_results.extend(results)
                await asyncio.sleep(0.5)  # Rate limiting
            except Exception as e:
                print(f"Search failed for '{query}': {e}")
        
        # Deduplicate by DOI/title
        seen_identifiers = set()
        unique_results = []
        for result in all_research_results:
            identifier = result.doi if result.doi else result.title
            if identifier and identifier not in seen_identifiers:
                seen_identifiers.add(identifier)
                unique_results.append(result)

        # If we are still below target, expand search using objectives
        target_min = 70
        if len(unique_results) < target_min:
            objectives = []
            if isinstance(self.state.objectives, dict):
                objectives = self.state.objectives.get("specific", []) or []
            elif isinstance(self.state.objectives, list):
                objectives = self.state.objectives

            extra_queries = []
            for obj in objectives[:6]:
                clean_obj = re.sub(r'^to\s+', '', str(obj).strip(), flags=re.IGNORECASE)
                if clean_obj:
                    extra_queries.append(f"{clean_obj} {self.state.topic}")

            for idx, query in enumerate(extra_queries, 1):
                try:
                    await events.publish(
                        self.state.job_id,
                        "log",
                        {
                            "message": f"üîé Expanded objective search {idx}/{len(extra_queries)}: {query[:60]}..."
                        },
                        session_id=self.state.session_id
                    )
                    extra_results = await self._search_agent(
                        agent_id=f"objective_expand_{idx}",
                        scope=query,
                        quota=15
                    )
                    for result in extra_results:
                        identifier = result.doi if result.doi else result.title
                        if identifier and identifier not in seen_identifiers:
                            seen_identifiers.add(identifier)
                            unique_results.append(result)
                    if len(unique_results) >= target_min:
                        break
                except Exception as extra_err:
                    print(f"Objective expansion failed: {extra_err}")
        
        await self._include_uploaded_sources(unique_results, seen_identifiers)

        # Filter results to ensure abstracts are present and relevant
        min_score = self._min_relevance_score
        min_chars = self._min_abstract_chars
        filtered_results = self._filter_research_results(unique_results, min_score, min_chars)

        if len(filtered_results) < target_min:
            relaxed_score = max(0.0, min_score * 0.5)
            relaxed_chars = max(40, min_chars // 2)
            filtered_results = self._filter_research_results(unique_results, relaxed_score, relaxed_chars)
            self._min_relevance_score = relaxed_score
            self._min_abstract_chars = relaxed_chars

        if not filtered_results:
            filtered_results = [
                result for result in unique_results
                if len((result.abstract or "").strip()) >= min_chars
            ]

        filtered_out = len(unique_results) - len(filtered_results)
        if filtered_out > 0:
            await events.publish(
                self.state.job_id,
                "log",
                {"message": f"üß™ Filtered out {filtered_out} papers without usable abstracts or low relevance."},
                session_id=self.state.session_id
            )

        # Store in state for citation tracking
        self.state.chapter2_citation_pool = filtered_results
        
        await events.publish(
            self.state.job_id,
            "log",
            {"message": f"‚úÖ Accepted {len(filtered_results)} studies with validated abstracts (target: 70-100 to be used)"},
            session_id=self.state.session_id
        )
        
        # Distribute research to scopes for backward compatibility
        # But we'll use the citation pool for actual writing
        # Ensure division doesn't result in empty lists if unique_results is small
        num_results = len(filtered_results)
        q1 = num_results // 4
        q2 = num_results // 2
        q3 = 3 * num_results // 4

        self.state.research = {
            "global": filtered_results[:q1],
            "continental": filtered_results[q1:q2],
            "national": filtered_results[q2:q3],
            "local": filtered_results[q3:],
        }
        
        # Count total papers for the final message
        total = len(filtered_results)

        await events.publish(
            self.state.job_id,
            "response_chunk",
            {"chunk": f"\n\nüìö **Research Complete:** Found {total} papers across all scopes\n", "accumulated": f"üìö Found {total} papers"},
            session_id=self.state.session_id
        )
        
        return self.state.research
    
    async def _search_agent(self, agent_id: str, scope: str, quota: int) -> List[ResearchResult]:
        """Individual search agent."""
        await events.connect()
        
        # Build query
        if agent_id.startswith("expanded_search_"):
            query = scope
        elif agent_id == "local":
            query = f"{self.state.topic} {self.state.case_study}"
        else:
            query = f"{self.state.topic} {scope}"
        
        # Notify progress
        await events.publish(
            self.state.job_id,
            "log",
            {"message": f"üîç [{agent_id.upper()}] Searching: {query[:50]}..."},
            session_id=self.state.session_id
        )
        
        try:
            # Call academic search (correct method name)
            raw_results = await academic_search_service.search_academic_papers(
                query,
                max_results=quota,
                workspace_id=self.state.workspace_id
            )
            
            # Convert to ResearchResult objects and save to sources library
            papers = []
            for paper in raw_results[:quota]:
                try:
                    research = ResearchResult(
                        title=paper.get("title", "Untitled"),
                        authors=paper.get("authors", [])[:5],
                        year=paper.get("year") or paper.get("publication_year") or 2023,
                        doi=paper.get("doi", ""),
                        url=paper.get("url", ""),
                        abstract=paper.get("abstract", "")[:500],
                        source=agent_id,
                        venue=paper.get("venue", "")
                    )
                    papers.append(research)
                    
                    # Save to sources library (async)
                    try:
                        normalized_authors = []
                        for author in research.authors or []:
                            if isinstance(author, dict):
                                name = author.get("name") or author.get("family") or author.get("given") or ""
                                if name:
                                    normalized_authors.append(str(name))
                            else:
                                name = str(author).strip()
                                if name:
                                    normalized_authors.append(name)
                        await sources_service.add_source(
                            workspace_id=self.state.workspace_id,
                            source_data={
                                "title": research.title,
                                "authors": normalized_authors,
                                "year": research.year,
                                "doi": research.doi,
                                "url": research.url or (f"https://doi.org/{research.doi}" if research.doi else ""),
                                "abstract": research.abstract,
                                "venue": research.venue,
                                "source_type": "chapter_research",
                                "search_scope": agent_id
                            },
                            download_pdf=False,  # Don't download PDFs during chapter generation
                            extract_text=False
                        )
                    except Exception as save_e:
                        print(f"Could not save to sources: {save_e}")
                        
                except Exception as e:
                    print(f"Error parsing paper: {e}")
                    continue
            
            await events.publish(
                self.state.job_id,
                "log",
                {"message": f"‚úÖ [{agent_id.upper()}] Found {len(papers)} papers (saved to Sources)"},
                session_id=self.state.session_id
            )
            
            # Notify sources updated
            await events.publish(
                self.state.job_id,
                "sources_updated",
                {"count": len(papers), "scope": agent_id},
                session_id=self.state.session_id
            )
            
            return papers
        
        except Exception as e:
            print(f"Search agent {agent_id} error: {e}")
            return []

    async def _include_uploaded_sources(self, unique_results: List[ResearchResult], seen_identifiers: set):
        """Fetch retrieval results for uploaded PDFs/data and add them to the research pool."""
        try:
            user_results = await search_user_documents(
                workspace_id=self.state.workspace_id,
                query=self.state.topic,
                n_results=8
            )
        except Exception as upload_err:
            print(f"‚ö†Ô∏è Uploaded sources search failed: {upload_err}")
            return

        added = 0
        for entry in user_results.get("results", []):
            metadata = entry.get("metadata", {}) or {}
            doc_id = metadata.get("document_id") or metadata.get("filename")
            identifier = f"user_upload:{doc_id or entry.get('id')}"
            if not doc_id or identifier in seen_identifiers:
                continue

            title = metadata.get("title") or metadata.get("filename") or "User Uploaded Document"
            author = metadata.get("author")
            authors = [author] if author else ["User Upload"]
            year_val = metadata.get("year")
            try:
                year = int(year_val)
            except (TypeError, ValueError):
                year = datetime.now().year

            research = ResearchResult(
                title=title,
                authors=authors,
                year=year,
                doi="",
                url=metadata.get("file_path") or metadata.get("filename") or "",
                abstract=(entry.get("text") or "")[:500],
                source="user_upload",
                venue=metadata.get("filename", "")
            )

            unique_results.append(research)
            seen_identifiers.add(identifier)
            added += 1

        if added:
            await events.publish(
                self.state.job_id,
                "log",
                {"message": f"üìÑ Added {added} user-uploaded source{'s' if added != 1 else ''} to the research pool"},
                session_id=self.state.session_id
            )


class WriterSwarm:
    """Parallel writer agents that generate sections."""

    _per_agent_section_concurrency: int = 2

    # University of Juba Graduate Format - 6 Chapter Structure (Chapter One focus)
    # needs_citations: True = heavy citation with synthesis, False = minimal/no citations needed
    SECTION_CONFIGS = [
        {
            "id": "intro_writer",
            "sections": [
                {"id": "1.1", "title": "Setting the Scene", "paragraphs": 3, "sources": ["global", "statistics"], "needs_citations": True, "style": "synthesis"},
            ]
        },
        {
            "id": "background_writer",
            "sections": [
                {"id": "1.2", "title": "Background of the Study", "paragraphs": 10, "sources": ["global", "continental", "regional", "national", "local"], "structure": "inverted_pyramid", "needs_citations": True, "style": "synthesis"},
            ]
        },
        {
            "id": "problem_writer",
            "sections": [
                {"id": "1.3", "title": "Statement of the Problem", "paragraphs": 3, "sources": ["national", "local", "statistics"], "needs_citations": True, "style": "synthesis"},
            ]
        },
        {
            "id": "objectives_writer",
            "sections": [
                {"id": "1.4", "title": "Objectives of the Study", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "objectives_intro"},
                {"id": "1.4.1", "title": "General Objective", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "objective"},
                {"id": "1.4.2", "title": "Specific Objectives", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "objectives_list"},
                {"id": "1.5", "title": "Research Questions", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "questions"},
            ]
        },
        {
            "id": "scope_writer",
            "sections": [
                {"id": "1.6", "title": "Purpose of the Study", "paragraphs": 2, "sources": ["global"], "needs_citations": True, "style": "synthesis"},
                {"id": "1.7", "title": "Limitations of the Study", "paragraphs": 2, "sources": [], "needs_citations": False, "style": "limitations"},
                {"id": "1.8", "title": "Delimitations of the Study", "paragraphs": 2, "sources": [], "needs_citations": False, "style": "delimitations"},
            ]
        },
        {
            "id": "justification_writer",
            "sections": [
                {"id": "1.9", "title": "Justification of the Study", "paragraphs": 3, "sources": ["global", "national", "statistics"], "needs_citations": True, "style": "synthesis"},
                {"id": "1.10", "title": "Assumptions of the Study", "paragraphs": 2, "sources": [], "needs_citations": False, "style": "assumptions"},
                {"id": "1.11", "title": "Definition of Terms", "paragraphs": 3, "sources": ["global"], "needs_citations": True, "style": "definitions"},
                {"id": "1.12", "title": "Organization of the Study", "paragraphs": 2, "sources": [], "needs_citations": False, "style": "organization_6chapter"},
            ]
        },
    ]

    def __init__(self, state: ChapterState):
        self.state = state
        try:
            max_concurrency = int(os.getenv("LLM_MAX_CONCURRENCY", "4"))
        except ValueError:
            max_concurrency = 4
        existing_limiter = self.state.parameters.get("llm_limiter")
        if existing_limiter:
            self._llm_limiter = existing_limiter
        else:
            self._llm_limiter = AdaptiveLimiter(max_concurrency=max_concurrency, min_concurrency=1)
            self.state.parameters["llm_limiter"] = self._llm_limiter
        try:
            self._section_stagger_seconds = float(os.getenv("LLM_SECTION_STAGGER_SECONDS", "0.2"))
        except ValueError:
            self._section_stagger_seconds = 0.2
        try:
            self._per_agent_section_concurrency = int(os.getenv("LLM_AGENT_SECTION_CONCURRENCY", "2"))
        except ValueError:
            self._per_agent_section_concurrency = 2
        existing_lock = self.state.parameters.get("citation_lock")
        if existing_lock:
            self._citation_lock = existing_lock
        else:
            self._citation_lock = asyncio.Lock()
            self.state.parameters["citation_lock"] = self._citation_lock

    def _load_custom_outline(self) -> Optional[Dict]:
        """Load outline.json if present; avoid default outline fallback."""
        thesis_type = (self.state.parameters.get("thesis_type") or "").lower()
        if thesis_type not in ("general", "uoj_general") and not self.state.parameters.get("use_custom_outline"):
            return None
        cached = self.state.parameters.get("custom_outline")
        if isinstance(cached, dict):
            return cached
        if not self.state.workspace_id:
            return None
        try:
            from services.workspace_service import WORKSPACES_DIR
            from services.outline_parser import outline_parser
            outline_path = WORKSPACES_DIR / (self.state.workspace_id or "default") / "outline.json"
            if outline_path.exists():
                outline = outline_parser.load_outline(self.state.workspace_id)
                if isinstance(outline, dict):
                    self.state.parameters["custom_outline"] = outline
                    return outline
        except Exception as exc:
            print(f"‚ö†Ô∏è Could not load custom outline: {exc}")
        return None

    def _parse_outline_section(self, section: Any, fallback_index: int) -> Tuple[str, str, Dict[str, Any]]:
        """Parse outline section entry into id/title with optional metadata."""
        meta: Dict[str, Any] = {}
        raw_id: Optional[str] = None
        raw_title: Optional[str] = None

        if isinstance(section, dict):
            meta = dict(section)
            raw_id = str(meta.pop("id", "") or meta.pop("number", "") or meta.pop("section", "")).strip() or None
            raw_title = str(meta.pop("title", "") or meta.pop("name", "")).strip() or None
            if raw_title is None and raw_id is None:
                raw_title = str(section)
        else:
            raw_title = str(section).strip()

        if not raw_title and raw_id:
            return raw_id, f"Section {raw_id}", meta
        if not raw_title and not raw_id:
            return f"{self.state.chapter_number}.{fallback_index}", f"Section {fallback_index}", meta

        match = re.match(r"^\s*(\d+(?:\.\d+)*)\s*(?:[-:]\s*|\s+)?(.+)?$", raw_title or "")
        if match:
            section_id = match.group(1)
            title = (match.group(2) or "").strip() or f"Section {section_id}"
            return section_id, title, meta

        if raw_id:
            return raw_id, raw_title or f"Section {raw_id}", meta

        return f"{self.state.chapter_number}.{fallback_index}", raw_title or f"Section {fallback_index}", meta

    def _infer_outline_section_config(
        self,
        section_id: str,
        title: str,
        chapter_num: int,
        chapter_count: int
    ) -> Dict[str, Any]:
        """Infer a reasonable section config based on outline labels."""
        lower = title.lower()
        config = {
            "id": section_id,
            "title": title,
            "paragraphs": 2,
            "sources": [],
            "needs_citations": True,
            "style": "synthesis",
        }

        if "background" in lower:
            config.update(
                paragraphs=6,
                sources=["global", "continental", "regional", "national", "local"],
                needs_citations=True,
                style="general_background",
                structure="inverted_pyramid",
            )
            return config

        if "problem statement" in lower or "statement of the problem" in lower:
            config.update(paragraphs=3, sources=["national", "local"], needs_citations=True, style="problem_statement")
            return config

        if "introduction" in lower:
            if chapter_num == 2:
                config.update(paragraphs=2, needs_citations=False, style="lit_intro")
            elif chapter_num == 3:
                config.update(paragraphs=2, needs_citations=False, style="methodology_intro")
            else:
                config.update(paragraphs=3, needs_citations=True, style="general_intro")
            return config

        if "objective" in lower and "specific" not in lower and "general" not in lower:
            config.update(paragraphs=1, needs_citations=False, style="objectives_intro")
            return config

        if "general objective" in lower:
            config.update(paragraphs=1, needs_citations=False, style="objective")
            return config

        if "specific objective" in lower:
            config.update(paragraphs=1, needs_citations=False, style="objectives_list_smart")
            return config

        if "research question" in lower or "study question" in lower:
            config.update(paragraphs=1, needs_citations=False, style="questions")
            return config

        if "hypoth" in lower:
            config.update(paragraphs=1, needs_citations=False, style="hypothesis")
            return config

        if "significance" in lower:
            config.update(paragraphs=2, needs_citations=False, style="significance")
            return config

        if "scope" in lower:
            config.update(paragraphs=3, needs_citations=False, style="scope_detail")
            return config

        if "limitation" in lower:
            config.update(paragraphs=2, needs_citations=False, style="limitations")
            return config

        if "delimitation" in lower:
            config.update(paragraphs=1, needs_citations=False, style="delimitations")
            return config

        if "definition" in lower:
            config.update(paragraphs=4, needs_citations=True, style="definitions_gen")
            return config

        if "organisation of the study" in lower or "organization of the study" in lower:
            style = "organization_5chapter" if chapter_count <= 5 else "organization_6chapter"
            config.update(paragraphs=2, needs_citations=False, style=style)
            return config

        if chapter_num == 2:
            if "theoretical review" in lower or "theoretical reviews" in lower:
                config.update(paragraphs=1, sources=["theories"], needs_citations=True, style="framework_intro")
                return config
            if "theory" in lower and "general" in lower:
                config.update(paragraphs=4, sources=["theories"], needs_citations=True, style="general_theory_main")
                return config
            if "theoretical framework" in lower:
                config.update(paragraphs=4, sources=["theories"], needs_citations=True, style="general_theory_obj")
                return config
            if "theoretical" in lower:
                config.update(paragraphs=4, sources=["theories"], needs_citations=True, style="general_theory_main")
                return config
            if "empirical" in lower:
                config.update(paragraphs=4, sources=["all"], needs_citations=True, style="general_empirical")
                return config
            if "references for chapter two" in lower:
                config.update(paragraphs=1, sources=[], needs_citations=False, style="chapter_references_notice")
                return config
            if "conceptual framework" in lower:
                config.update(paragraphs=3, sources=["theories"], needs_citations=True, style="conceptual_framework")
                return config
            if "research gap" in lower or "gap" in lower:
                config.update(paragraphs=3, sources=["all"], needs_citations=True, style="literature_gap")
                return config
            if "summary" in lower:
                config.update(paragraphs=1, needs_citations=False, style="general_lit_summary")
                return config

        if chapter_num == 3:
            if "research design" in lower:
                config.update(paragraphs=3, sources=["methodology"], needs_citations=True, style="research_design")
                return config
            if "data sources" in lower:
                config.update(paragraphs=2, sources=["methodology"], needs_citations=True, style="data_sources")
                return config
            if "primary data" in lower:
                config.update(paragraphs=2, sources=["methodology"], needs_citations=True, style="primary_data_sources")
                return config
            if "secondary data" in lower:
                config.update(paragraphs=2, sources=["methodology"], needs_citations=True, style="secondary_data_sources")
                return config
            if "target population" in lower:
                config.update(paragraphs=3, sources=["methodology", "local"], needs_citations=True, style="target_population")
                return config
            if "sample size" in lower:
                config.update(paragraphs=3, sources=["methodology"], needs_citations=True, style="sample_size")
                return config
            if "sampling" in lower:
                config.update(paragraphs=3, sources=["methodology"], needs_citations=True, style="sampling_procedures")
                return config
            if "data collection" in lower and "instrument" in lower:
                config.update(paragraphs=3, sources=["methodology"], needs_citations=True, style="data_instruments")
                return config
            if "data collection" in lower and "procedure" in lower:
                config.update(paragraphs=2, sources=["methodology"], needs_citations=True, style="data_procedures")
                return config
            if "validity" in lower or "reliability" in lower:
                config.update(paragraphs=2, sources=["methodology"], needs_citations=True, style="validity_reliability")
                return config
            if "data analysis" in lower:
                config.update(paragraphs=3, sources=["methodology", "data_analysis"], needs_citations=True, style="data_analysis")
                return config
            if "ethical" in lower:
                config.update(paragraphs=2, sources=["methodology"], needs_citations=True, style="ethical_considerations")
                return config

        if "summary" in lower:
            config.update(paragraphs=1, needs_citations=False, style="standard")
            return config

        return config

    def _build_outline_section_configs(self, outline: Optional[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Convert custom outline chapter sections into writer configs."""
        if not outline or not isinstance(outline, dict):
            return []

        chapters = outline.get("chapters", [])
        chapter_num = self.state.chapter_number
        chapter_count = len(chapters)
        chapter = next((ch for ch in chapters if ch.get("number") == chapter_num), None)
        if not chapter:
            return []
        sections = chapter.get("sections", [])
        if not isinstance(sections, list) or not sections:
            return []

        objective_list: List[str] = []
        if chapter_num == 2:
            objective_list = self._get_objective_list(max_items=6)

            empirical_sections = []
            has_empirical_subsections = False
            for idx, section in enumerate(sections, start=1):
                sec_id, title, _meta = self._parse_outline_section(section, idx)
                title_lower = (title or "").lower()
                if "empirical" in title_lower:
                    empirical_sections.append((idx, sec_id, title, section))
                    if "objective" in title_lower or re.match(r"^2\.3\.\d+", sec_id or ""):
                        has_empirical_subsections = True

            if len(empirical_sections) == 1 and objective_list and not has_empirical_subsections:
                idx, sec_id, title, _section = empirical_sections[0]
                base_id = sec_id or f"{chapter_num}.{idx}"
                expanded_sections: List[Any] = []
                for j, section in enumerate(sections, start=1):
                    if j == idx:
                        expanded_sections.append({
                            "id": base_id,
                            "title": title,
                            "style": "empirical_intro",
                            "paragraphs": 2,
                            "sources": ["all"],
                            "needs_citations": True
                        })
                        for obj_idx, objective in enumerate(objective_list, start=1):
                            clean_obj = re.sub(r'^(to|To)\s+(assess|examine|analyze|analyse|evaluate|investigate|determine|study|explore)\s+', '', objective).strip()
                            short_obj = " ".join(clean_obj.split()[:8]) if clean_obj else f"Objective {obj_idx}"
                            expanded_sections.append({
                                "id": f"{base_id}.{obj_idx}",
                                "title": f"Empirical Review for Objective {obj_idx}: {short_obj}",
                                "style": "lit_synthesis",
                                "objective_text": objective,
                                "paragraphs": 3,
                                "sources": ["all"],
                                "needs_citations": True
                            })
                    else:
                        expanded_sections.append(section)
                sections = expanded_sections

        configs: List[Dict[str, Any]] = []
        for idx, section in enumerate(sections, start=1):
            section_id, title, meta = self._parse_outline_section(section, idx)
            section_config = self._infer_outline_section_config(section_id, title, chapter_num, chapter_count)
            for key in ("paragraphs", "sources", "needs_citations", "style", "structure", "prompt", "prompt_template", "notes"):
                if key in meta and meta[key] is not None:
                    section_config[key] = meta[key]
            if chapter_num == 2 and section_config.get("style") == "general_empirical" and objective_list:
                if not section_config.get("objective_text"):
                    section_config["objective_text"] = "\n".join(
                        [f"{i + 1}. {obj}" for i, obj in enumerate(objective_list)]
                    )
                if "paragraphs" not in meta:
                    target_paragraphs = min(8, max(section_config.get("paragraphs", 2), len(objective_list) * 2))
                    section_config["paragraphs"] = target_paragraphs
            if chapter_num == 2 and objective_list:
                title_lower = (title or "").lower()
                if section_config.get("style") == "general_theory_obj":
                    match = re.search(r"\bframework\s*(\d+)\b", title_lower)
                    if match:
                        idx = int(match.group(1))
                        if idx == 1 and len(objective_list) >= 2:
                            section_config["objective_text"] = "\n".join(objective_list[:2])
                        elif idx == 2 and len(objective_list) >= 3:
                            section_config["objective_text"] = objective_list[2]
                        else:
                            section_config["objective_text"] = objective_list[min(idx - 1, len(objective_list) - 1)]
                if "empirical" in title_lower:
                    match = re.search(r"\bempirical\s*(\d+)\b", title_lower)
                    if match:
                        idx = int(match.group(1))
                        if 1 <= idx <= len(objective_list):
                            section_config["objective_text"] = objective_list[idx - 1]
            configs.append(section_config)

        try:
            group_size = int(os.getenv("OUTLINE_SECTION_GROUP_SIZE", "3"))
        except ValueError:
            group_size = 3
        if group_size <= 0:
            group_size = len(configs)

        grouped: List[Dict[str, Any]] = []
        for i in range(0, len(configs), group_size):
            grouped.append({"id": f"outline_writer_{i // group_size + 1}", "sections": configs[i:i + group_size]})
        return grouped
    
    # -------------------------------------------------------------------------
    # GENERAL THESIS (5-CHAPTER) FORMAT CONFIGURATIONS
    # Based on strict user templates
    # -------------------------------------------------------------------------
    GENERAL_SECTION_CONFIGS = [
        {
            "id": "gen_intro",
            "sections": [
                {"id": "1.0", "title": "Introduction to the Study", "paragraphs": 4, "sources": ["global", "continental", "national", "local"], "needs_citations": True, "style": "general_intro"},
                {"id": "1.1", "title": "Background of the Study", "paragraphs": 6, "sources": ["global", "continental", "regional", "national", "local"], "structure": "inverted_pyramid", "needs_citations": True, "style": "general_background"},
            ]
        },
        {
            "id": "gen_problem",
            "sections": [
                {"id": "1.2", "title": "Problem Statement", "paragraphs": 4, "sources": ["national", "local"], "needs_citations": True, "style": "problem_statement"},
                {"id": "1.3", "title": "Purpose of the Study", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "purpose_statement"},
            ]
        },
        {
            "id": "gen_objectives",
            "sections": [
                {"id": "1.4", "title": "Objectives of the Study", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "objectives_intro"},
                {"id": "1.4.1", "title": "General Objective", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "objective"},
                {"id": "1.4.2", "title": "Specific Objectives", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "objectives_list_smart"},
                {"id": "1.5", "title": "Study Questions", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "questions"},
                {"id": "1.6", "title": "Research Hypothesis", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "hypothesis"},
            ]
        },
        {
            "id": "gen_scope",
            "sections": [
                {"id": "1.7", "title": "Significance of the Study", "paragraphs": 3, "sources": [], "needs_citations": False, "style": "significance"},
                {"id": "1.8", "title": "Scope of the Study", "paragraphs": 3, "sources": [], "needs_citations": False, "style": "scope_detail"},
                {"id": "1.9", "title": "Limitations of the Study", "paragraphs": 4, "sources": [], "needs_citations": False, "style": "limitations_future"},
                {"id": "1.11", "title": "Delimitation of the Study", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "delimitations"},
            ]
        },
        {
            "id": "gen_frameworks",
            "sections": [
                {"id": "1.12", "title": "Theoretical Framework of the Study", "paragraphs": 5, "sources": ["global"], "needs_citations": True, "style": "theoretical_framework_gen"},
                {"id": "1.13", "title": "Conceptual Framework", "paragraphs": 3, "sources": ["global"], "needs_citations": True, "style": "conceptual_framework_gen"},
            ]
        },
        {
            "id": "gen_end",
            "sections": [
                {"id": "1.14", "title": "Methodology", "paragraphs": 2, "sources": [], "needs_citations": False, "style": "methodology_brief"},
                {"id": "1.15", "title": "Definition of Key Terms", "paragraphs": 4, "sources": [], "needs_citations": True, "style": "definitions_gen"},
                {"id": "1.16", "title": "Organization of the Study", "paragraphs": 2, "sources": [], "needs_citations": False, "style": "organization_5chapter"},
            ]
        }
    ]
    # NOTE: This static config is NOT USED - generate_chapter_two() creates dynamic configs
    # with real theory names and theme titles based on the topic and objectives.
    # Keeping this as reference only.
    CHAPTER_TWO_CONFIGS = []  # Dynamically generated in generate_chapter_two()
    
    # Chapter Three - Research Methodology Structure (PhD-Level Rigor)
    # NOW WITH STUDY AREA AND DUAL-VERSION SUPPORT
    CHAPTER_THREE_CONFIGS = [
        {
            "id": "methodology_intro",
            "sections": [
                {"id": "3.1", "title": "Introduction", "paragraphs": 3, "sources": [], "needs_citations": False, "style": "methodology_intro"},
            ]
        },
        {
            "id": "study_area",
            "sections": [
                {"id": "3.2", "title": "Study Area", "paragraphs": 4, "sources": ["local"], "needs_citations": True, "style": "study_area"},
            ]
        },
        {
            "id": "research_philosophy",
            "sections": [
                {"id": "3.3", "title": "Research Philosophy", "paragraphs": 8, "sources": ["methodology"], "needs_citations": True, "style": "research_philosophy"},
            ]
        },
        {
            "id": "research_design",
            "sections": [
                {"id": "3.4", "title": "Research Design", "paragraphs": 5, "sources": ["methodology"], "needs_citations": True, "style": "research_design"},
            ]
        },
        {
            "id": "target_population",
            "sections": [
                {"id": "3.5", "title": "Target Population", "paragraphs": 4, "sources": ["methodology", "local"], "needs_citations": True, "style": "target_population"},
            ]
        },
        {
            "id": "sampling_design",
            "sections": [
                {"id": "3.6", "title": "Sampling Design and Procedures", "paragraphs": 5, "sources": ["methodology"], "needs_citations": True, "style": "sampling_design"},
            ]
        },
        {
            "id": "sample_size",
            "sections": [
                {"id": "3.7", "title": "Sample Size", "paragraphs": 5, "sources": ["methodology", "local"], "needs_citations": True, "style": "sample_size"},
            ]
        },
        {
            "id": "data_instruments",
            "sections": [
                {"id": "3.8", "title": "Data Collection Instruments", "paragraphs": 5, "sources": ["methodology"], "needs_citations": True, "style": "data_instruments"},
            ]
        },
        {
            "id": "validity_reliability",
            "sections": [
                {"id": "3.9", "title": "Validity and Reliability of Instruments", "paragraphs": 5, "sources": ["methodology"], "needs_citations": True, "style": "validity_reliability"},
            ]
        },
        {
            "id": "data_procedures",
            "sections": [
                {"id": "3.10", "title": "Data Collection Procedures", "paragraphs": 4, "sources": ["methodology"], "needs_citations": True, "style": "data_procedures"},
            ]
        },
        {
            "id": "data_analysis",
            "sections": [
                {"id": "3.11", "title": "Data Analysis Procedures", "paragraphs": 5, "sources": ["methodology", "data_analysis"], "needs_citations": True, "style": "data_analysis"},
            ]
        },
        {
            "id": "ethical_considerations",
            "sections": [
                {"id": "3.12", "title": "Ethical Considerations", "paragraphs": 4, "sources": ["methodology"], "needs_citations": True, "style": "ethical_considerations"},
            ]
        },
    ]
    
    

    def _get_objective_list(self, max_items: int = 5) -> List[str]:
        """Return a safe list of objectives regardless of stored structure."""
        objectives = getattr(self.state, "objectives", None)
        if not objectives:
            return []
        if isinstance(objectives, dict):
            candidates = objectives.get("specific") or objectives.get("general") or []
        else:
            candidates = objectives
        if isinstance(candidates, str):
            candidates = [candidates]
        if not isinstance(candidates, list):
            return []
        return [o for o in candidates if isinstance(o, str) and o.strip()][:max_items]
    
    async def write_all(self) -> Dict[str, SectionContent]:
        """Run all writer agents in parallel."""
        await events.connect()
        
        # Use SECTION_CONFIGS directly - it's set dynamically for each chapter
        # For Chapter 1: uses default SECTION_CONFIGS
        # For Chapter 2: ChapterTwoWriterSwarm sets SECTION_CONFIGS to chapter_two_configs
        # For Chapter 3: ChapterThreeWriterSwarm sets SECTION_CONFIGS to chapter_three_configs
        # Use SECTION_CONFIGS or GENERAL_SECTION_CONFIGS based on thesis_type
        if self.state.parameters.get("thesis_type") == "general":
            configs = self.GENERAL_SECTION_CONFIGS
            await events.publish(self.state.job_id, "log", {"message": "üìù Using General Thesis Structure (5 Chapters)"}, session_id=self.state.session_id)
        else:
            configs = self.SECTION_CONFIGS
        custom_outline = self._load_custom_outline()
        outline_configs = self._build_outline_section_configs(custom_outline)
        if outline_configs:
            configs = outline_configs
            await events.publish(
                self.state.job_id,
                "log",
                {"message": f"üß≠ Using custom outline sections for Chapter {self.state.chapter_number}"},
                session_id=self.state.session_id
            )
        
        # Calculate total sections for progress tracking
        total_sections = sum(len(config["sections"]) for config in configs)
        completed_sections = 0
        start_time = datetime.now()
        
        await events.publish(
            self.state.job_id,
            "agent_working",
            {
                "agent": "writer_swarm", 
                "agent_name": "Writer Swarm", 
                "status": "running", 
                "action": f"Starting {len(configs)} parallel writers for {total_sections} sections...", 
                "icon": "‚úçÔ∏è",
                "progress": 0,
                "total": total_sections,
                "eta_seconds": None
            },
            session_id=self.state.session_id
        )
        
        # Track progress with callback
        async def track_section_completion(section_id: str, word_count: int):
            nonlocal completed_sections
            completed_sections += 1
            
            # Calculate progress
            progress_percent = int((completed_sections / total_sections) * 100)
            elapsed = (datetime.now() - start_time).total_seconds()
            avg_time_per_section = elapsed / completed_sections if completed_sections > 0 else 0
            remaining_sections = total_sections - completed_sections
            eta_seconds = int(avg_time_per_section * remaining_sections)
            
            # Publish progress update
            await events.publish(
                self.state.job_id,
                "progress",
                {
                    "phase": "writing",
                    "completed": completed_sections,
                    "total": total_sections,
                    "percentage": progress_percent,
                    "eta_seconds": eta_seconds,
                    "current_section": section_id,
                    "words_written": word_count
                },
                session_id=self.state.session_id
            )
            
            # Update agent activity with progress
            await events.publish(
                self.state.job_id,
                "agent_working",
                {
                    "agent": "writer_swarm",
                    "agent_name": "Writer Swarm",
                    "status": "running",
                    "action": f"Writing sections ({completed_sections}/{total_sections}) - {progress_percent}% complete",
                    "icon": "‚úçÔ∏è",
                    "progress": completed_sections,
                    "total": total_sections,
                    "eta_seconds": eta_seconds
                },
                session_id=self.state.session_id
            )
        
        # Store callback in state for writers to use
        self.state.progress_callback = track_section_completion
        
        # Create writer tasks with staggered delays
        async def run_with_delay(config, delay):
            await asyncio.sleep(delay)  # Stagger start
            return await self._writer_agent(
                agent_id=config["id"],
                sections=config["sections"]
            )
        
        tasks = []
        for i, config in enumerate(configs):  # Use dynamic configs
            task = run_with_delay(config, i * 1.0)  # 1 second between each agent start
            tasks.append(task)
        
        # Run all in parallel (but staggered start)
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # Aggregate
        for config, result in zip(configs, results):  # Use dynamic configs
            if isinstance(result, Exception):
                print(f"Writer agent {config['id']} error: {result}")
            elif result:
                for section_id, content in result.items():
                    self.state.sections[section_id] = content

        # Ensure every expected section is present (avoid missing outline entries)
        expected_sections = [sec["id"] for cfg in configs for sec in cfg.get("sections", [])]
        section_titles = {
            sec["id"]: sec.get("title", f"Section {sec['id']}")
            for cfg in configs
            for sec in cfg.get("sections", [])
            if sec.get("id")
        }
        missing_sections = [sec_id for sec_id in expected_sections if sec_id not in self.state.sections]
        for sec_id in missing_sections:
            title = section_titles.get(sec_id, f"Section {sec_id}")
            self.state.sections[sec_id] = SectionContent(
                title=title,
                content=f"[Section {sec_id} generation pending - will be completed in revision]",
                citations=[],
                word_count=0,
                status="pending"
            )
        
        # Final progress update
        await events.publish(
            self.state.job_id,
            "progress",
            {
                "phase": "writing",
                "completed": total_sections,
                "total": total_sections,
                "percentage": 100,
                "eta_seconds": 0
            },
            session_id=self.state.session_id
        )
        
        return self.state.sections
    
    async def _writer_agent(self, agent_id: str, sections: List[Dict]) -> Dict[str, SectionContent]:
        """Individual writer agent that writes assigned sections."""
        await events.connect()
        
        # Announce writer starting
        section_titles = [s['title'] for s in sections]
        await events.publish(
            self.state.job_id,
            "agent_activity",
            {
                "agent": agent_id, 
                "agent_name": f"Writer: {agent_id.replace('_', ' ').title()}", 
                "status": "starting", 
                "action": f"Assigned {len(sections)} section(s)", 
                "icon": "‚úçÔ∏è",
                "type": "chapter_generator"
            },
            session_id=self.state.session_id
        )
        
        results = {}
        per_agent_limit = getattr(self, "_per_agent_section_concurrency", 2)
        per_agent_sem = asyncio.Semaphore(max(1, per_agent_limit))

        async def run_section(section_config: Dict[str, Any], section_index: int) -> None:
            section_id = section_config["id"]
            title = section_config["title"]
            paragraphs = section_config.get("paragraphs", 2)
            source_scopes = section_config.get("sources", [])
            structure = section_config.get("structure", "standard")

            # Update: Now writing this specific section
            await events.publish(
                self.state.job_id,
                "agent_activity",
                {
                    "agent": agent_id,
                    "agent_name": f"Writer: {agent_id.replace('_', ' ').title()}",
                    "status": "running",
                    "action": f"Writing ¬ß{section_id}: {title[:40]}...",
                    "icon": "‚úçÔ∏è",
                    "type": "chapter_generator"
                },
                session_id=self.state.session_id
            )

            await events.publish(
                self.state.job_id,
                "log",
                {"message": f"‚úçÔ∏è [{agent_id}] Writing section {section_id}: {title}..."},
                session_id=self.state.session_id
            )

            # Gather relevant papers for this section
            relevant_papers = []

            # For Chapter 2, use fresh citations from pool
            if section_id.startswith("2.") and hasattr(self.state, 'chapter2_citation_pool'):
                citations_needed = paragraphs * 4
                async with self._citation_lock:
                    fresh_citations = self.state.get_fresh_citations(citations_needed)
                relevant_papers = fresh_citations

                remaining = self.state.get_remaining_count()
                await events.publish(
                    self.state.job_id,
                    "log",
                    {"message": f"üìö Allocated {len(fresh_citations)} fresh citations to ¬ß{section_id} ({remaining} remaining in pool)"},
                    session_id=self.state.session_id
                )
            else:
                for scope in source_scopes:
                    relevant_papers.extend(self.state.research.get(scope, []))

            needs_citations = section_config.get("needs_citations", True)
            style = section_config.get("style", "synthesis")

            if needs_citations and relevant_papers:
                citation_context = self._build_citation_context(relevant_papers)
            else:
                citation_context = ""

            # Build prompt based on style
            if structure == "inverted_pyramid":
                prompt = self._build_pyramid_prompt(section_id, title, paragraphs, citation_context)
            elif style == "synthesis":
                prompt = self._build_synthesis_prompt(section_id, title, paragraphs, citation_context)
            elif style in ["objectives_intro", "objective", "objectives_list", "questions"]:
                prompt = self._build_objectives_prompt(section_id, title, style)
            elif style == "organization_6chapter":
                prompt = self._build_organization_prompt(section_id, title)
            elif style in ["limitations", "delimitations", "assumptions"]:
                prompt = self._build_scope_prompt(section_id, title, style)
            elif style == "definitions":
                prompt = self._build_definitions_prompt(section_id, title, citation_context)
            elif style == "general_intro":
                prompt = self._build_general_intro_prompt(section_id, title, citation_context)
            elif style == "general_background":
                prompt = self._build_general_background_prompt(section_id, title, citation_context)
            elif style == "problem_statement":
                prompt = self._build_problem_statement_gen_prompt(section_id, title, citation_context)
            elif style == "purpose_statement":
                prompt = self._build_purpose_statement_prompt(section_id, title)
            elif style == "objectives_list_smart":
                prompt = self._build_objectives_smart_prompt(section_id, title)
            elif style == "hypothesis":
                prompt = self._build_hypothesis_prompt(section_id, title)
            elif style == "significance":
                prompt = self._build_significance_prompt(section_id, title)
            elif style == "scope_detail":
                prompt = self._build_scope_detail_prompt(section_id, title)
            elif style == "limitations_future":
                prompt = self._build_limitations_future_prompt(section_id, title)
            elif style == "theoretical_framework_gen":
                prompt = self._build_theoretical_gen_prompt(section_id, title, citation_context)
            elif style == "conceptual_framework_gen":
                prompt = self._build_conceptual_gen_prompt(section_id, title, citation_context)
            elif style == "methodology_brief":
                prompt = self._build_methodology_brief_prompt(section_id, title)
            elif style == "definitions_gen":
                prompt = self._build_definitions_gen_prompt(section_id, title, citation_context)
            elif style == "organization_5chapter":
                prompt = self._build_organization_5chapter_prompt(section_id, title)
            elif style == "general_chapter2_intro":
                prompt = self._build_general_lit_intro_prompt(section_id, title)
            elif style == "general_theory_main":
                prompt = self._build_general_theory_main_prompt(section_id, title, citation_context)
            elif style == "general_theory_obj":
                obj_text = section_config.get("objective_text", "study objectives")
                prompt = self._build_general_theory_obj_prompt(section_id, title, obj_text, citation_context)
            elif style == "general_empirical":
                obj_text = section_config.get("objective_text", "")
                prompt = self._build_general_empirical_prompt(section_id, title, obj_text, citation_context)
            elif style == "general_lit_summary":
                prompt = self._build_general_lit_summary_prompt(section_id, title)
            elif style == "lit_intro":
                prompt = self._build_lit_intro_prompt(section_id, title)
            elif style == "empirical_intro":
                prompt = self._build_empirical_intro_prompt(section_id, title, citation_context)
            elif style == "framework_intro":
                prompt = self._build_framework_intro_prompt(section_id, title, citation_context)
            elif style == "theory_detailed":
                prompt = self._build_theory_detailed_prompt(section_id, title, citation_context, title)
            elif style == "theme_intro":
                objective_text = section_config.get("objective_text", "")
                prompt = self._build_theme_intro_prompt(section_id, title, title, objective_text)
            elif style == "lit_synthesis":
                objective_text = section_config.get("objective_text", "")
                prompt = self._build_lit_synthesis_prompt(section_id, title, citation_context, objective_text)
            elif style == "literature_gap":
                prompt = self._build_literature_gap_prompt(section_id, title, citation_context)
            elif style == "conceptual_framework":
                prompt = self._build_conceptual_framework_prompt(section_id, title, citation_context)
            elif style == "methodology_intro":
                prompt = self._build_methodology_intro_prompt(section_id, title)
            elif style == "research_philosophy":
                prompt = self._build_research_philosophy_prompt(section_id, title, citation_context)
            elif style == "research_design":
                prompt = self._build_research_design_prompt(section_id, title, citation_context)
            elif style == "target_population":
                prompt = self._build_target_population_prompt(section_id, title, citation_context)
            elif style in ["sampling_procedures", "sampling_design"]:
                prompt = self._build_sampling_procedures_prompt(section_id, title, citation_context)
            elif style == "sample_size":
                prompt = self._build_sample_size_prompt(section_id, title, citation_context)
            elif style == "data_instruments":
                prompt = self._build_data_instruments_prompt(section_id, title, citation_context)
            elif style == "data_sources":
                prompt = self._build_data_sources_prompt(section_id, title, citation_context)
            elif style == "primary_data_sources":
                prompt = self._build_primary_data_sources_prompt(section_id, title, citation_context)
            elif style == "secondary_data_sources":
                prompt = self._build_secondary_data_sources_prompt(section_id, title, citation_context)
            elif style == "validity_reliability":
                prompt = self._build_validity_reliability_prompt(section_id, title, citation_context)
            elif style == "data_procedures":
                prompt = self._build_data_procedures_prompt(section_id, title, citation_context)
            elif style == "data_analysis":
                prompt = self._build_data_analysis_prompt(section_id, title, citation_context)
            elif style == "ethical_considerations":
                prompt = self._build_ethical_considerations_prompt(section_id, title, citation_context)
            else:
                prompt = self._build_standard_prompt(section_id, title, paragraphs, citation_context)

            if self.state.chapter_number == 3:
                meth_ctx = self.state.parameters.get('methodology_context')
                if meth_ctx:
                    context_injection = "\n\n=== MANDATORY RESEARCH PARAMETERS (DO NOT DEVIATE) ===\n"
                    context_injection += f"TARGET POPULATION: {meth_ctx.get('population', {}).get('target_size', 'Use calculated value')}\n"
                    context_injection += f"POPULATION DESCRIPTION: {meth_ctx.get('population', {}).get('description', '')}\n"
                    context_injection += f"SAMPLE SIZE (n): {meth_ctx.get('sampling', {}).get('sample_size')} (You MUST use this exact number)\n"
                    context_injection += f"RESEARCH DESIGN: {meth_ctx.get('research_design', 'survey')}\n"
                    context_injection += f"SAMPLING TECHNIQUE: {meth_ctx.get('sampling', {}).get('technique', '')}\n"
                    context_injection += f"JUSTIFICATION: {meth_ctx.get('sampling', {}).get('justification', '')}\n"
                    preferred = meth_ctx.get('preferred_analyses', [])
                    if preferred:
                        context_injection += f"PREFERRED ANALYSES: {', '.join(preferred)}\n"
                    context_injection += "========================================================\n"
                    prompt += context_injection

            custom_instr = self.state.parameters.get('custom_instructions', '')
            if custom_instr:
                prompt = f"=== USER DIRECTION ===\n{custom_instr}\n====================\n\n" + prompt

            try:
                stagger = self._section_stagger_seconds * section_index
                if stagger:
                    await asyncio.sleep(stagger)

                content = None
                for attempt in range(3):
                    try:
                        async with self._llm_limiter:
                            content = await deepseek_direct_service.generate_content(
                                prompt=prompt,
                                system_prompt=self._get_system_prompt(),
                                temperature=0.7,
                                max_tokens=4000
                            )
                        if content:
                            self._llm_limiter.record_success()
                            break
                        self._llm_limiter.record_failure()
                    except Exception as retry_e:
                        self._llm_limiter.record_failure()
                        print(f"Attempt {attempt+1} failed for {section_id}: {retry_e}")
                        await asyncio.sleep(2 * (attempt + 1))

                if not content:
                    content = f"[Section {section_id} generation pending - will be completed in revision]"

                content = self._clean_generated_content(content)
                if relevant_papers:
                    content = self._link_citations_to_sources(content, relevant_papers)

                if '```' in content:
                    content = add_source_after_diagrams(content, title)

                word_count = len(content.split())

                results[section_id] = SectionContent(
                    title=title,
                    content=content,
                    citations=relevant_papers,
                    word_count=word_count,
                    status="completed"
                )

                if '```' in content:
                    diagram_type = None
                    content_upper = content.upper()

                    if style == "theory_detailed":
                        diagram_type = "theory_framework"
                    elif "RESEARCH ONION" in content_upper or "SAUNDERS" in content_upper or "CONCENTRIC" in content_upper:
                        diagram_type = "research_onion"
                    elif style == "research_philosophy" or "PHILOSOPHY" in title.upper() or ("ONTOLOGY" in content_upper and "EPISTEMOLOGY" in content_upper):
                        diagram_type = "research_philosophy_map"
                    elif style == "study_area" or "MAP" in content_upper:
                        diagram_type = "study_area_map"
                    elif "framework" in title.lower() or "conceptual" in content.lower():
                        diagram_type = "conceptual_framework"
                    else:
                        code_blocks = content.split('```')
                        for block in code_blocks[1::2]:
                            if any(char in block for char in ['|', '+', '-', '=', '/', '\\', '[', ']']) and len(block.split('\n')) > 3:
                                diagram_type = "generic_diagram"
                                break

                    if diagram_type:
                        print(f"üñºÔ∏è Generating {diagram_type} image for {section_id}")
                        try:
                            await self._generate_diagram_image(section_id, title, content, results, diagram_type)
                            print(f"‚úÖ Image generated successfully for {section_id}")
                        except Exception as img_e:
                            print(f"‚ùå Image generation failed for {section_id}: {img_e}")
                            import traceback
                            traceback.print_exc()

                await events.publish(
                    self.state.job_id,
                    "response_chunk",
                    {"chunk": f"\n\n## {section_id} {title}\n\n{results[section_id].content}\n", "accumulated": results[section_id].content},
                    session_id=self.state.session_id
                )

                await events.publish(
                    self.state.job_id,
                    "log",
                    {"message": f"‚úÖ [{agent_id}] Completed {section_id} ({word_count} words)"},
                    session_id=self.state.session_id
                )

                if hasattr(self.state, 'progress_callback') and self.state.progress_callback:
                    try:
                        await self.state.progress_callback(section_id, word_count)
                    except Exception as e:
                        print(f"Progress callback error: {e}")

            except Exception as e:
                print(f"‚ùå Error writing section {section_id}: {e}")
                import traceback
                traceback.print_exc()

                results[section_id] = SectionContent(
                    title=title,
                    content=f"Error generating content: {str(e)}",
                    citations=[],
                    status="failed"
                )

        async def run_with_gate(section_config: Dict[str, Any], section_index: int) -> None:
            async with per_agent_sem:
                await run_section(section_config, section_index)

        tasks = [
            run_with_gate(section_config, idx)
            for idx, section_config in enumerate(sections)
        ]
        await asyncio.gather(*tasks, return_exceptions=True)
        
        # Announce completion
        await events.publish(
            self.state.job_id,
            "agent_activity",
            {
                "agent": agent_id, 
                "agent_name": f"Writer: {agent_id.replace('_', ' ').title()}", 
                "status": "completed", 
                "action": f"Finished all assigned sections", 
                "icon": "‚úÖ",
                "type": "chapter_generator"
            },
            session_id=self.state.session_id
        )
        
        return results


    def _clean_generated_content(self, content: str) -> str:
        """Strip metadata, command parameters, and prompt leaks from content."""
        if not content:
            return ""
            
        lines = content.split('\n')
        cleaned_lines = []
        
        # Regex patterns to identify metadata lines
        metadata_patterns = [
            r'^n\s*=\s*\d+',              # n=120
            r'^topic\s*=',                # topic=...
            r'^case[_\s]?study\s*=',      # case_study=...
            r'^/uoj_phd',                 # /uoj_phd
            r'^design\s*=',               # design=...
            r'^TOPIC:',                   # TOPIC: Security...
            r'^CASE STUDY:',              # CASE STUDY: Juba...
            r'^STUDY OBJECTIVES:',        # STUDY OBJECTIVES:
            r'^OBJECTIVES:',
            r'^METHODOLOGY CONTEXT:',     # Context injection headers
            r'^TARGET POPULATION:',
            r'^SAMPLE SIZE \(n\):',
            r'^SAMPLING TECHNIQUE:',
            r'^=== MANDATORY',            # Separators
            r'^================',
            r'^2\.2 Prevalence Characteristics' # specific user complaint
        ]
        
        # Compile patterns
        import re
        patterns = [re.compile(p, re.IGNORECASE) for p in metadata_patterns]
        
        for line in lines:
            line_str = line.strip()
            # Skip empty lines at start
            if not cleaned_lines and not line_str:
                continue
                
            # Check if line matches any metadata pattern
            is_metadata = False
            # Only check "short" lines which are likely metadata headers (less than 150 chars)
            if len(line_str) < 150: 
                for p in patterns:
                    if p.search(line_str):
                        is_metadata = True
                        break
            
            if not is_metadata:
                cleaned_lines.append(line)
        
        return "\n".join(cleaned_lines).strip()

    def _link_citations_to_sources(self, content: str, papers: List[ResearchResult]) -> str:
        """Attach source URLs to in-text citations when possible."""
        if not content or not papers:
            return content

        import re

        url_map = {}
        for paper in papers:
            if not paper.authors:
                continue
            if paper.url and paper.url.startswith("http"):
                url = paper.url
            elif paper.doi:
                url = f"https://doi.org/{paper.doi}"
            else:
                continue

            first_author = paper.authors[0]
            if isinstance(first_author, dict):
                name = first_author.get("name", first_author.get("family", ""))
            else:
                name = str(first_author)
            if not name:
                continue

            last_name = name.split(",")[0].strip() if "," in name else name.split()[-1]
            year = str(paper.year)
            if last_name and year:
                url_map[f"{last_name.lower()}:{year}"] = url

        if not url_map:
            return content

        def link_part(part: str) -> str:
            if "](" in part:
                return part
            match = re.search(r"([A-Za-z][A-Za-z-']+)(?:\s+et al\.)?(?:\s*&\s+[A-Za-z][A-Za-z-']+)?\s*,\s*(\d{4})", part)
            if not match:
                return part
            last = match.group(1)
            year = match.group(2)
            url = url_map.get(f"{last.lower()}:{year}")
            if not url:
                return part
            return part.replace(match.group(0), f"[{match.group(0)}]({url})", 1)

        def replace_group(match: re.Match) -> str:
            inner = match.group(1)
            if "](" in inner:
                return match.group(0)
            parts = [p.strip() for p in inner.split(";")]
            linked_parts = [link_part(p) for p in parts]
            return "(" + "; ".join(linked_parts) + ")"

        content = re.sub(r"\(([^()]*\d{4}[^()]*)\)", replace_group, content)

        def replace_narrative(match: re.Match) -> str:
            name = match.group(1)
            year = match.group(2)
            key_match = re.search(r"([A-Za-z][A-Za-z-']+)", name)
            if not key_match:
                return match.group(0)
            last = key_match.group(1)
            url = url_map.get(f"{last.lower()}:{year}")
            if not url:
                return match.group(0)
            return f"[{name} ({year})]({url})"

        content = re.sub(r"(?<!\[)(\b[A-Z][A-Za-z-']+(?:\s+(?:&|and)\s+[A-Z][A-Za-z-']+|\s+et al\.)?)\s*\((\d{4})\)", replace_narrative, content)

        return content



    
    async def _generate_diagram_image(self, section_id: str, title: str, content: str, results: Dict, diagram_type: str = "generic"):
        """Generate high-quality academic diagram image for ANY type using DALL-E.
        
        Supports:
        - theory_framework: Theoretical/conceptual frameworks
        - research_onion: Saunders Research Onion
        - conceptual_framework: Study-specific frameworks
        - generic_diagram: Any ASCII diagram
        """
        from services.image_generation import image_generation_service
        from services.workspace_service import WORKSPACES_DIR
        import httpx
        import re
        import os
        
        # Extract components from ASCII diagram in content
        components = []
        diagram_text = ""
        lines = content.split('\n')
        
        # Find code block with diagram
        in_code_block = False
        for line in lines:
            if '```' in line:
                in_code_block = not in_code_block
                continue
            if in_code_block:
                diagram_text += line + "\n"
                # Extract text components from various diagram formats
                # Box patterns: |text|, [text], (text)
                box_texts = re.findall(r'\|\s*([^|]+?)\s*\|', line)
                bracket_texts = re.findall(r'\[\s*([^\]]+?)\s*\]', line)
                paren_texts = re.findall(r'\(\s*([^\)]+?)\s*\)', line)
                # Also extract from arrow patterns: -> Text
                arrow_texts = re.findall(r'->\s*([A-Za-z][A-Za-z\s]+?)(?:\n|$)', line)
                components.extend(box_texts + bracket_texts + paren_texts + arrow_texts)
        
        components = [c.strip() for c in components if c.strip() and len(c.strip()) > 2]
        components = list(dict.fromkeys(components))[:8]  # Max 8 unique components
        
        # For research onion, we may have layer descriptions instead of boxed components
        if diagram_type == "research_onion" and len(components) < 2:
            # Extract Layer patterns: Layer N: Name -> Value
            layer_matches = re.findall(r'Layer\s*\d+:\s*(\w+)\s*->\s*(\w+)', content)
            for layer_name, layer_value in layer_matches:
                components.append(f"{layer_name}: {layer_value}")
        
        if not components or len(components) < 2:
            print(f"‚ö†Ô∏è Insufficient diagram components ({len(components)}) for {section_id} - skipping image generation")
            return  # Need at least 2 components
        
        component_list = ", ".join(components[:6])  # Use top 6 for description
        
        # Build high-quality DALL-E prompt based on diagram type
        # Academic Saunders Research Onion style
        if diagram_type == "research_onion" or diagram_type == "research_methodology":
            image_prompt = f"""Create a professional SAUNDERS RESEARCH ONION diagram for academic PhD thesis:

DESIGN: Six concentric oval/ellipse layers (like an onion cross-section):

OUTERMOST LAYER: "Research Philosophy" - Positivism, Realism, Interpretivism, Pragmatism
LAYER 2: "Research Approach" - Deductive, Inductive, Abductive  
LAYER 3: "Methodological Choice" - Mono method, Multi-method, Mixed method
LAYER 4: "Research Strategy" - Survey, Case Study, Experiment, Ethnography, Action Research
LAYER 5: "Time Horizon" - Cross-sectional, Longitudinal
INNERMOST: "Data Collection and Analysis" - Techniques and Procedures

Study-specific choices: {component_list}

STYLE:
- Classic concentric ellipses/ovals (research onion shape)
- Light blue/teal color gradient
- White background
- Clear BLACK text labels
- Labels on RIGHT side with dotted lines pointing to layers
- Title: "Saunders' Research Onion"
- Professional academic publication quality
- Similar to Saunders et al. textbook diagram

Format: Academic flowchart diagram for doctoral dissertation"""

        elif diagram_type == "research_philosophy_map":
            image_prompt = f"""Create a professional ACADEMIC Research Philosophy MAP diagram for PhD thesis:

DESIGN: Hierarchical tree/mind-map structure showing philosophical assumptions:

TOP LEVEL: "Research Philosophy" (main heading)

FOUR MAIN BRANCHES (each in a distinct box):
1. ONTOLOGY - "Nature of Reality"
   Sub-branches: Objectivism, Constructivism, Pragmatism

2. EPISTEMOLOGY - "Nature of Knowledge" 
   Sub-branches: Positivism, Interpretivism, Critical Realism, Pragmatism

3. AXIOLOGY - "Role of Values"
   Sub-branches: Value-free, Value-bound

4. METHODOLOGY - "Research Process"
   Sub-branches: Quantitative, Qualitative, Mixed Methods

Study-specific focus: {component_list}

STYLE:
- Hierarchical tree structure flowing TOP to BOTTOM
- Main philosophy box at top center
- Four main branches spreading downward
- Sub-branches underneath each main branch
- Clean professional blue/gray boxes
- White background, BLACK text
- Connecting lines between hierarchy levels
- Title: "Research Philosophy Framework"
- Professional PhD thesis publication quality
- Similar to academic methodology textbooks

Format: Academic diagram for doctoral dissertation Chapter 3"""

        elif diagram_type == "theory_framework":
            image_prompt = f"""Create a professional academic HORIZONTAL theoretical framework diagram:

Theory Components: {component_list}

LAYOUT: Horizontal flowchart with boxes and connecting arrows

Style Requirements:
- HORIZONTAL flowchart layout (left to right)
- Clean PhD thesis quality
- White background, black text
- Rounded rectangle boxes for concepts
- Clear directional arrows showing relationships
- Academic journal publication quality
- Professional blue/gray color palette
- High contrast, very readable
- No decorative elements

Format: Suitable for doctoral dissertation Chapter 2"""

        elif diagram_type == "conceptual_framework":
            image_prompt = f"""Create a professional HORIZONTAL conceptual framework diagram for PhD research:

Components: {component_list}

LAYOUT: 
- Independent Variables on LEFT side in boxes
- Arrows pointing RIGHT showing relationships
- Dependent Variable(s) on RIGHT side
- Clear hypothesis paths labeled H1, H2, H3 etc.

Style: Horizontal flowchart, clean white background, professional blue boxes, black text, academic publication quality."""

        else:  # Generic diagram
            image_prompt = f"""Create a professional academic HORIZONTAL flowchart diagram:

Key components: {', '.join(components[:8])}

Style: Horizontal layout with boxes and arrows, left to right flow, clean professional look, white background, suitable for PhD thesis."""
        
        print(f"üìù Image Generation Prompt: {image_prompt[:200]}...")
        
        # Generate image using the image generation service (supports DALL-E, Gemini, etc.)
        try:
            # Use DALL-E specifically for academic diagrams (better quality for text)
            result = await image_generation_service.generate(
                prompt=image_prompt,
                size="1024x1024",
                model="dalle"  # Force DALL-E for better text rendering in diagrams
            )
            
            if not result.get("success"):
                print(f"‚ö†Ô∏è Image generation failed: {result.get('error')}")
                return
            
            image_url = result.get("url") or result.get("image_url")
            if not image_url:
                print(f"‚ö†Ô∏è No image URL in result: {result}")
                return
                
            print(f"‚úÖ Image generated: {image_url[:100]}...")
            
            # Download and save image
            async with httpx.AsyncClient(timeout=60.0) as client:
                image_response = await client.get(image_url)
                image_response.raise_for_status()
                image_data = image_response.content
            
            # Save to workspace
            image_filename = f"{section_id.replace('.', '_')}_{diagram_type}.png"
            workspace_path = WORKSPACES_DIR / self.state.workspace_id / "images"
            os.makedirs(workspace_path, exist_ok=True)
            image_path = workspace_path / image_filename
            
            with open(image_path, 'wb') as f:
                f.write(image_data)
            
            print(f"üíæ Image saved: {image_path}")
            
            # Replace ASCII diagram with image in content
            if section_id in results:
                old_content = results[section_id].content
                
                # Find and extract caption
                caption_match = re.search(r'Caption:\s*(.+?)(?:\n|Source:)', old_content, re.IGNORECASE)
                caption = caption_match.group(1).strip() if caption_match else f"{title} Framework"
                
                # Find and extract source
                source_match = re.search(r'Source:\s*(.+?)(?:\n|```|$)', old_content, re.IGNORECASE | re.MULTILINE)
                source = source_match.group(1).strip() if source_match else "Researcher Conceptualization"
                
                # Replace code block with image
                new_content = re.sub(
                    r'```[\s\S]*?```',
                    f'\n\n![{caption}](images/{image_filename})\n\n**Figure:** *{caption}*  \n**Source:** *{source}*\n\n',
                    old_content,
                    count=1
                )
                
                results[section_id] = SectionContent(
                    title=results[section_id].title,
                    content=new_content,
                    citations=results[section_id].citations,
                    word_count=len(new_content.split()),
                    status="completed"
                )
                
                print(f"‚úÖ Content updated with image for {section_id}")

                await events.publish(
                    self.state.job_id,
                    "log",
                    {"message": f"üñºÔ∏è Generated {diagram_type} image for {section_id}"},
                    session_id=self.state.session_id
                )
                
                print(f"‚úÖ Successfully generated and inserted {diagram_type} image: {image_filename}")
                
        except Exception as e:
            print(f"Diagram image generation failed for {section_id}: {e}")
            import traceback
            traceback.print_exc()
            # Keep ASCII diagram if image generation fails
    
    def _build_citation_context(self, papers: List[ResearchResult]) -> str:
        """Build citation context for LLM with actual URLs."""
        if not papers and not getattr(self.state, 'uploaded_sources_context', None):
            return "No approved sources provided. Do not add citations; explicitly state that evidence is limited."
        
        
        context = ""
        
        # Add uploaded sources first (Priority)
        if hasattr(self.state, 'uploaded_sources_context') and self.state.uploaded_sources_context:
            context += """
USER UPLOADED DOCUMENTS (PRIORITY CONTEXT):
The user has provided the following documents. You MUST use information from these documents where relevant.
-------------------------------------------------------------------
"""
            context += self.state.uploaded_sources_context
            context += "\n-------------------------------------------------------------------\n\n"

        context += """APPROVED CITATION SOURCES:
Do NOT cite any author or paper not on this list. If Twenge, Valkenburg, Keles, Odgers, Best, or any other author is NOT on this list, DO NOT CITE THEM.

APPROVED SOURCE LIST (cite ONLY from this list or uploaded docs):

"""
        # Filter clean papers
        clean_papers = []
        seen_keys = set()
        for p in papers:
            # Check for valid authors
            if not p.authors:
                continue
            
            first_author = str(p.authors[0])
            if any(bad in first_author.lower() for bad in ["unknown", "anonymous", "n/a", "undefined"]):
                continue
            identifier = p.doi or p.title
            if not identifier:
                continue
            key = str(identifier).strip().lower()
            if key in seen_keys:
                continue
            seen_keys.add(key)
            clean_papers.append(p)
            
        for i, paper in enumerate(clean_papers[:30]):  # Limit to 30 papers for broader coverage
            # Get the actual URL for this paper
            if paper.url and paper.url.startswith("http"):
                url = paper.url
            elif paper.doi:
                url = f"https://doi.org/{paper.doi}"
            else:
                url = ""  # No URL available
            
            context += f"{i+1}. {paper.to_apa()} - \"{paper.title}\"\n"
            # Increased truncation from 200 to 1200 for deeper grounding
            if paper.abstract:
                context += f"   Abstract: {paper.abstract[:1200]}...\n"
            else:
                context += "   Abstract: [Not available]\n"
            if url:
                context += f"   URL for citation: {url}\n\n"
            else:
                context += f"   (No URL available - cite as plain text, do not invent a link)\n\n"
        
        context += "\n‚ö†Ô∏è END OF APPROVED SOURCES. Any citation not from this list is PROHIBITED.\n"
        return context
    
    def _build_pyramid_prompt(self, section_id: str, title: str, paragraphs: int, citation_context: str) -> str:
        """Build prompt for background section based on selected style."""
        # Get the selected style from state
        style = self.state.background_style if hasattr(self.state, 'background_style') else "inverted_pyramid"
        style_config = BACKGROUND_STYLES.get(style, BACKGROUND_STYLES["inverted_pyramid"])
        
        # Build structure instructions based on style
        if style == "inverted_pyramid":
            structure = f"""STRUCTURE (INVERTED PYRAMID - write in this order):
1. GLOBAL CONTEXT (2-3 paragraphs): Worldwide perspective on the topic
2. CONTINENTAL CONTEXT (2 paragraphs): African perspective  
3. REGIONAL CONTEXT (1-2 paragraphs): East African perspective
4. NATIONAL CONTEXT (2 paragraphs): Uganda-specific context
5. LOCAL CONTEXT (1-2 paragraphs): Specific to {self.state.case_study}"""

        elif style == "component_based":
            structure = """STRUCTURE (COMPONENT-BASED - write in this order):
1. HISTORICAL BACKGROUND (2-3 paragraphs): Origins and evolution of the issue
2. THEORETICAL BACKGROUND (2-3 paragraphs): Key theories supporting the topic
3. CONCEPTUAL BACKGROUND (2 paragraphs): Key concepts, models, definitions
4. CONTEXTUAL BACKGROUND (2-3 paragraphs): The specific setting of your study"""

        elif style == "thematic":
            structure = f"""STRUCTURE (THEMATIC - organized by key themes):
1. THEME: Social Media Usage Patterns (2-3 paragraphs)
2. THEME: Mental Health Indicators (2-3 paragraphs)
3. THEME: Youth Vulnerability Factors (2-3 paragraphs)
4. THEME: Intervention Approaches (2 paragraphs)
5. SYNTHESIS: How themes connect to {self.state.case_study} (1-2 paragraphs)"""

        elif style == "chronological":
            structure = """STRUCTURE (CHRONOLOGICAL - past to present):
1. ORIGINS (2 paragraphs): Early development of the issue
2. EVOLUTION (2-3 paragraphs): Major changes and milestones over time
3. CURRENT STATE (2-3 paragraphs): Present-day trends and findings
4. EMERGING GAPS (2 paragraphs): What is still missing and needs investigation"""

        elif style == "problem_driven":
            structure = f"""STRUCTURE (PROBLEM-DRIVEN - symptoms to causes):
1. OBSERVED SITUATION (2 paragraphs): What is currently observed
2. SYMPTOMS/CHALLENGES (2-3 paragraphs): Visible problems and challenges
3. CAUSES/CONTRIBUTING FACTORS (2-3 paragraphs): Underlying reasons
4. CORE PROBLEM (1-2 paragraphs): The central issue
5. NEED FOR INVESTIGATION (1 paragraph): Why study this in {self.state.case_study}"""

        elif style == "funnel":
            structure = """STRUCTURE (FUNNEL - broad to narrow gap):
1. BROAD TOPIC DESCRIPTION (2-3 paragraphs): General overview of the topic area
2. EXISTING FINDINGS (2-3 paragraphs): What research has established
3. DEBATES/CONTRADICTIONS (2 paragraphs): Conflicting findings or perspectives
4. RESEARCH GAP (2 paragraphs): The specific gap this study addresses"""

        elif style == "gap_oriented":
            structure = f"""STRUCTURE (GAP-ORIENTED - direct gap identification):
1. WHAT IS KNOWN (3-4 paragraphs): Established findings in the field
2. WHAT IS NOT KNOWN (2-3 paragraphs): Gaps in current knowledge
3. WHY THE GAP MATTERS (1-2 paragraphs): Significance and implications
4. HOW THIS STUDY FILLS THE GAP (1 paragraph): Contribution of {self.state.case_study}"""

        elif style == "variable_based":
            structure = f"""STRUCTURE (VARIABLE-BASED - by study variables):
1. INDEPENDENT VARIABLE(S) (3-4 paragraphs): Background on {self.state.topic.split()[0]}
2. DEPENDENT VARIABLE (2-3 paragraphs): Mental health outcomes in literature
3. MODERATING/MEDIATING VARIABLES (2 paragraphs): Factors that influence the relationship
4. VARIABLE INTERACTIONS (1-2 paragraphs): How variables connect in {self.state.case_study}"""

        elif style == "policy_context":
            structure = f"""STRUCTURE (POLICY-CONTEXT - policy framework):
1. GLOBAL POLICIES (2-3 paragraphs): International frameworks and guidelines
2. REGIONAL POLICIES (2 paragraphs): Continental/regional frameworks
3. NATIONAL POLICIES (2-3 paragraphs): Country-level policies and laws
4. POLICY GAPS/IMPLEMENTATION CHALLENGES (2 paragraphs): Issues in {self.state.case_study}"""

        elif style == "multilevel_system":
            structure = f"""STRUCTURE (MULTILEVEL ECOLOGICAL SYSTEM):
1. INDIVIDUAL LEVEL (2-3 paragraphs): Personal factors affecting the issue
2. INTERPERSONAL LEVEL (2 paragraphs): Family, peer, and relationship factors
3. COMMUNITY LEVEL (2-3 paragraphs): School, neighborhood, community factors
4. SOCIETAL LEVEL (2 paragraphs): Cultural, policy, and systemic factors in {self.state.case_study}"""
        
        else:
            structure = f"""STRUCTURE (INVERTED PYRAMID - default):
1. GLOBAL CONTEXT (2-3 paragraphs): Worldwide perspective
2. CONTINENTAL CONTEXT (2 paragraphs): African perspective
3. REGIONAL CONTEXT (1-2 paragraphs): East African perspective
4. NATIONAL CONTEXT (2 paragraphs): Uganda-specific context
5. LOCAL CONTEXT (1-2 paragraphs): Specific to {self.state.case_study}"""

        sentence_level_citations = ""
        if section_id == "1.2":
            sentence_level_citations = """
SENTENCE-LEVEL CITATION REQUIREMENT (MANDATORY FOR THIS SECTION):
- Each sentence MUST end with its own in-text citation.
- Do NOT place citations only at paragraph end.
- Use 1‚Äì2 citations per sentence from the approved list; vary sources across sentences.
"""

        return f"""Write section "{section_id} {title}" for a thesis chapter.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}
BACKGROUND STYLE: {style_config['name']}

{structure}

{citation_context}
{sentence_level_citations}

5-STEP SYNTHESIS PROCESS FOR EACH PARAGRAPH:
1. Start with a THEMATIC SENTENCE stating the specific finding
2. Detail the ANCHOR STUDY: Author (Year), methodology (N=, method type), specific findings (statistics if available)
3. Provide CRITICAL ANALYSIS: implications, then identify the GAP in your own words
4. Include SUPPORTING/CONTRASTING studies to synthesize the evidence (MINIMUM 2-4 additional sources)
5. End with GROUPED CITATIONS: [(Author1, Year; Author2, Year; Author3, Year)](URL)

CRITICAL REQUIREMENTS:
- Write {paragraphs} detailed paragraphs (7-10 sentences each) following 5-step synthesis
- MANDATORY: Minimum 3-5 citations per paragraph - high density required
- Do NOT reuse the same study in adjacent sentences; rotate sources within each paragraph
- Avoid citing the same author-year pair more than once in a paragraph unless absolutely necessary
- Include methodology and statistics when available from abstracts
- APA 7 STRICT: In-text (Author, Year), grouped at end [(Author1, Year; Author2, Year)](URL)
- Do NOT include the section heading
- Do NOT hallucinate citations - only use sources from the approved list above

Write the section content now (without any heading):"""

    def _build_theme_prompt(self, section_id: str, title: str, paragraphs: int, citation_context: str) -> str:
        """Build thematic literature section with UK English."""
        return f"""Write section "{section_id} {title}" - thematic literature synthesis.

**LANGUAGE REQUIREMENTS:**
- UK English spelling (analyse, organisation, whilst, amongst, realise, synthesise, criticise)
- Formal academic register
- Critical analytical tone
- Scholarly synthesis chapter.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

{citation_context}

Write {paragraphs} detailed paragraphs. Each paragraph MUST follow this EXACT 5-STEP FORMAT:

**STEP 1: Thematic Sentence**
Start with a clear topic sentence stating the specific finding or debate.

**STEP 2: Anchor Study with Full Details**
"A study by [Author] (Year) investigated [topic] in [context]. The study employed a [quantitative/qualitative/mixed] methodology with N=[sample size]. Using [specific method: OLS regression, thematic analysis, etc.]..."

**STEP 3: Statistical/Qualitative Findings**
Present ALL relevant results:
- For quantitative: "Descriptive statistics showed X% of respondents... The regression was significant (p < 0.05) with Œ≤ = 0.34, R¬≤ = 0.42..."
- For qualitative: "Three major themes emerged: (1)..., (2)..., (3)... Participants described..."
- Include effect sizes, confidence intervals, p-values when available

**STEP 4: Critical Analysis & Gap (in YOUR words as researcher)**
"The findings from [Author] (Year) provide strong evidence for... However, this study focus on [context] limits applicability to [my context]. The methodological choice of [X] means that [limitation]. This creates a gap for research examining..."

**STEP 5: Contrasting/Supporting Studies + Grouped Citation**
"This finding is supported by [Author2] (Year), who found... In contrast, [Author3] (Year) in [different context] suggested... (Author1, Year; Author2, Year; Author3, Year)"

CRITICAL RULES:
- Every paragraph needs MINIMUM 3 different citations
- Include methodology (N, method type) for EVERY study mentioned
- Include statistical results (p-values, Œ≤, r, %) where available
- Gap analysis must be in YOUR words, not quoting abstract
- End each paragraph with grouped citation: (Author1, Year; Author2, Year; Author3, Year)

Do NOT include the heading.
Just write the content:"""

    def _build_standard_prompt(self, section_id: str, title: str, paragraphs: int, citation_context: str) -> str:
        """Build standard section prompt."""
        return f"""Write section "{section_id} {title}" for a thesis chapter.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

{citation_context}

CRITICAL CITATION REQUIREMENTS:
- Write {paragraphs} well-developed paragraphs (6-8 sentences minimum)
- MANDATORY: Each paragraph MUST contain MINIMUM 3-5 citations - high citation density required
- APA 7 FORMAT (STRICT):
  * In-text: (Author, Year) or Author (Year) for narrative citations
  * With URL: [(Author, Year)](URL) - always use actual URLs from approved sources
  * Multiple authors: [(Author1, Year; Author2, Year; Author3, Year)](URL)
  * Do NOT use made-up citations - ONLY use sources from the approved list
- Example: "Social media affects mental health [(Smith, 2020; Jones, 2021)](https://doi.org/10.1234/example)."
- Academic formal tone, specific and substantive
- Do NOT include the section heading/title - just write content

Write the section content now (without any heading):"""

    def _build_synthesis_prompt(self, section_id: str, title: str, paragraphs: int, citation_context: str) -> str:
        """Build prompt for 5-step research synthesis with methodology and statistics."""
        sentence_level_citations = ""
        if section_id in {"1.2", "1.3"}:
            sentence_level_citations = """
SENTENCE-LEVEL CITATION REQUIREMENT (MANDATORY FOR THIS SECTION):
- Each sentence MUST end with its own in-text citation.
- Do NOT place citations only at paragraph end.
- Use 1‚Äì2 citations per sentence from the approved list; vary sources across sentences.
"""
        return f"""Write section "{section_id} {title}" for a thesis chapter using the 5-STEP SYNTHESIS format.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

{citation_context}
{sentence_level_citations}

FOR EACH PARAGRAPH, FOLLOW THIS 5-STEP PROCESS:

1. **THEMATIC SENTENCE**: Start with a clear topic sentence stating the specific finding or debate.

2. **ANCHOR STUDY DETAILS**: 
   - Introduce: "A study by Author (Year) investigated..."
   - Methodology: State the method clearly (quantitative/qualitative, N=sample size, specific method like regression, survey, interviews)
   - Findings: Include SPECIFIC results - descriptive statistics (percentages, means), regression results (Œ≤, p-values), or qualitative themes

3. **CRITICAL ANALYSIS & GAP**: 
   - State the implication: "The findings provide evidence that..."
   - Identify the gap IN YOUR OWN WORDS: "However, this study focus on X context limits applicability to Y..."

4. **CONTRASTING/SUPPORTING STUDIES** (MINIMUM 2-3 additional sources): 
   - "This aligns with Author2 (Year) who found..."
   - "Similarly, Author3 (Year) reported..."
   - "In contrast, Author4 (Year) suggested..."

5. **CITATIONS (APA 7)**:
   - Default: End paragraph with grouped citations: [(Author1, Year; Author2, Year; Author3, Year; Author4, Year)](URL)
   - If the sentence-level requirement is active, each sentence MUST carry its own citation instead of a single grouped paragraph-end citation.

CRITICAL REQUIREMENTS:
- Write {paragraphs} detailed paragraphs (8-10 sentences each)
- MANDATORY: Minimum 4-5 citations per paragraph for high density
- Do NOT reuse the same study in adjacent sentences; rotate sources within each paragraph
- Avoid citing the same author-year pair more than once in a paragraph unless absolutely necessary
- Include methodology details (sample size, method type) when available from abstracts
- Include statistical findings if mentioned in abstracts
- APA 7 STRICT: (Author, Year) in-text, grouped [(Author1, Year; Author2, Year)](URL) at end
- Do NOT include the section heading
- Use ONLY sources from the approved list above - NO fabricated citations.
- If a specific methodology (e.g., sample size, specific statistical test) or numeric result is not present in the provided abstract, DO NOT invent one. Focus on the reported findings and theoretical implications instead.
- Hallucinating specific data points not present in the source is a SEVERE violation of academic integrity.

Write the section content now (without any heading):"""

    # -------------------------------------------------------------------------
    # GENERAL THESIS PROMPT BUILDERS (User Custom)
    # -------------------------------------------------------------------------
    
    def _build_general_intro_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        return f"""Write a brief Introduction about {self.state.topic} in {self.state.parameters.get('country', 'South Sudan')} and specifically in {self.state.case_study} with enough in-text citations. Make about three paragraphs for this Introduction and conclude the fourth paragraph outlining the outline of chapter one ie saying due to the above introduction, chapter one of this study will focus on historical background, problem statement, purpose of the study, objectives of the study outlining the general and specific objectives, research questions and hypothesis, significance of the study, scope of the study, brief methodology of the study, anticipated limitations and delimitation, assumptions of the study, definition of key terms, and summary of chapter one. NOTE THAT THE CURRENT YEAR WE ARE IN IS 2026 and citations need to be between June of 2020 to June of 2026 and in APA style.

Use ONLY sources from the CITATION CONTEXT below. If the approved sources do not cover a sub-topic, explicitly state that evidence is limited and do not invent citations. Do not fabricate authors or studies. Avoid placeholder or generic names (e.g., Smith, Johnson, Lee) unless they appear in the approved source list. Use UK English spelling. Ensure citations are in APA 7 format using LAST NAMES ONLY so that links can be attached (e.g., (Author, 2023)). If local sources exist in the context, use them for local content; if not, note the limitation.

dont bullet or number, dont sub headings, present in big detailed paragraphs in academic tone. never say we, say the study, or the reseacher. Annd be brief.

CITATION CONTEXT:
{citation_context}
"""

    def _build_general_background_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        country = self.state.parameters.get('country', 'South Sudan')
        return f"""Write a historical Background of the study about {self.state.topic} in multiple SINGLE paragraphs (no subheadings, no bullets). Use strong academic tone, UK English, and avoid "we". Use ONLY sources from the CITATION CONTEXT below. If a region is not covered by approved sources, state that evidence is limited and do not invent citations. Do not fabricate authors or studies. Avoid placeholder or generic names (e.g., Smith, Johnson, Lee) unless they appear in the approved source list. Use author‚Äìdate citations in parentheses (e.g., (Surname, 2023) or (Surname et al., 2024)). Avoid two-author formats; use single surname or et al. Use only LAST NAMES so hyperlinks can be attached.

GLOBAL SECTION (five single paragraphs):
1) One paragraph giving a global historical overview of {self.state.topic}.
2) One paragraph covering the Americas (mention sample countries/states).
3) One paragraph covering Asia (mention sample countries/states).
4) One paragraph covering Australia/Oceania (mention sample countries/states).
5) One paragraph covering Europe (mention sample countries/states).

AFRICAN SECTION (five single paragraphs):
6) One paragraph giving an Africa-wide historical overview of {self.state.topic}.
7) One paragraph covering North Africa/Arab African countries (e.g., Egypt, Libya, Tunisia, Morocco, Sudan) using only approved sources.
8) One paragraph covering Southern Africa.
9) One paragraph covering Central Africa.
10) One paragraph covering West Africa.

EAST AFRICA SECTION (two single paragraphs):
11) One paragraph giving an East African overview.
12) One paragraph mentioning sample districts/villages/places in East African countries, and include local place names where sources allow.

COUNTRY + LOCAL SECTION (two single paragraphs):
13) One paragraph giving a {country}-level historical background with local place names where sources allow.
14) One paragraph giving the past-to-present situation of {self.state.topic} in {self.state.case_study}, then conclude that it is upon the above background that this study aims to examine {self.state.topic} in {self.state.case_study}, {country}.

NOTE: The current year is 2026; use sources dated June 2020 to June 2026 where available in the approved list.

CITATION CONTEXT:
{citation_context}
"""

    def _build_problem_statement_gen_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        country = self.state.parameters.get('country', 'South Sudan')
        return f"""Write a standard problem statement for the study about {self.state.topic} in {self.state.case_study}, {country}. Use UK English and an academic tone. Do not use bullets or headings. Never say "we".

Organise each paragraph to cover: the current nature of the problem, the population affected, the magnitude supported by data, effects on individuals/communities/service providers, plausible contributing factors, and attempts to solve the problem including gaps. If evidence is missing, explicitly state the gap.

Use ONLY sources from the CITATION CONTEXT below. Do not fabricate studies or authors. Avoid placeholder names (e.g., Smith, Johnson, Lee) unless they appear in the approved source list. Use author‚Äìdate citations in parentheses (e.g., (Surname, 2023) or (Surname et al., 2024)) so links can be attached. Avoid two-author formats.

CITATION CONTEXT:
{citation_context}
"""

    def _build_purpose_statement_prompt(self, section_id: str, title: str) -> str:
        country = self.state.parameters.get('country', 'South Sudan')
        return f"""Write the purpose of the study about {self.state.topic} in {self.state.case_study}, {country}. Let it be precise and very summarized. Only the purpose of the study don't add anything else and write in academic and professional tone. Be brief."""

    def _build_objectives_smart_prompt(self, section_id: str, title: str) -> str:
        objective_list = self._get_objective_list(max_items=10)
        if objective_list:
            formatted = "\n".join([f"{idx + 1}. {obj}" for idx, obj in enumerate(objective_list)])
            return f"""Use the specific objectives exactly as provided.
{uk_english_note}
SPECIFIC OBJECTIVES:
{formatted}

Return ONLY the numbered objectives list, preserving the wording."""
        return f"""List THREE SMART specific objectives about {self.state.topic} in {self.state.case_study}.
{uk_english_note}

Rules:
- Write each objective on its OWN line.
- Use numbered formatting: 1., 2., 3.
- Keep each objective short and precise (one sentence each).
- Do NOT write a paragraph.
- Do NOT include time frames.
- The last two objectives must focus on challenges and solutions, respectively.

Return ONLY the numbered objectives list."""

    def _build_hypothesis_prompt(self, section_id: str, title: str) -> str:
        return f"""Convert the objectives into hypothesis statements from H1,H01 to H4,H04 based on {self.state.topic}."""

    def _build_significance_prompt(self, section_id: str, title: str) -> str:
        country = self.state.parameters.get('country', 'South Sudan')
        return f"""State the Significance of the study about {self.state.topic} in {country} and {self.state.case_study}.
        State the Beneficiary: Then state the Significance ....."""

    def _build_scope_detail_prompt(self, section_id: str, title: str) -> str:
        country = self.state.parameters.get('country', 'South Sudan')
        return f"""State the Scope of the study about {self.state.topic} in {self.state.case_study}, {country} in terms of content, Time and geographical scopes. 
        In Each scope write it in detail way. 
        In Geographical scope, write the geography of the place, its longitude and latitude, its directions and neigbouring places/villages/Payams/Bomas/Distincts. 
        In time scope, note that we are in 2025 and studies take three months period.
        Don‚Äôt bullet or number."""

    def _build_limitations_future_prompt(self, section_id: str, title: str) -> str:
        country = self.state.parameters.get('country', 'South Sudan')
        return f"""State the Limitations of the Study about {self.state.topic} in {self.state.case_study}, {country}. Explain each of them in details and talk in future tense. in Each, tell us how you could mitigate it in few sentence(s).
        Make like 4 to 7 limitations."""
        
    def _build_delimitations_prompt_gen(self, section_id: str, title: str) -> str:
        country = self.state.parameters.get('country', 'South Sudan')
        return f"""State and explain the Delimitation(s) of the study about {self.state.topic} in {self.state.case_study}, {country}. Present all in One paragraph and write in academic language."""

    def _build_theoretical_gen_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        return f"""Select ONE existing theory explicitly named in the CITATION CONTEXT below and use it to frame the study about {self.state.topic}.
State the author(s) and year, explain what the theory says with precise in-text citations, then provide two opposing and two supporting scholarly views drawn from the same CITATION CONTEXT, each in its own paragraph.
State the importance of the theory in the context of {self.state.topic}, then its importance in {self.state.case_study}, and finally the gaps.

Rules:
- Do NOT invent a new theory name.
- Do NOT create placeholder citations.
- Use ONLY sources from the CITATION CONTEXT below. If no suitable theory exists, explicitly state that evidence is limited and avoid inventing one.
- No bullets or sub-headings; formal academic tone; UK English.

CITATION CONTEXT:
{citation_context}
"""

    def _build_conceptual_gen_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        return f"""Just List to make my copying easy and State Independent and dependent Variables for the study about {self.state.topic} and list 10 independent and 5 dependent variables. List four intervening variables also. Then make a discussion on how each of the Independent, dependent and intervening Variables relates to another with the concept of the study with intext citations. Be detailed in discussions and in context of {self.state.case_study}.

        Independent Variables						Dependent Variables

        Figure 1. 1: Conceptual Framework 
        Designed and Molded by Researcher (2025)
        
        CITATION CONTEXT:
        {citation_context}
        """

    def _build_methodology_brief_prompt(self, section_id: str, title: str) -> str:
        return f"""Brief methodology of the study about {self.state.topic}. Mention research design, sample size, tools."""

    def _build_definitions_gen_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        return f"""Write definition of key terms on the study about {self.state.topic} in {self.state.case_study}. Present with citations.
        Use ONLY sources from the CITATION CONTEXT below. If a definition source is not provided, explicitly state evidence is limited.
        dont bullet or number, dont sub headings, present in big detailed paragraphs in academic tone. never say we, say the study, or the reseacher.
        """

    def _build_organization_5chapter_prompt(self, section_id: str, title: str) -> str:
        return f"""Write Organisation of the study which will be guided in five chapters in Chapter one introduction, two is literature review, three is methodology, four is data analysis, presentation and interpretations of findings, five is discusions, summary, conlusions, recommendations, sugestionsfor futer studies
        Write in context of {self.state.topic} in {self.state.case_study}."""

    def _build_general_lit_intro_prompt(self, section_id: str, title: str) -> str:
        return f"""In one paragraph, write Introduction of chapter two about literature reviews for the study about {self.state.topic} and study objectives ie saying Chapter two of this study will be about literature reviews using previous information from former scholars, both theoretical and empirical studies will be reviewed and study gaps in accordance to the study area of {self.state.case_study}, {self.state.parameters.get('country', 'South Sudan')} will be identified which will be he basis for this study."""

    def _build_general_theory_main_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        return f"""For the study titled {self.state.topic} in {self.state.case_study}, {self.state.parameters.get('country', 'South Sudan')} write a theoretical framework section using ONLY theories explicitly named in the CITATION CONTEXT below.

Requirements:
- Do NOT invent or rename a theory.
- Use at least four real citations from the CITATION CONTEXT (2020-2025).
- Provide two opposing and two supporting scholarly perspectives, each in its own paragraph.
- Explain the theory, then its importance for the study and case study, and conclude with gaps.

If no suitable theory exists in the CITATION CONTEXT, state that evidence is limited and avoid fabrication.

CITATION CONTEXT:
{citation_context}"""

    def _build_general_theory_obj_prompt(self, section_id: str, title: str, objectives_text: str, citation_context: str) -> str:
        return f"""Select the objectives: "{objectives_text}" and write a theoretical framework section using ONLY theories explicitly named in the CITATION CONTEXT below.

Requirements:
- Do NOT invent a new theory name.
- Use at least four real citations from the CITATION CONTEXT (2020-2025).
- Provide two opposing and two supporting scholarly perspectives.
- Explain the theory, its importance for the objectives, and the gaps in the case study context.

If no suitable theory exists in the CITATION CONTEXT, state that evidence is limited and avoid fabrication.

CITATION CONTEXT:
{citation_context}"""

    def _build_general_empirical_prompt(self, section_id: str, title: str, objective: str, citation_context: str) -> str:
        country = self.state.parameters.get('country', 'South Sudan')
        objective_text = (objective or "").strip()
        objective_lines = [line.strip() for line in objective_text.splitlines() if line.strip()]
        if not objective_lines:
            objective_lines = [f"Review empirical studies relevant to {self.state.topic} in {self.state.case_study}."]
        objective_block = "\n".join(objective_lines)
        objective_instruction = "Cover each objective in a distinct paragraph or mini-subsection with clear transitions."
        return f"""Select up to six real studies about the objective(s) below from the approved source list.

OBJECTIVES TO COVER:
{objective_block}

{objective_instruction}
        For each, make sure they are not more than five years old (2020-2025). If fewer than six approved sources exist, cite fewer and state evidence is limited.
        Write like this: Author (year) conducted a study about ... where the main objective was to... in ... the methodology was ..., the study found out that (with statistical results)... The study concluded that ... The study recommended that ... However, the study gap is ... Write more of the gaps. (Then cite at the end ie Author, year).
        
        Let it be from different countries in this order:
        1. Any Asian country
        2. Any South American Country
        3. Any West African country
        4. Any Central or South African Country
        5. Any East African country
        6. Lastly {country}
        
        Kindly be stating the countries only when the approved source list provides that information. Make real citations of real studies, authors, years, studies, methodology, findings, conclusion, recommendations etc. ranges from 2019 to 2025.
        
        CITATION CONTEXT:
        {citation_context}"""

    def _build_general_lit_summary_prompt(self, section_id: str, title: str) -> str:
        return f"""Write literature summary and knowledge gap basing on the empirical reviews above in the context of {self.state.topic} in {self.state.case_study}, {self.state.parameters.get('country', 'South Sudan')}.
        Don‚Äôt bullet or number."""

    def _build_empirical_intro_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        return f"""Write a short empirical literature review introduction for section "{section_id} {title}".

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

AVAILABLE SOURCES:
{citation_context}

REQUIREMENTS:
- 1-2 paragraphs
- UK English spelling
- Formal academic tone
- Cite 2-3 sources total
- Explain that the empirical review is organised around the study objectives
- Do NOT include the section heading

Write the section content now:"""

    def _build_objectives_prompt(self, section_id: str, title: str, style: str) -> str:
        """Build prompt for objectives sections - improved for academic quality."""
        uk_english_note = "\n\n**LANGUAGE**: UK English spelling (analyse, organisation, whilst, amongst, realise)\n**TONE**: Formal academic register\n"
        objective_count = self.state.parameters.get("objective_count")
        objective_list = self._get_objective_list()
        general_objective = ""
        if isinstance(self.state.objectives, dict):
            general_objective = (self.state.objectives.get("general") or "").strip()
        
        if style == "objectives_intro":
            return f"""Write a brief introduction paragraph for "{section_id} {title}".
{uk_english_note}
TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

Write 1-2 clear sentences that:
- State that this section delineates the study objectives
- Mention that objectives guide the investigation design and methodology
Do NOT include citations. Do NOT include the heading.
Just write the content directly:"""
        
        elif style == "objective":
            if general_objective:
                return f"""Use the general objective exactly as provided.
{uk_english_note}
GENERAL OBJECTIVE:
{general_objective}

Return ONLY the objective text, without additional commentary or heading."""
            return f"""Write the general objective for "{section_id} {title}".
{uk_english_note}
TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

Write ONE comprehensive, academically rigorous general objective that:
- Uses strong action verbs (investigate, examine, explore, evaluate, analyze)
- Is SPECIFIC to {self.state.case_study} context
- Clearly links the TOPIC to the CASE STUDY location
- Is measurable and achievable

Format: "The main objective of this study is to [action verb] the [specific aspect of topic] [among/within specific population or setting] in [specific location in case study]"

Example structure: "...to investigate the prevalence and determinants of [specific issue] among [specific population] in [specific region/district], {self.state.case_study}"

Do NOT include citations. Do NOT include the heading.
Just write the objective:"""
        
        elif style == "objectives_list":
            if objective_list:
                formatted = "\n".join([f"{idx + 1}. {obj}" for idx, obj in enumerate(objective_list)])
                return f"""Use the specific objectives exactly as provided.
{uk_english_note}
SPECIFIC OBJECTIVES:
{formatted}

Return ONLY the objectives list, preserving the wording."""
            target = objective_count or 5
            roman = ["i", "ii", "iii", "iv", "v", "vi", "vii"]
            sample_lines = "\n".join([
                f"{roman[i]}. [Objective {i + 1} aligned to the study context]"
                for i in range(min(target, len(roman)))
            ])
            return f"""Write {target} specific objectives for "{section_id} {title}".
{uk_english_note}
TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

Create SMART (Specific, Measurable, Achievable, Relevant, Time-bound) objectives that:
- Each focuses on ONE distinct aspect of the research
- Are precisely worded and context-specific
- Build logically toward answering the research problem
- Include methodology hints (examine, assess, determine, evaluate, establish, analyze, explore)
- Reference specific variables, populations, or contexts

Write as a numbered list using lowercase Roman numerals:
{sample_lines}

CRITICAL: Make each objective:
- Grounded in {self.state.case_study} context
- Distinct and non-overlapping
- Researchable with clear methodology implied

Do NOT include citations. Do NOT include the heading.
Just write the objectives list:"""
        
        elif style == "questions":
            target = objective_count or 5
            objectives_text = ""
            if objective_list:
                objectives_text = "\n".join([f"{idx + 1}. {obj}" for idx, obj in enumerate(objective_list)])
            roman = ["i", "ii", "iii", "iv", "v", "vi", "vii"]
            sample_lines = "\n".join([
                f"{roman[i]}. [Research question directly corresponding to objective {i + 1}]"
                for i in range(min(target, len(roman)))
            ])
            return f"""Write {target} research questions that correspond PRECISELY to the specific objectives for "{section_id} {title}".
{uk_english_note}
TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

SPECIFIC OBJECTIVES:
{objectives_text or "[Auto-generate objectives if none are provided]"}

For EACH specific objective, create ONE corresponding research question that:
- Directly addresses the same variables/concepts as the objective
- Is formulated as a proper question (not a statement)
- Is answerable through empirical investigation
- Includes specific context to {self.state.case_study}

Types of research questions to use:
- Descriptive: "What is the prevalence/magnitude/extent of [variable] among [population] in [case study]?"
- Relational: "What is the relationship between [X] and [Y] among [population] in [case study]?"
- Comparative: "How does [variable] differ between [group A] and [group B] in [case study]?"
- Exploratory: "What factors influence/contribute to [outcome] among [population] in [case study]?"
- Evaluative: "To what extent does [intervention/factor] affect [outcome] in [specific context in case study]?"

Write as a numbered list:
{sample_lines}

CRITICAL: Ensure perfect 1:1 alignment between each objective and its corresponding research question.

Do NOT include citations. Do NOT include the heading.
Just write the research questions:"""
        
        return ""

    def _build_organization_prompt(self, section_id: str, title: str) -> str:
        """Build prompt for 6-chapter organization section."""
        return f"""Write section "{section_id} {title}" - outline the thesis structure.

**LANGUAGE REQUIREMENTS:**
- UK English spelling (organisation, analyse, whilst)
- Formal academic register
- Clear structural language

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

Describe the organization of this thesis using the UNIVERSITY OF JUBA 6-CHAPTER FORMAT:

**Chapter One: Introduction** - Provides the setting, background, problem statement, objectives, research questions, purpose, scope, justification, and definitions.

**Chapter Two: Literature Review** - Reviews theoretical and conceptual frameworks, thematic literature organized by research objectives, and identifies research gaps.

**Chapter Three: Research Methodology** - Details the research philosophy, design, population, sampling, data collection instruments, validity, reliability, and ethical considerations.

**Chapter Four: Presentation and Interpretation of Data** - Presents findings organized by research questions and themes from the data collection instruments.

**Chapter Five: Results and Discussion** - Discusss findings in relation to literature from Chapter Two, showing confirmations or variations from existing knowledge.

**Chapter Six: Summary, Conclusions and Recommendations** - Summarizes findings, draws conclusions, provides recommendations, and suggests areas for future research.

Write 2 clear paragraphs describing this structure.
Do NOT include citations. Do NOT include the heading.
Just write the content:"""

    def _build_scope_prompt(self, section_id: str, title: str, style: str) -> str:
        """Build prompt for limitations, delimitations, assumptions sections."""
        if style == "limitations":
            content_guide = """Write about LIMITATIONS - factors beyond the researcher control:
- Methodological limitations (sample size, design constraints)
- Data availability limitations
- Time and resource constraints
- Generalizability concerns
- Potential biases"""
        elif style == "delimitations":
            content_guide = """Write about DELIMITATIONS - deliberate boundaries set by the researcher:
- Geographic scope (focused on specific location)
- Population scope (specific demographic)
- Time period covered
- Variables included/excluded
- Theoretical boundaries"""
        else:  # assumptions
            content_guide = """Write about ASSUMPTIONS underlying this study:
- Participants will respond honestly
- Data collection instruments are valid
- Sample is representative
- Theoretical framework is applicable to context
- Variables are measurable"""
        
        return f"""Write section "{section_id} {title}" for this thesis chapter.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

{content_guide}

Write 2 well-developed paragraphs in academic language.
Do NOT include citations (this is a methodological section).
Do NOT include the heading.
Just write the content:"""

    def _build_definitions_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build prompt for definitions section with optional citations."""
        return f"""Write section "{section_id} {title}" defining key operational terms.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

{citation_context if citation_context else ""}

Define 4-6 key terms/concepts used in this study. For each term:
- Provide a clear, operational definition
- Reference the source if from literature
- Explain how the term is used specifically in THIS study

Key terms to define (select the most relevant):
- The main subject (e.g., {self.state.topic.split()[0] if self.state.topic else "topic"})
- The context (e.g., aspects of {self.state.case_study})
- Key variables from objectives
- Relevant methodological terms

Format each definition clearly, with the term in **bold**.
Include citations where definitions come from literature.
Do NOT include the heading.
Just write the definitions:"""

    # ========== CHAPTER TWO PROMPT BUILDERS ==========
    
    def _build_lit_intro_prompt(self, section_id: str, title: str) -> str:
        """Build literature review introduction with UK English."""
        return f"""Write section "{section_id} {title}" - introduce the literature review.

**LANGUAGE REQUIREMENTS:**
- UK English spelling (analyse, organisation, whilst, amongst, realise, synthesise)
- Formal academic register
- Scholarly tone chapter.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

Write 2 paragraphs that:
1. Explain the purpose of this literature review chapter
2. Briefly outline what will be covered (theoretical framework, thematic reviews, research gaps)
3. Connect to the research objectives from Chapter One

Do NOT include citations. Do NOT include the heading.
Just write the content:"""

    def _build_framework_intro_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build conceptual framework with UK English."""
        return f"""Write section "{section_id} {title}" - develop conceptual framework.

**LANGUAGE REQUIREMENTS:**
- UK English spelling (analyse, organisation, whilst, conceptualise, operationalise)
- Formal academic register
- Precise scholarly languageal details.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

{citation_context}

Write 2 substantive paragraphs:
1. Introduce the theoretical underpinnings of this study
2. Justify WHY these specific theories/concepts were selected
3. Explain how they guide the research objectives

Use citations from the provided sources.
Do NOT include the heading.
Just write the content:"""

    def _build_theory_detailed_prompt(self, section_id: str, title: str, citation_context: str, theory_name: str = "") -> str:
        """Build detailed theory section with UK English and hierarchical sub-headings."""
        actual_theory = theory_name if theory_name else title
        
        # Calculate sub-heading numbers based on section_id (e.g., "2.1.1" -> ["2.1.1.1", "2.1.1.2", etc.])
        sub_base = section_id  # e.g., "2.1.1"
        
        return f"""Write a comprehensive theoretical analysis of {actual_theory} for section {section_id}.

LANGUAGE REQUIREMENTS:
- UK English spelling (analyse, organisation, behaviour, realise, contextualise)
- Formal academic register with critical scholarly tone

RESEARCH CONTEXT:
- Topic: {self.state.topic}
- Case Study: {self.state.case_study}
- Theory: {actual_theory}

AVAILABLE SOURCES:
{citation_context}

CRITICAL: Include hierarchical sub-headings (###) for each subsection as shown below.

Write using this hierarchical structure:

### {sub_base}.1 Theoretical Origins and Development
Write 2-3 paragraphs introducing {actual_theory}, discussing its intellectual origins, the scholar(s) who developed it, the historical context of its emergence, and how it has evolved through subsequent scholarly contributions. Trace the theoretical lineage and key developmental milestones.

### {sub_base}.2 Core Constructs and Theoretical Mechanisms
Write 2-3 paragraphs explaining the fundamental principles, key constructs, and explanatory mechanisms of the theory. Demonstrate how the theory accounts for relevant phenomena. Integrate empirical studies that have tested or applied the theory, including methodological details and findings.

### {sub_base}.3 Empirical Applications and Supporting Evidence
Write 2-3 paragraphs discussing how researchers have applied this theory across different contexts. Present empirical studies with specific findings, methodologies, and their contributions to theoretical understanding.

### {sub_base}.4 Critical Perspectives and Limitations
Write 1-2 paragraphs presenting both supportive and critical perspectives. Identify theoretical limitations, boundary conditions, and contextual constraints that affect the theory's applicability.

### {sub_base}.5 Relevance to Current Study
Write 1-2 paragraphs connecting {actual_theory} specifically to {self.state.topic} in the context of {self.state.case_study}. Explain how this theoretical lens informs the research questions and guides the analytical framework of the current study.

### {sub_base}.6 Conceptual Framework Diagram
Present a simple ASCII art diagram showing the key components and their relationships, followed by 1 paragraph of interpretive explanation of how this framework guides the study.

WRITING REQUIREMENTS:
- MUST include all sub-headings exactly as shown above (### {sub_base}.1, ### {sub_base}.2, etc.)
- Cite only sources from the provided context above
- Include specific methodological details when discussing studies
- Include 3-5 citations per paragraph using APA 7 (LAST NAMES ONLY)
- ASCII diagram MUST be in code block (```)
- Do NOT include the main section heading (e.g., "## {section_id} {title}") - that will be added automatically

Write the complete section content now with ALL hierarchical sub-headings:"""

    def _build_theme_intro_prompt(self, section_id: str, title: str, theme_name: str = "", objective_text: str = "") -> str:
        """Build prompt for thematic section introduction - links to research objective."""
        actual_theme = theme_name if theme_name else title
        obj_context = f"\n- Research Objective: {objective_text}" if objective_text else ""
        
        return f"""Write a brief introductory paragraph for section {section_id}: "{title}".

RESEARCH CONTEXT:
- Topic: {self.state.topic}
- Case Study: {self.state.case_study}{obj_context}

This section reviews empirical literature related to the research objective stated above.

Write ONE substantive paragraph (5-7 sentences) that:
1. States that this section reviews literature relevant to the research objective
2. Briefly mentions the specific objective being addressed (paraphrase, don't copy verbatim)
3. Explains the significance of reviewing empirical studies on this aspect
4. Previews the key themes that will be examined in the subsections

REQUIREMENTS:
- Use UK English spelling (analyse, organisation, behaviour)
- Write in formal academic prose
- Do NOT include citations in this introductory paragraph
- Do NOT include the section heading in your response
- Do NOT copy the full objective text verbatim - paraphrase it

Write the paragraph now:"""

    def _build_lit_synthesis_prompt(self, section_id: str, title: str, citation_context: str, objective_text: str = "") -> str:
        """Build prompt for literature synthesis - scholarly academic prose tied to research objective."""
        obj_context = f"\nRESEARCH OBJECTIVE BEING ADDRESSED:\n{objective_text}\n" if objective_text else ""
        
        return f"""Write section "{section_id} {title}" as a comprehensive literature synthesis.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}
SUBSECTION FOCUS: {title}
{obj_context}
AVAILABLE SOURCES FOR CITATION:
{citation_context}

Write 10 well-developed paragraphs of scholarly prose synthesising empirical literature related to the subsection focus.

APA 7 CITATION FORMAT - CRITICAL:
- Use LAST NAMES ONLY: Smith (2024), Jones & Brown (2023), Williams et al. (2022)
- NEVER use full names like "John Smith" or "Dr. Robert Jones"
- Single author: Smith (2024) or (Smith, 2024)
- Two authors: Smith & Jones (2024)
- Three or more: Smith et al. (2024)

EACH PARAGRAPH MUST:
1. Begin with a clear thematic statement introducing the specific aspect being discussed
2. Present findings from 2-3 studies with specific details:
   - Author LAST NAME and year only
   - Research context and location
   - Methodology used (sample size, research design)
   - Key quantitative findings (percentages, correlations, significance levels) or qualitative themes
3. Provide critical analysis explaining strengths, limitations, and implications
4. Connect findings to the research objective and the broader research context
5. End with parenthetical group citations: (Smith, 2024; Jones, 2023; Brown, 2022)

WRITING REQUIREMENTS:
- Write flowing academic prose WITHOUT subheadings, bullet points, or numbered lists
- Use UK English spelling (analyse, organisation, behaviour, realise, contextualise)
- Cite ONLY sources from the provided citation context above
- Include specific statistical findings (e.g., r=0.67, p<0.01, 73% of participants)
- Discuss methodological approaches critically
- NEVER cite research objectives, research questions, or methodology descriptions
- Connect all discussion to {self.state.topic} in {self.state.case_study}

Do NOT include the section heading.
Do NOT use placeholder text or template language.
Do NOT fabricate citations - only use sources provided above.

Write the section content now:"""

    def _build_literature_gap_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build prompt for research gap and literature matrix."""
        return f"""Write a consolidated research gap analysis for section {section_id}.

RESEARCH CONTEXT:
- Topic: {self.state.topic}
- Case Study: {self.state.case_study}

AVAILABLE SOURCES:
{citation_context}

Write the following components as flowing academic prose:

COMPONENT 1: Gap Synthesis (2 paragraphs)
Synthesise the key gaps identified throughout the literature review. Discuss:
- Methodological limitations in existing research approaches
- Geographical and contextual gaps, particularly regarding {self.state.case_study}
- Theoretical frameworks that remain untested or underdeveloped
- How this current study specifically addresses these identified gaps

COMPONENT 2: Literature Summary Matrix
Create a comprehensive markdown table summarising the key studies reviewed:

| Author (Year) | Research Focus | Methodology | Sample | Key Findings | Gap/Limitation |
|--------------|----------------|-------------|--------|--------------|----------------|

Include 8-10 of the most relevant studies from the sources provided.

COMPONENT 3: Research Justification (1 paragraph)
Based on the identified gaps, provide a compelling justification for why this study is necessary, timely, and significant to the field.

COMPONENT 4: Contribution Statement (1 paragraph)
Articulate how this study will contribute to theoretical knowledge, professional practice, and policy development in the field.

REQUIREMENTS:
- Use UK English spelling throughout
- Cite only from the sources provided above
- Write in formal academic prose
- Do NOT include the section heading in your response

Write the section content now:"""

    def _build_conceptual_framework_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build prompt for conceptual framework with horizontal branching ASCII diagram."""
        return f"""Write section "{section_id} {title}" - a comprehensive conceptual framework for the study.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}
CITATION CONTEXT:
{citation_context}

**CONTENT REQUIREMENTS:**

1. **SCIENTIFIC DEFINITION**: Define conceptual framework based on scholarly sources (e.g., Miles & Huberman, 1994 or Maxwell, 2013). (1 paragraph)

2. **MANDATORY HORIZONTAL ASCII DIAGRAM**: Create a detailed, horizontal, branching diagram showing the relationship between variables.
   
   **DIAGRAM STRUCTURE:**
   - [Independent Variables] on the LEFT (vertical stack)
   - [Dependent Variable] on the RIGHT
   - Show arrows (---->) pointing from independent variables to the dependent variable.
   - Use boxes and clear labels for ALL main themes/variables identified in the literature review.
   
   Example structure:
   ```
   +-----------------------+      +-------------------------+
   | INDEPENDENT VARIABLES |      |   DEPENDENT VARIABLE    |
   +-----------------------+      +-------------------------+
   | [Variable A]          |----->|                         |
   |                       |      |                         |
   | [Variable B]          |----->|  [Overall Goal/Topic]   |
   |                       |      |                         |
   | [Variable C]          |----->|                         |
   +-----------------------+      +-------------------------+
   ```
   Caption: Figure 2.1: Conceptual Framework for the Study
   Source: Author's Construct (2025)

3. **DETAILED EXPLANATION**: Describe each variable and the hypothesized relationships in scholarly detail. (3 paragraphs)

**WRITING STYLE:**
- Use academic UK English.
- Cite sources provided to support the relationships.
- Ensure the variables mentioned here match the themes discussed in the Literature Review empirical sections.

Write the section content now:"""

    def _get_variables_context(self) -> str:
        """Get formatted variables for prompt integration."""
        if hasattr(self.state, 'objective_variables') and self.state.objective_variables:
            ctx = "\nARCHITECTURAL VARIABLES (The Golden Thread):\n"
            for obj_num, v_list in self.state.objective_variables.items():
                ctx += f"- Objective {obj_num} Variables: {', '.join(v_list)}\n"
            return ctx
        return ""

    def _get_system_prompt(self) -> str:
        vars_ctx = self._get_variables_context()
        return f"""You are an expert academic thesis writer. You write in formal academic English with proper APA 7 citations.

{vars_ctx}

You MUST follow the "Golden Thread" principle: ensure that variables identified in the literature review (Chapter 2) are consistently tracked throughout Chapter 3 (Methodology), Chapter 4 (Analysis), and Chapter 5 (Discussion).

ABSOLUTELY CRITICAL - READ THIS CAREFULLY:
You will be given a numbered list of sources. You must ONLY cite from this list.
- If "Fassi et al. (2024)" is in the source list, you may cite it.
- If a paper is NOT in the source list, you MUST NOT cite it, even if you know it exists.
- NEVER cite Twenge, Valkenburg, Keles, Odgers, Best, boyd, or ANY author not explicitly listed.
- Before writing a citation, CHECK that it appears in the source list.
- GROUNDING RULE: Do not state specific percentages, sample sizes, or p-values unless you see them in the provided Abstract text. If the abstract is vague, your writing must reflect that vagueness rather than creating "plausible" details.

APA 7 CITATION FORMAT - CRITICAL:
1. Use LAST NAMES ONLY in citations - NEVER full names
   ‚úì CORRECT: Smith (2024), Jones & Brown (2023), Williams et al. (2022)
   ‚úó WRONG: John Smith (2024), Robert Jones & Mary Brown (2023)
2. Single author: Smith (2024) or (Smith, 2024)
3. Two authors: Smith & Jones (2024) or (Smith & Jones, 2024)
4. Three or more authors: Smith et al. (2024) or (Smith et al., 2024)
5. For linked citations: [Smith (2024)](URL) or [(Smith, 2024)](URL)

WHAT TO CITE - CRITICAL:
‚úì CITE: Literature findings, theories, statistics, empirical evidence, definitions from scholars
‚úó DO NOT CITE: 
  - Research objectives (these are YOUR objectives, not from literature)
  - Research questions (these are YOUR questions)
  - Methodology descriptions (unless citing a methodology source)
  - Your own analysis or interpretations
  - Study area descriptions (unless citing geographic data)
  - Sample size calculations (cite formula source only, not the calculation)
  - Ethical considerations (unless citing ethical guidelines)

QUALITY RULES:
1. Every factual claim from literature MUST have a citation
2. Each paragraph discussing literature needs MINIMUM 3 citations
3. Write substantively - no filler content
4. Use transition words between paragraphs
5. Maintain academic tone throughout
6. Use UK English spelling (analyse, organisation, behaviour)

VIOLATION WARNING: Using full author names instead of last names, or citing non-citable sections, is a critical error."""
        
        # Add custom user instructions if provided
        custom_instr = self.state.parameters.get('custom_instructions', '')
        if custom_instr:
            prompt += f"""
\n\n=== SPECIAL USER INSTRUCTIONS (URGENT) ===
The user has provided these specific guidelines for this thesis. You MUST prioritize these:
{custom_instr}
===========================================\n
"""
        return prompt

    # ============================================================================
    # ADAPTIVE METHODOLOGY HELPER METHODS
    # ============================================================================
    
    def _detect_data_collection_type(self) -> str:
        """Intelligently detect if study needs primary, secondary, or both data types.
        
        Returns: 'primary', 'secondary', or 'both'
        """
        # Get objectives and topic for analysis
        objectives_text = ""
        objective_list = self._get_objective_list()
        if objective_list:
            objectives_text = " ".join(objective_list)
        
        topic = self.state.topic.lower()
        combined_text = (objectives_text + " " + topic).lower()
        
        # Keywords indicating PRIMARY data collection
        primary_keywords = [
            "survey", "questionnaire", "interview", "focus group",
            "collect data", "primary data", "field study", "empirical",
            "experiment", "observation", "measure", "assess prevalence",
            "determine factors", "examine relationship", "test hypothesis"
        ]
        
        # Keywords indicating SECONDARY data (literature-based, meta-analysis)
        secondary_keywords = [
            "review", "meta-analysis", "systematic review", "secondary data",
            "existing data", "archival", "historical", "documentary analysis",
            "content analysis", "bibliometric", "scoping review"
        ]
        
        # Count keyword matches
        primary_score = sum(1 for kw in primary_keywords if kw in combined_text)
        secondary_score = sum(1 for kw in secondary_keywords if kw in combined_text)
        
        # Decision logic
        if primary_score > 0 and secondary_score > 0:
            return "both"  # Mixed methods or triangulation
        elif primary_score > secondary_score:
            return "primary"
        elif secondary_score > primary_score:
            return "secondary"
        else:
            # Default: most PhD studies collect primary data
            return "primary"
    
    def _get_tense_version(self, is_proposal: bool = False) -> dict:
        """Get appropriate verb tenses for proposal (future) vs report (past).
        
        Args:
            is_proposal: True for proposal version, False for report/thesis
        
        Returns: Dictionary with tense variations
        """
        if is_proposal:
            # Proposal version - FUTURE tense (will, shall)
            return {
                "collect": "will collect",
                "collected": "will be collected",
                "use": "will use",
                "used": "will be used",
                "analyze": "will analyze",
                "analyzed": "will be analyzed",
                "employ": "will employ",
                "employed": "will be employed",
                "adopt": "will adopt",
                "adopted": "will be adopted",
                "select": "will select",
                "selected": "will be selected",
                "ensure": "will ensure",
                "ensured": "will be ensured",
                "conduct": "will conduct",
                "conducted": "will be conducted",
                "obtain": "will obtain",
                "obtained": "will be obtained",
                "distribute": "will distribute",
                "distributed": "will be distributed",
                "calculate": "will calculate",
                "calculated": "will be calculated"
            }
        else:
            # Report/Thesis version - PAST tense (was, were)
            return {
                "collect": "collected",
                "collected": "was collected",
                "use": "used",
                "used": "was used",
                "analyze": "analyzed",
                "analyzed": "was analyzed",
                "employ": "employed",
                "employed": "was employed",
                "adopt": "adopted",
                "adopted": "was adopted",
                "select": "selected",
                "selected": "was selected",
                "ensure": "ensured",
                "ensured": "was ensured",
                "conduct": "conducted",
                "conducted": "was conducted",
                "obtain": "obtained",
                "obtained": "was obtained",
                "distribute": "distributed",
                "distributed": "was distributed",
                "calculate": "calculated",
                "calculated": "was calculated"
            }

    # ============================================================================
    # CHAPTER 3: METHODOLOGY PROMPT BUILDERS (PhD-Level Rigor)
    # ============================================================================

    
    def _build_methodology_intro_prompt(self, section_id: str, title: str) -> str:
        """Build prompt for methodology chapter introduction."""
        # Get objectives from state if available
        objectives_text = ""
        objective_list = self._get_objective_list(4)
        if objective_list:
            objectives_text = f"\n\nREFERENCE OBJECTIVES (from Chapter 1):\n" + "\n".join([f"- {obj}" for obj in objective_list])
        
        return f"""Write section "{section_id} {title}" for Chapter Three: Research Methodology.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}{objectives_text}

Write 3 clear paragraphs:

**Paragraph 1**: Restate the Research Problem (2-3 sentences)
- Briefly remind the reader of the core research problem being investigated
- Reference the specific research objectives from Chapter One

**Paragraph 2**: Chapter Purpose (2-3 sentences)
- Explain that this chapter presents the systematic approach used to address the research questions
- Emphasize the importance of methodological rigor in doctoral research

**Paragraph 3**: Chapter Roadmap (3-4 sentences)
- Provide a clear overview of the structure of this chapter
- List the sections: Research Philosophy, Research Design, Target Population, Sampling Design, Sample Size, Data Collection Instruments, Validity and Reliability, Data Collection Procedures, Data Analysis Procedures, and Ethical Considerations

REQUIREMENTS:
- Academic formal tone, concise and clear
- Do NOT include citations in the introduction
- Do NOT include the section heading

Write the content now:"""

    def _build_research_philosophy_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build adaptive prompt for research philosophy with natural narrative flow."""
        objectives_context = ""
        objective_list = self._get_objective_list()
        if objective_list:
            obj_text = "\n".join([f"- {obj}" for obj in objective_list])
            objectives_context = f"\n\nSTUDY OBJECTIVES (analyze to decide philosophy):\n{obj_text}\n"
        
        return f"""Write section "{section_id} {title}" - adaptive research philosophy with natural flow.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}{objectives_context}

{citation_context}

**CRITICAL REQUIREMENTS:**

1. **START WITH SCHOLARLY DEFINITION**: "Research philosophy, as defined by Saunders et al. (2019), constitutes..."

2. **TENSE AND VOICE**: Use {self._get_tense_version(self.state.is_proposal)['adopted']} tense throughout this section (e.g., "{self._get_tense_version(self.state.is_proposal)['adopted']}", "{self._get_tense_version(self.state.is_proposal)['employed']}").

3. **NO NUMBERED LISTS OR SUB-HEADINGS**: Write as flowing narrative paragraphs

4. **ANALYZE & DECIDE**: Don't default to positivism - analyze study and choose appropriate philosophy
5. **CITATION DISTRIBUTION**: Every paragraph MUST contain at least one scholarly citation from the provided research pool. Do not clump all citations at the beginning; distribute them naturally throughout the entire section.

**CONTENT TO COVER (in natural flowing paragraphs):**

Paragraph 1: Define research philosophy, its importance, introduce Saunders' Research Onion framework

Paragraphs 2-3: Discuss ontology (objectivism vs constructivism), justify choice, reject alternative

Paragraphs 4-5: Discuss epistemology (positivism/interpretivism/pragmatism), justify choice, reject alternatives  

Paragraph 6: Discuss axiology (value-free vs value-laden)

Paragraph 7: Discuss research approach (deductive vs inductive), justify choice

Paragraph 8: Present Research Onion diagram:

```
============================================
    SAUNDERS' RESEARCH ONION  
============================================
Layer 1: Philosophy    -> [Your chosen philosophy]
Layer 2: Approach      -> [Deductive/Inductive]
Layer 3: Strategy      -> [Based on study]
Layer 4: Time Horizon  -> [Cross-sectional/Longitudinal]
Layer 5: Data Collection -> [Methods]
============================================
```

Caption: Figure 3.1: Research Philosophy and Design Framework  
Source: Adapted from Saunders, Lewis & Thornhill (2019)

**2. Ontological Stance (1 paragraph)**
- Define Ontology: nature of reality and existence
- Compare **Objectivism** (reality exists independently) vs. **Constructivism** (reality is socially constructed)
- **JUSTIFY YOUR CHOICE** for this study (e.g., "{self._get_tense_version(self.state.is_proposal)['adopted'].capitalize()} because...")
- **REJECT THE ALTERNATIVE**: Explain why the other was not suitable

**3. Epistemological Stance (2 paragraphs)**  
- Define Epistemology: what constitutes acceptable knowledge
- Compare three philosophies:
  * **Positivism**: Observable facts, hypothesis testing, quantitative [(Saunders et al., 2019)](URL)
  * **Interpretivism**: Subjective meanings, qualitative [(Creswell, 2014)](URL)
  * **Pragmatism**: Mixed methods, practical solutions
- **JUSTIFY YOUR CHOICE** rigorously (2-3 reasons why it fits study objectives)
- **REJECT ALTERNATIVES**: Why the others are unsuitable for THIS research

**4. Axiological Stance (1 paragraph)**
- Define Axiology: role of values in research
- Discuss value-free (objective) vs. value-laden (subjective) research
- State your stance and justify with citations

**5. Research Approach: Deductive vs. Inductive (1 paragraph)**
- Compare Deductive (theory -> data, testing hypotheses) vs. Inductive (data -> theory, building theory)
- **JUSTIFY YOUR CHOICE** based on the philosophy selected above
- Cite methodology texts [(Sekaran & Bougie, 2016)](URL)

**6. Research Onion Visual Framework (1 paragraph - MANDATORY DIAGRAM)**
CRITICAL: Create an ASCII diagram of the Research Onion showing the layers peeling to your choices:

```
============================================
    SAUNDERS' RESEARCH ONION
============================================
Layer 1: Philosophy ->  [YOUR CHOICE: e.g., Positivism]
Layer 2: Approach ->    [YOUR CHOICE: e.g., Deductive]
Layer 3: Strategy ->    [YOUR CHOICE: e.g., Survey]
Layer 4: Time Horizon -> [YOUR CHOICE: e.g., Cross-sectional]
Layer 5: Data Collection

Caption: Figure 3.1: Research Philosophy and Design Framework
Source: Adapted from Saunders, Lewis & Thornhill (2019)
```

After the diagram, write 3-4 sentences interpreting how these layers work together for THIS study.

**7. Summary and Alignment (1 paragraph)**
- Summarize how the chosen philosophy aligns with research objectives
- Connect philosophy to the specific research questions

CRITICAL REQUIREMENTS:
- MANDATORY: 3-5 citations per paragraph from methodology sources
- APA 7 STRICT: (Author, Year) format, grouped citations [(Author1, Year; Author2, Year)](URL)
- Justify EVERY choice - never just state what was done
- ASCII diagram in code block (```)
- Do NOT include section heading

Write the content now:"""

    def _build_research_design_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build prompt for research design section."""
        return f"""Write section "{section_id} {title}" - detailed research design justification.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}
MANDATORY DESIGN: {self.state.parameters.get('methodology_context', {}).get('research_design', 'survey')}

{citation_context}

Write 6 detailed paragraphs:

**1. Research Strategy (2 paragraphs)**
- You MUST justify why the MANDATORY DESIGN above was chosen.
- Evaluate multiple strategies: Survey, Experiment, Case Study, Ethnography, Grounded Theory, Action Research
- For EACH strategy, briefly explain what it entails (1-2 sentences)
- **JUSTIFY YOUR CHOICE** (e.g., "Survey {self._get_tense_version(self.state.is_proposal)['selected']} because it allows for...")  
- **REJECT ALTERNATIVES**: Explain why others (e.g., Experiment) were unsuitable for this context
- Cite methodology authors [(Yin, 2018; Creswell, 2014)](URL)

**2. Time Horizon (1 paragraph)**
- Compare **Cross-sectional** (one point in time) vs. **Longitudinal** (over time)
- **JUSTIFY YOUR CHOICE** (e.g., "Cross-sectional was chosen due to time constraints and...")
- **REJECT THE ALTERNATIVE**: Why longitudinal was not feasible
- Cite [(Saunders et al., 2019)](URL)

**3. Research Type/Nature (1 paragraph)**
- Discuss: Exploratory, Descriptive, Explanatory, or Correlational research
- State which type(s) apply to THIS study
- Justify based on research questions

**4. Data Type (1 paragraph)**
- Specify: Quantitative, Qualitative, or Mixed Methods
- Justify the choice based on philosophy (Section 3.2) and objectives
- If quantitative: mention use of numerical data, statistical analysis
- If qualitative: mention themes, narratives
- Cite [(Creswell & Creswell, 2018)](URL)

**5. Integration and Summary (1 paragraph)**
- Explain how Strategy + Time Horizon + Data Type work together
- Connect back to research objectives
- Show alignment with philosophy from Section 3.2

CRITICAL REQUIREMENTS:
- MANDATORY: 3-5 citations per paragraph
- APA 7 STRICT: (Author, Year), grouped [(Author1, Year; Author2, Year)](URL)
- **CITATION DISTRIBUTION**: Every paragraph MUST contain at least one scholarly citation. Do not clump all citations at the beginning; distribute them naturally throughout.
- Justify every choice, reject alternatives explicitly
- Do NOT include section heading

Write the content now:"""

    def _build_target_population_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build prompt for target population with table."""
        return f"""Write section "{section_id} {title}" - define study population with table.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

{citation_context}

Write 4 paragraphs + 1 table:

**1. Unit of Analysis (1 paragraph)**
- Define "Unit of Analysis" [(Sekaran & Bougie, 2016)](URL)
- Clearly state the unit for THIS study (e.g., employees, students, households, organizations)
- Justify why this unit is appropriate for the research objectives

**2. Population Definition (1 paragraph)**
- Define the **Theoretical Population** (all possible members)
- Define the **Accessible Population** (those you can realistically reach in {self.state.case_study})
- Explain any difference between theoretical and accessible populations

**3. Population Characteristics (1 paragraph)**
- Describe key characteristics of the target population (e.g., demographics, roles, locations)
- Mention the geographic/organizational scope in {self.state.case_study}
- Estimate the total population size (use realistic numbers based on context)

**4. Population Distribution Table (MANDATORY)**
Create **Table 3.1: Target Population Distribution**

Format as follows:
```
Table 3.1: Target Population Distribution

| Category/Strata          | Population (N) | Percentage (%) |
|--------------------------|----------------|----------------|
| [Group 1, e.g., Managers]| [realistic #]  | [calculate %]  |
| [Group 2, e.g., Staff]   | [realistic #]  | [calculate %]  |
| [Group 3, if applicable] | [realistic #]  | [calculate %]  |
| **Total**                | **[sum]**      | **100%**       |

Source: [Realistic source, e.g., "Human Resource Records, 2024" or "Ministry of Health Database, 2023"]
```

After the table, write 2-3 sentences interpreting the distribution (e.g., "As shown in Table 3.1, managers constitute X% of the population...")

CRITICAL REQUIREMENTS:
- Use REALISTIC population numbers appropriate to {self.state.case_study}
- Ensure percentages add up to 100%
- Minimum 3 citations per paragraph
- APA 7 format
- **CITATION DISTRIBUTION**: Citations must be distributed throughout the text, not just at the start.
- Do NOT include section heading

Write the content now:"""

    def _build_sampling_procedures_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build prompt for sampling procedures."""
        include_sample_size = "sample size" in (title or "").lower()
        sample_size_block = ""
        paragraph_count = 6
        if include_sample_size:
            paragraph_count = 8
            meth_ctx = self.state.parameters.get('methodology_context', {})
            user_n = meth_ctx.get('sampling', {}).get('sample_size') or self.state.parameters.get('sample_size') or 385
            from services.research_context_manager import ResearchContextManager
            config = {
                'sample_size': user_n,
                'research_design': meth_ctx.get('research_design', 'survey'),
                'topic': self.state.topic,
                'case_study': self.state.case_study
            }
            rcm = ResearchContextManager(config)
            justification_data = rcm.get_sample_size_justification()
            citation = justification_data['citation']
            method_name = justification_data['method']
            prompt_instruction = justification_data['prompt_text']

            sample_size_block = f"""

**5. Sample Size Determination (2 paragraphs + calculation block)**
- Define sample size with scholarly citations ({citation}; Yamane, 1967; Cochran, 1977).
- Justify the chosen method for this study (use {method_name}).
- Explicitly state the final sample size n={user_n} and link it to the study design.

{prompt_instruction}

**Sample Size Calculation (Step-by-Step):**
1. State the formula on its own line using $$...$$.
2. List each substitution step with actual values.
3. Simplify step-by-step.
4. Conclude with the final result ‚âà n={user_n}.

**Table: Sample Size Distribution by Stratum (if applicable)**

| Strata/Category | Population (N) | Proportion | Sample Size (n) | Sampling Method |
|-----------------|----------------|------------|-----------------|------------------|
| [Stratum 1]     | [realistic #]  | [0.XX]     | [proportional]  | Stratified/Purposive |
| [Stratum 2]     | [realistic #]  | [0.XX]     | [proportional]  | Stratified/Purposive |
| **Total**       | **[Realistic N]** | **1.00**   | **{user_n}** | ‚Äì                |
"""

        return f"""Write section "{section_id} {title}" - comprehensive sampling methodology.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

{citation_context}

Write {paragraph_count} detailed paragraphs:

**1. Sampling Design Choice (1 paragraph)**
- Compare **Probability Sampling** (random, representative) vs. **Non-Probability Sampling** (purposive, convenience)
- **JUSTIFY YOUR CHOICE** for this study
- **REJECT THE ALTERNATIVE**: Why the other approach was unsuitable
- Cite [(Kothari, 2004; Saunders et al., 2019)](URL)

**2. Specific Sampling Technique (2 paragraphs)**
- If Probability: Evaluate Simple Random, Stratified Random, Systematic, Cluster
- If Non-Probability: Evaluate Convenience, Purposive, Snowball, Quota
- **JUSTIFY YOUR SPECIFIC TECHNIQUE** (e.g., "Stratified Random Sampling {self._get_tense_version(self.state.is_proposal)['selected']} to ensure representation across...")
- Explain how strata were defined (if stratified) or selection criteria (if purposive)
- Cite sampling literature [(Sekaran & Bougie, 2016)](URL)

**3. Step-by-Step Sampling Procedure (2 paragraphs)**
CRITICAL: Provide EXACT procedural steps:
- Step 1: How the sampling frame was obtained (e.g., "The employee payroll list from...")
- Step 2: How strata were defined (e.g., "Employees were categorized by department...")  
- Step 3: How respondents were selected FROM EACH STRATUM (e.g., "Using a random number generator...")
- Step 4: Replacement or non-replacement protocol

**4. Mitigating Sampling Bias (1 paragraph)**
- Discuss potential sources of sampling bias (e.g., non-response, selection bias)
- Explain how your procedure minimizes bias
- Mention ensuring representation across key demographics
{sample_size_block}

CRITICAL REQUIREMENTS:
- MANDATORY: 3-5 citations per paragraph
- Be EXTREMELY specific about procedures - a researcher should be able to replicate
- APA 7 format
- **CITATION DISTRIBUTION**: Spread citations naturally within sentences. Avoid citation dumping.
```
- Do NOT include section heading

Write the content now:"""

    def _build_sample_size_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build sample size prompt - Prioritizes user n and selects BEST justification."""
        
        # 1. Get User Input (n)
        meth_ctx = self.state.parameters.get('methodology_context', {})
        user_n = meth_ctx.get('sampling', {}).get('sample_size') or self.state.parameters.get('sample_size')
        
        # 2. Setup Context Manager
        from services.research_context_manager import ResearchContextManager
        
        # Ensure we have a valid config dict to pass
        config = {
            'sample_size': user_n or self.state.parameters.get('sample_size') or 385,
            'research_design': meth_ctx.get('research_design', 'survey'),
            'topic': self.state.topic,
            'case_study': self.state.case_study
        }
        
        # Pass population config if available
        rcm = ResearchContextManager(config)
        # Manually inject pre-calculated population if it exists in context
        if meth_ctx.get('population'):
            # We trust RCM to handle this or we just rely on its own calculation which matches our logic
            pass

        # 3. Get Intelligent Justification
        justification_data = rcm.get_sample_size_justification()
        
        citation = justification_data['citation']
        method_name = justification_data['method']
        prompt_instruction = justification_data['prompt_text']
        
        objectives_context = ""
        objective_list = self._get_objective_list()
        if objective_list:
            obj_text = "\\n".join([f"- {obj}" for obj in objective_list])
            objectives_context = f"\\n\\nSTUDY OBJECTIVES:\\n{obj_text}\\n"

        return f"""Write content for sample size determination section.

**CRITICAL: Do NOT write the heading "{section_id} {title}" - it will be added automatically. Start directly with the scholarly definition.**

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}{objectives_context}

{citation_context}

**MANDATORY OPENING**: Begin with scholarly definition:
"Sample size, as defined by {citation}, refers to the number of observations or cases selected from a population to constitute a representative subset for statistical analysis..."

Cite 2-3 scholars ({citation}; Yamane, 1967; Cochran, 1977).

**LANGUAGE**: UK English (analyse, realise, organisation, whilst)
**TENSE**: {self._get_tense_version(self.state.is_proposal)['used'].capitalize()} tense throughout.

**CONTENT STRUCTURE:**

Paragraph 1: Define sample size with scholarly citations, explain importance.

Paragraph 2: Justify sampling strategy selection (e.g., Stratified Random or Purposive).

        **Paragraph 3 & 4 (CRITICAL JUSTIFICATION):**
        Use the **{method_name}** method as it is best suited for this study's parameters (n={config['sample_size']}, Design={config['research_design']}).

        {prompt_instruction}

        **MANDATORY CALCULATION BLOCK (NO HEADING, USE BOLD LABEL ONLY):**
        After paragraph 4, add:
        **Sample Size Calculation (Step-by-Step):**
        - Provide a numbered list with each step on its own line.
        - Always show the values used (N, e, Z/œá¬≤, P) where applicable.
        - Include the formula on its own line using $$...$$.
        - Show substitution, simplification, and final result ‚âà n={config['sample_size']}.
        - If the method is non-formula (e.g., saturation or rule-of-thumb), show the decision steps and numeric justification (range/threshold ‚Üí selected n).

**ALTERNATIVE METHODS PARAGRAPH (REQUIRED):**
Add a short paragraph (3-5 sentences) listing at least two alternative sample size approaches (e.g., Yamane, Cochran, Krejcie & Morgan, power analysis) and briefly explain why the chosen method is most appropriate for this study's design and context.

Paragraph 5: Justify adequacy, mention power analysis if applicable.

Paragraph 6: Present distribution table (if applicable for n={config['sample_size']}):

**Table 3.7: Sample Size Distribution by Stratum**

| Strata/Category | Population (N) | Proportion | Sample Size (n) | Sampling Method |
|-----------------|----------------|------------|-----------------|------------------|
| [Stratum 1]     | [realistic #]  | [0.XX]     | [proportional]  | Stratified/Purposive |
| [Stratum 2]     | [realistic #]  | [0.XX]     | [proportional]  | Stratified/Purposive |
| **Total**       | **[Realistic N]** | **1.00**   | **{config['sample_size']}** | ‚Äì                |

*Source: Researcher's computation, 2024*

Paragraph 7: Interpret table.

        **FORMATTING RULES:**
        - NO section heading
        - UK English spelling
        - Past tense throughout
        - Display equations on their own line using $$...$$ (no inline formulas)
        - If any formula is used, include a numbered, step-by-step calculation list
- Markdown tables with | pipes
- **Bold** for totals row
- NO PLACEHOLDERS - use realistic {self.state.case_study} context

Write the content now:"""

    def _build_data_instruments_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build data instruments prompt with intelligent tool selection."""
        objectives_context = ""
        objective_list = self._get_objective_list()
        if objective_list:
            obj_text = "\n".join([f"- {obj}" for obj in objective_list])
            objectives_context = f"\n\nSTUDY OBJECTIVES (analyze to decide tools):\n{obj_text}\n"
        
        return f"""Write content for data collection instruments section.

**CRITICAL: Do NOT write the heading "{section_id} {title}" - it will be added automatically. Start directly with the scholarly definition.**

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}{objectives_context}

{citation_context}

**MANDATORY OPENING**: Begin with scholarly definition:
"Data collection instruments, as defined by Creswell (2014), are tools used to gather information from respondents to address research questions..."

Cite 2-3 scholars (Creswell, 2014; Kothari, 2004; Sekaran & Bougie, 2016).

**LANGUAGE**: UK English (analyse, whilst, organisation)
**TENSE**: {self._get_tense_version(self.state.is_proposal)['used'].capitalize()} tense throughout (e.g., "{self._get_tense_version(self.state.is_proposal)['adopted']}", "{self._get_tense_version(self.state.is_proposal)['developed']}", "{self._get_tense_version(self.state.is_proposal)['administered']}")

**INTELLIGENT TOOL SELECTION:**

ANALYZE the study objectives and DECIDE the most appropriate instrument(s):

**Decision Logic:**
- If objectives measure ATTITUDES/PERCEPTIONS/OPINIONS ‚Üí **Structured Questionnaire** (Likert Scale)
- If objectives explore EXPERIENCES/MEANINGS ‚Üí **Interview Guide** (Semi-structured)
- If objectives examine BEHAVIORS/PRACTICES ‚Üí **Observation Checklist**
- If objectives analyze DOCUMENTS/RECORDS ‚Üí **Document Analysis Guide**
- If objectives test CAUSE-EFFECT ‚Üí **Experimental Protocol**

**For Quantitative Studies (most common):**

Paragraph 1: **Instrument Selection and Justification**
- State chosen instrument (e.g., "A structured questionnaire {self._get_tense_version(self.state.is_proposal)['adopted']}...")
- Justify based on:
  * Study objectives (measuring attitudes/perceptions)
  * Sample size (n > 100 requires standardized tool)
  * Data type needed (quantitative for statistical analysis)
  * Efficiency (large sample, geographical spread)
- Cite (Kothari, 2004; Creswell, 2014)

Paragraph 2: **Questionnaire Structure**
Detail the sections:

**Section A: Demographic Information (6 items)**
- Age, Gender, Education Level, Work Experience, Position, [Context-specific variable]
- Scales: Nominal and Ordinal
- Justification for each variable

**Section B: [Independent Variable 1 from objectives] (8-10 items)**
- Adapted from [Validated Source, Year]
- 5-Point Likert Scale
- Sample items provided

**Section C: [Independent Variable 2 from objectives] (8-10 items)**
- Adapted from [Validated Source, Year]
- 5-Point Likert Scale
- Sample items provided

**Section D: [Dependent Variable from objectives] (8-10 items)**
- Adapted from [Validated Source, Year]
- 5-Point Likert Scale
- Sample items provided

**Total Items:** 40-44 items

Paragraph 3: **Measurement Scales**
- Explain 5-Point Likert Scale:
  * 1 = Strongly Disagree
  * 2 = Disagree
  * 3 = Neutral
  * 4 = Agree
  * 5 = Strongly Agree
- Justify choice (captures variance, familiar, psychometrically sound)
- Cite (Likert, 1932)

Paragraph 4: **Item Development**
- Items adapted from validated instruments in literature
- Context-specific modifications for {self.state.case_study}
- Mix of positive and negative items (reverse coding)
- Pilot tested for clarity
- Provide 2-3 sample items per section

Paragraph 5: **Administration Mode**
- State mode (self-administered, drop-and-pick, online, etc.)
- Justify based on:
  * Sample size and distribution
  * Literacy level
  * Cost-effectiveness
  * Response rate expectations
- Estimated completion time (15-20 minutes)

**FORMATTING RULES:**
- NO section heading
- UK English spelling
- Past tense throughout
- Start with scholarly definition
- 3-5 citations per paragraph
- **CITATION DISTRIBUTION**: Distribute citations evenly within paragraphs.
- Provide SPECIFIC sample items (not placeholders)
- Use realistic context from {self.state.case_study}

Write the content now:"""

    def _build_data_sources_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build data sources prompt for methodology."""
        objective_list = self._get_objective_list()
        objectives_context = ""
        if objective_list:
            obj_text = "\n".join([f"- {obj}" for obj in objective_list])
            objectives_context = f"\n\nSTUDY OBJECTIVES:\n{obj_text}\n"
        return f"""Write content for the data sources section.

**CRITICAL: Do NOT write the heading "{section_id} {title}". Start directly with the definition.**

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}{objectives_context}

{citation_context}

Include:
1. A brief scholarly definition of data sources in research.
2. Distinction between primary and secondary data with examples.
3. Clear statement of the data sources used in this study and why they fit the objectives and design.

REQUIREMENTS:
- UK English spelling
- Formal academic tone
- Past tense where appropriate
- 2-3 citations per paragraph
- No bullet list headings

Write the content now:"""

    def _build_primary_data_sources_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build primary data sources prompt."""
        return f"""Write content for the primary data sources subsection.

**CRITICAL: Do NOT write the heading "{section_id} {title}". Start directly with the explanation.**

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

{citation_context}

Cover:
- What counts as primary data for this study
- The instruments used (questionnaires, interviews, observation) and why
- How primary data align with the study objectives

REQUIREMENTS:
- UK English spelling
- Formal academic tone
- Past tense where appropriate
- 2-3 citations per paragraph

Write the content now:"""

    def _build_secondary_data_sources_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build secondary data sources prompt."""
        return f"""Write content for the secondary data sources subsection.

**CRITICAL: Do NOT write the heading "{section_id} {title}". Start directly with the explanation.**

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

{citation_context}

Cover:
- What counts as secondary data for this study
- Typical sources (journal articles, government reports, institutional records)
- How secondary data complement primary data for the objectives

REQUIREMENTS:
- UK English spelling
- Formal academic tone
- Past tense where appropriate
- 2-3 citations per paragraph

Write the content now:"""

    def _build_validity_reliability_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build validity/reliability prompt - UK English, past tense, scholarly definition."""
        return f"""Write content for validity and reliability testing section.

**CRITICAL: Do NOT write the heading "{section_id} {title}" - it will be added automatically. Start directly with the scholarly definition.**

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

{citation_context}

**MANDATORY OPENING**: Begin with scholarly definition:
"Validity and reliability, as defined by Hair et al. (2019), constitute the fundamental psychometric properties that ensure research instruments measure what they purport to measure consistently and accurately..."

Cite 2-3 scholars (Hair et al., 2019; Sekaran & Bougie, 2016; Tavakol & Dennick, 2011).

**LANGUAGE**: UK English (analyse, realise, whilst, amongst)
**TENSE**: {self._get_tense_version(self.state.is_proposal)['used'].capitalize()} tense throughout (e.g., "{self._get_tense_version(self.state.is_proposal)['tested']}", "{self._get_tense_version(self.state.is_proposal)['assessed']}", "{self._get_tense_version(self.state.is_proposal)['calculated']}")

**CONTENT STRUCTURE:**

Paragraph 1: Define validity and reliability with scholarly citations

Paragraph 2: Introduce Cronbach's Alpha for reliability testing:

$$\\alpha = \\frac{{K}}{{K-1}}\\left(1 - \\frac{{\\sum\\sigma_{{y_i}}^2}}{{\\sigma_x^2}}\\right)$$

Where:
- Œ± = Cronbach's Alpha coefficient
- K = number of items in the scale
- œÉ¬≤(yi) = variance of individual item i
- œÉ¬≤(x) = variance of total scores
Then provide a numbered, step-by-step calculation list on separate lines. If no numeric values are provided, keep the steps symbolic (do NOT invent numbers).

Paragraph 3: Explain interpretation thresholds:
- Œ± > 0.9 = Excellent
- Œ± > 0.8 = Good
- Œ± > 0.7 = Acceptable  
- Œ± < 0.6 = Unacceptable

Cite (George & Mallery, 2003; Tavakol & Dennick, 2011)

Paragraph 4: Describe validity testing:
- Content validity: Expert panel review
- CVI formula:

$$CVI = \\frac{{\\text{{Experts rating relevant}}}}{{\\text{{Total experts}}}}$$

- Construct validity: Factor analysis (EFA/CFA)
- Cite (Polit & Beck, 2006; Hair et al., 2019)
After the CVI formula, include a short numbered list of calculation steps (symbolic only if data are not provided).

Paragraph 5: Describe pilot study (n=30, location, date, purpose)
NO PLACEHOLDERS like "University of X"

Paragraph 6: Present reliability results table:

**Table 3.9: Reliability Test Results (Pilot Study, n=30)**

| Variable/Scale | Number of Items | Cronbach's Alpha (Œ±) | Interpretation |
|----------------|-----------------|----------------------|----------------|
| [Scale 1 from study] | [#] | [0.7-0.9] | [Good/Acceptable] |
| [Scale 2 from study] | [#] | [0.7-0.9] | [Good/Acceptable] |
| [Scale 3 from study] | [#] | [0.7-0.9] | [Good/Acceptable] |
| [Scale 4 from study] | [#] | [0.7-0.9] | [Good/Acceptable] |
| **Overall Instrument** | **[total]** | **[0.8-0.9]** | **Good** |

*Source: Pilot study data, 2024*

Paragraph 7: Interpret results - all scales exceeded Œ± > 0.70, no items {self._get_tense_version(self.state.is_proposal)['collected']} (deleted)

**FORMATTING RULES:**
- NO section heading
- UK English spelling (whilst, amongst, analyse)
- Past tense throughout (was, were)
- Display equations on their own line using $$...$$ (no inline formulas)
- If any formula is used, include a numbered, step-by-step calculation list on separate lines
- Markdown tables with | pipes
- **Bold** for totals row
- *Italics* for source line
- Start with scholarly definition
- 3-5 citations per paragraph
- **CITATION DISTRIBUTION**: Distribute citations evenly.
- NO PLACEHOLDERS
- Use realistic {self.state.case_study} context

Write the content now:"""

    def _build_data_procedures_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build prompt for data collection procedures."""
        return f"""Write section "{section_id} {title}" - data collection procedural details.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

{citation_context}

Write 4 paragraphs:

**1. Primary Data Collection Method (1 paragraph)**
- Describe the administration method: 
  * **Drop-and-Pick-Later**: Questionnaires delivered and collected after [X days]
  * **Online Administration**: Google Forms/SurveyMonkey sent via email
  * **Face-to-Face**: Researcher-administered questionnaires
- Justify the method chosen for {self.state.case_study} context
- Mention date range of data collection (e.g., "March-April 2024" or "{self._get_tense_version(self.state.is_proposal)['conducted']} between...")

**2. Step-by-Step Collection Procedure (1 paragraph)**
CRITICAL: Provide exact procedural steps:
- Step 1: {self._get_tense_version(self.state.is_proposal)['obtained'].capitalize()} permission/introductory letter from university
- Step 2: Contacted [organizations/institutions] in {self.state.case_study}
- Step 3: {self._get_tense_version(self.state.is_proposal)['distributed'].capitalize()} questionnaires to sampled respondents
- Step 4: Provided clear instructions and {self._get_tense_version(self.state.is_proposal)['ensured']} confidentiality
- Step 5: {self._get_tense_version(self.state.is_proposal)['collected'].capitalize()} completed questionnaires
- Step 6: Checked for completeness and clarity

**3. Response Rate Management (1 paragraph)**
- Discuss strategies to maximize response rate:
  * Follow-up reminders (phone calls, emails)
  * Introductory letter explaining study purpose
  * Assurance of confidentiality and anonymity
  * Convenient return methods
  * Mention target response rate (e.g., >70%)
- Cite [(Fowler, 2014)](URL)

**4. Secondary Data Sources (1 paragraph)**
- Identify secondary data sources: Journal articles, books, government reports, organizational records
- Explain how secondary data supplemented primary data or informed literature review
- Mention databases accessed (e.g., Google Scholar, PubMed, organizational archives)

CRITICAL REQUIREMENTS:
- MANDATORY: 3-5 citations per paragraph
- **CITATION DISTRIBUTION**: Spread citations naturally.
- Be very specific about procedures - replicability is key
- APA 7 format
- Do NOT include section heading

Write the content now:"""

    def _build_data_analysis_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build prompt for data analysis procedures with statistical tests."""
        return f"""Write section "{section_id} {title}" - comprehensive data analysis methods.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}
MANDATORY ANALYSES: {', '.join(self.state.parameters.get('methodology_context', {}).get('preferred_analyses', ['Pearson Correlation', 'Multiple Regression']))}

{citation_context}

Write 6 paragraphs:

**0. ANALYSIS OVERVIEW**
- You MUST mention and justify the MANDATORY ANALYSES specified above.

**1. Data Preparation (1 paragraph)**
- **Coding**: Assigning numerical codes to responses (e.g., Male=1, Female=2, Likert 1-5)
- **Data Entry**: Entering data into statistical software
- **Cleaning**: Checking for missing data, outliers, inconsistencies
- **Handling Missing Data**: Deletion or imputation strategy
- Cite [(Pallant, 2020)](URL)

**2. Statistical Software (1 paragraph)**
- Specify the software: **SPSS Version [27]**, **AMOS**, **SmartPLS**, or **Stata**
- Justify the choice based on study requirements (e.g., "SPSS {self._get_tense_version(self.state.is_proposal)['selected']} for its robust...")
- Mention version number for reproducibility

**3. Descriptive Statistics (1 paragraph)**
- List descriptive tests used:
  * **Frequencies and Percentages**: For demographic variables (Section A)
  * **Mean and Standard Deviation**: For Likert scale variables (Sections B-D)
  * **Tables and Graphs**: For data presentation
- Purpose: Profile respondents and describe variable distributions
- Cite [(Field, 2018)](URL)

**4. Inferential Statistics - Correlation Analysis (1 paragraph)**
- Introduce **Pearson Correlation Coefficient (r)** for examining relationships
- Formula:
$$r = \\frac{{\\sum(x_i - \\bar{{x}})(y_i - \\bar{{y}})}}{{\\sqrt{{\\sum(x_i - \\bar{{x}})^2 \\sum(y_i - \\bar{{y}})^2}}}}$$
- After the formula, add a numbered list of calculation steps on separate lines (symbolic steps only; do NOT invent data).
- Interpret r values: -1 to +1 (strength and direction)
- Purpose: Test associations between independent and dependent variables
- Cite [(Cohen, 1988)](URL)

**5. Inferential Statistics - Regression Analysis (2 paragraphs)**

**Paragraph 1: Regression Model Specification**
- Introduce **Multiple Linear Regression** for testing effects/impacts
- Present the regression equation for THIS study:

$$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + \\varepsilon$$

Where:
- Y = Dependent Variable [specify from your topic]
- X‚ÇÅ, X‚ÇÇ, X‚ÇÉ = Independent Variables [specify from objectives]
- Œ≤‚ÇÄ = Intercept
- Œ≤‚ÇÅ, Œ≤‚ÇÇ, Œ≤‚ÇÉ = Regression coefficients
- Œµ = Error term
Then provide a numbered, step-by-step list describing how the model was estimated (no numeric values unless provided).

**Paragraph 2: Regression Assumptions and Tests**
- Mention assumptions: Linearity, Normality, Homoscedasticity, No Multicollinearity
- Tests: VIF for multicollinearity, Durbin-Watson for autocorrelation
- Significance level: Œ± = 0.05 (95% confidence)
- R¬≤, Adjusted R¬≤, F-statistic for model fit
- Cite [(Hair et al., 2019; Tabachnick & Fidell, 2019)](URL)

CRITICAL REQUIREMENTS:
- MANDATORY: LaTeX formulas for correlation and regression
- Specify the EXACT regression model for your topic
- Minimum 3-5 citations per paragraph
- **CITATION DISTRIBUTION**: Distribute citations naturally.
- APA 7 format
- Do NOT include section heading
- Display equations on their own line using $$...$$ (no inline formulas)
- If any formula is used, include a numbered, step-by-step calculation list on separate lines

Write the content now:"""

    def _build_ethical_considerations_prompt(self, section_id: str, title: str, citation_context: str) -> str:
        """Build prompt for ethical considerations."""
        return f"""Write section "{section_id} {title}" - comprehensive ethical protocols.

TOPIC: {self.state.topic}
CASE STUDY: {self.state.case_study}

{citation_context}

Write 4 paragraphs:

**1. Introduction to Research Ethics (1 paragraph)**
- Define research ethics: moral principles guiding research conduct [(Bryman, 2016)](URL)
- State the importance of ethical considerations in research involving human subjects
- Mention adherence to institutional and national ethical guidelines

**2. Core Ethical Pillars (2 paragraphs)**

**Informed Consent:**
- Explain how participants were informed about the study purpose, procedures, risks, and benefits
- Mention provision of information sheets and consent forms
- State that participation was entirely voluntary with right to withdraw
- Cite [(American Psychological Association, 2017)](URL)

**Confidentiality and Anonymity:**
- Describe measures to protect participant identity (anonymous questionnaires, codes instead of names)
- Explain data storage security (password-protected files, locked cabinets)
- Assure that data will only be used for research purposes
- Mention data retention period and disposal plan

**Prevention of Harm:**
- Discuss minimization of physical, psychological, social harm to participants
- State that questions were designed to be non-intrusive
- Mention debriefing procedures if applicable

**3. Ethical Approvals and Permissions (1 paragraph)**
- **Institutional Approval**: {self._get_tense_version(self.state.is_proposal)['obtained'].capitalize()} introductory letter from [University Name] Graduate School
- **Organizational Permissions**: Sought approval from relevant authorities in {self.state.case_study}
- **Ethics Review Board**: Mention if IRB/Ethics Committee approval {self._get_tense_version(self.state.is_proposal)['obtained']}
- **Informed Consent Documentation**: All participants {self._get_tense_version(self.state.is_proposal)['obtained']} (signed) consent forms before data collection

CRITICAL REQUIREMENTS:
- MANDATORY: 3-5 citations per paragraph
- Be specific about actual steps taken in THIS study
- APA 7 format
- Do NOT include section heading

Write the content now:"""





class QualitySwarm:
    """PhD-Grade Multi-Agent Quality Control System.
    
    4 Specialized Agents:
    1. Structural Analyst - Optimize structure, remove redundancy
    2. Stylistic Refinement - Enhance academic tone, readability
    3. Citation Integrity - Validate all citations, fix formatting
    4. Coherence Logic - Ensure logical flow and alignment
    """
    
    def __init__(self, state: ChapterState):
        self.state = state
        self._placeholder_author_pattern = re.compile(r"\b(author|anon|unknown)\b", re.IGNORECASE)

    def _extract_last_name(self, author: Any) -> str:
        if isinstance(author, dict):
            name = author.get("name") or author.get("family") or author.get("given") or ""
        else:
            name = str(author or "").strip()
        if not name:
            return ""
        if "," in name:
            return name.split(",")[0].strip()
        parts = name.split()
        return parts[-1] if parts else name

    def _collect_allowed_author_last_names(self) -> set:
        allowed = set()
        for papers in self.state.research.values():
            for paper in papers:
                for author in paper.authors or []:
                    last = self._extract_last_name(author)
                    if last:
                        allowed.add(last.lower())
        return allowed

    def _filter_citation_chunk(self, chunk: str, allowed_authors: set) -> str:
        match = re.search(r"(.+?),\s*(\d{4}[a-z]?)", chunk)
        if not match:
            return ""
        author_part = match.group(1).strip()
        if self._placeholder_author_pattern.search(author_part):
            return ""
        if allowed_authors:
            candidate_parts = re.split(r"\s+(?:and|&)\s+|,\s*", author_part)
            candidate_parts = [part.replace("et al.", "").strip() for part in candidate_parts if part.strip()]
            matched = False
            for part in candidate_parts:
                last = part.split()[-1] if part else ""
                if last and last.lower() in allowed_authors:
                    matched = True
                    break
            if not matched:
                return ""
        return chunk.strip()

    def _strip_invented_theory_sentences(self, text: str) -> str:
        triggers = [
            "generated for the present study",
            "generated for this study",
            "proposed for the present study",
            "proposed for this study",
            "this study proposes",
            "this study introduces",
            "novel theory",
            "new theory",
            "is proposed as"
        ]
        sentences = re.split(r"(?<=[.!?])\s+", text)
        filtered = []
        for sentence in sentences:
            if any(trigger in sentence.lower() for trigger in triggers):
                continue
            filtered.append(sentence)
        return " ".join(filtered).strip()

    def _sanitize_citations(self, text: str, allowed_authors: set, title: str) -> str:
        def repl_parenthetical(match: re.Match) -> str:
            content = match.group(1)
            parts = [part.strip() for part in content.split(";") if part.strip()]
            kept = []
            for part in parts:
                filtered = self._filter_citation_chunk(part, allowed_authors)
                if filtered:
                    kept.append(filtered)
            if not kept:
                return ""
            return f"({'; '.join(kept)})"

        def repl_bracket(match: re.Match) -> str:
            content = match.group(1)
            parts = [part.strip() for part in content.split(";") if part.strip()]
            kept = []
            for part in parts:
                filtered = self._filter_citation_chunk(part, allowed_authors)
                if filtered:
                    kept.append(filtered)
            if not kept:
                return ""
            return f"[{'; '.join(kept)}]"

        text = re.sub(r"\(([^()]*\d{4}[a-z]?(?:[^()]*)?)\)", repl_parenthetical, text)
        text = re.sub(r"\[([^\]]*\d{4}[a-z]?(?:[^\]]*)?)\]", repl_bracket, text)

        def repl_narrative(match: re.Match) -> str:
            author = match.group(1)
            year = match.group(2)
            if self._placeholder_author_pattern.search(author):
                return ""
            if allowed_authors:
                last = author.split()[-1].strip()
                if not last or last.lower() not in allowed_authors:
                    return ""
            return f"{author} ({year})"

        text = re.sub(r"\b([A-Z][A-Za-z\\-]+(?:\\s+et\\s+al\\.)?)\\s*\\((\\d{4}[a-z]?)\\)", repl_narrative, text)

        if "theor" in title.lower() or "framework" in title.lower():
            text = self._strip_invented_theory_sentences(text)

        text = re.sub(r"\s{2,}", " ", text)
        text = re.sub(r"\(\s*\)", "", text)
        text = re.sub(r"\[\s*\]", "", text)
        return text.strip()
    
    async def validate_and_combine(self) -> str:
        """Run 4-agent quality pipeline and combine sections."""
        await events.connect()
        
        await events.publish(
            self.state.job_id,
            "agent_working",
            {"agent": "quality_swarm", "agent_name": "Quality Control", "status": "running", "action": "Starting 4-agent quality pipeline...", "icon": "üîç"},
            session_id=self.state.session_id
        )
        
        # Phase 1: Combine raw sections first
        raw_content = self._combine_sections()
        
        # Phase 2: Run all 4 agents in parallel on each section
        await events.publish(
            self.state.job_id,
            "log",
            {"message": "üîç Running 4 quality agents in parallel..."},
            session_id=self.state.session_id
        )
        
        quality_tasks = [
            self._run_structural_agent(),
            self._run_stylistic_agent(),
            self._run_citation_agent(),
            self._run_coherence_agent(),
        ]
        
        await asyncio.gather(*quality_tasks)
        
        # Phase 3: Final assembly
        final_content = self._combine_sections()
        final_content += self._generate_references()
        
        self.state.final_content = final_content
        
        await events.publish(
            self.state.job_id,
            "log",
            {"message": "‚úÖ Quality control complete - PhD-ready output generated"},
            session_id=self.state.session_id
        )
        
        await events.publish(
            self.state.job_id,
            "stage_completed",
            {"stage": "complete", "status": "success"},
            session_id=self.state.session_id
        )
        
        return final_content
    
    async def _run_structural_agent(self) -> None:
        """AGENT 1: Structural Analyst - Optimize structure, remove redundancy."""
        await events.connect()
        
        await events.publish(
            self.state.job_id,
            "agent_activity",
            {"agent": "structural_analyst", "agent_name": "Structural Analyst", "status": "running", "action": "Analyzing structure & removing redundancy...", "type": "chapter_generator"},
            session_id=self.state.session_id
        )
        
        issues_found = []
        
        # Check for redundancy across sections
        all_content = " ".join([s.content for s in self.state.sections.values()])
        
        # Simple redundancy detection (repeated phrases)
        from collections import Counter
        words = all_content.lower().split()
        word_counts = Counter(words)
        common_repeated = [w for w, c in word_counts.items() if c > 10 and len(w) > 8]
        
        if common_repeated:
            issues_found.append(f"High-frequency terms: {', '.join(common_repeated[:5])}")
        
        # Check section lengths
        for section_id, section in self.state.sections.items():
            word_count = len(section.content.split())
            if word_count < 100:
                issues_found.append(f"Section {section_id} may be too short ({word_count} words)")
            elif word_count > 1500:
                issues_found.append(f"Section {section_id} may be too long ({word_count} words)")
        
        await events.publish(
            self.state.job_id,
            "log",
            {"message": f"üìê Structural Agent: {len(issues_found)} observations noted"},
            session_id=self.state.session_id
        )
    
    async def _run_stylistic_agent(self) -> None:
        """AGENT 2: Stylistic Refinement - Enhance academic tone & readability."""
        await events.connect()
        
        await events.publish(
            self.state.job_id,
            "agent_activity",
            {"agent": "stylistic_agent", "agent_name": "Stylistic Refinement", "status": "running", "action": "Analyzing academic tone & readability...", "type": "chapter_generator"},
            session_id=self.state.session_id
        )
        
        style_metrics = {
            "avg_sentence_length": 0,
            "passive_voice_count": 0,
            "academic_markers": 0
        }
        
        # Analyze each section for style
        total_sentences = 0
        total_words = 0
        
        for section in self.state.sections.values():
            sentences = section.content.split('.')
            for sentence in sentences:
                words = sentence.split()
                if len(words) > 3:
                    total_sentences += 1
                    total_words += len(words)
                    
                    # Check for passive voice markers
                    if any(marker in sentence.lower() for marker in ['was ', 'were ', 'been ', 'being ']):
                        style_metrics["passive_voice_count"] += 1
                    
                    # Check for academic markers
                    if any(marker in sentence.lower() for marker in ['however', 'furthermore', 'consequently', 'thus', 'therefore']):
                        style_metrics["academic_markers"] += 1
        
        if total_sentences > 0:
            style_metrics["avg_sentence_length"] = total_words / total_sentences
        
        await events.publish(
            self.state.job_id,
            "log",
            {"message": f"‚úèÔ∏è Style Agent: Avg sentence {style_metrics['avg_sentence_length']:.0f} words, {style_metrics['academic_markers']} academic transitions"},
            session_id=self.state.session_id
        )
    
    async def _run_citation_agent(self) -> None:
        """AGENT 3: Citation & Integrity - Validate citations, fix formatting."""
        await events.connect()
        
        await events.publish(
            self.state.job_id,
            "agent_activity",
            {"agent": "citation_agent", "agent_name": "Citation Integrity", "status": "running", "action": "Validating citations & APA 7 format...", "type": "chapter_generator"},
            session_id=self.state.session_id
        )
        
        citation_metrics = {
            "total_papers": 0,
            "with_doi": 0,
            "with_url": 0,
            "missing_link": 0,
            "malformed_citations": []
        }
        
        # Validate all research papers
        for scope, papers in self.state.research.items():
            for paper in papers:
                citation_metrics["total_papers"] += 1
                if paper.doi:
                    citation_metrics["with_doi"] += 1
                if paper.url:
                    citation_metrics["with_url"] += 1
                if not paper.doi and not paper.url:
                    citation_metrics["missing_link"] += 1
        
        # Check citations in content
        import re
        for section in self.state.sections.values():
            # Find malformed citations (e.g., "13)." instead of "(Author, Year)")
            malformed = re.findall(r'\d+\)', section.content)
            citation_metrics["malformed_citations"].extend(malformed)

        allowed_authors = self._collect_allowed_author_last_names()
        removed_citation_blocks = 0
        for section in self.state.sections.values():
            original = section.content
            cleaned = self._sanitize_citations(original, allowed_authors, section.title or "")
            if cleaned != original:
                removed_citation_blocks += 1
                section.content = cleaned
        
        self.state.total_citations = citation_metrics["total_papers"]
        
        status = "‚úÖ" if citation_metrics["missing_link"] == 0 else "‚ö†Ô∏è"
        await events.publish(
            self.state.job_id,
            "log",
            {"message": f"{status} Citation Agent: {citation_metrics['with_doi']}/{citation_metrics['total_papers']} have DOIs, {len(citation_metrics['malformed_citations'])} malformed, cleaned {removed_citation_blocks} sections"},
            session_id=self.state.session_id
        )
    
    async def _run_coherence_agent(self) -> None:
        """AGENT 4: Coherence & Logic - Ensure logical flow and alignment."""
        await events.connect()
        
        await events.publish(
            self.state.job_id,
            "agent_activity",
            {"agent": "coherence_agent", "agent_name": "Coherence Logic", "status": "running", "action": "Checking logical flow & alignment...", "type": "chapter_generator"},
            session_id=self.state.session_id
        )
        
        chapter_num = getattr(self.state, "chapter_number", 1)
        expected_map = {
            1: ["1.1", "1.2", "1.3", "1.4", "1.4.1", "1.4.2", "1.5", "1.6", "1.7", "1.8", "1.9", "1.10", "1.11", "1.12"],
            3: ["3.1", "3.2", "3.3", "3.4", "3.5", "3.6", "3.7", "3.8", "3.9", "3.10", "3.11", "3.12"]
        }
        expected_sections = expected_map.get(
            chapter_num,
            [sec for sec in self.state.sections.keys() if sec.startswith(f"{chapter_num}.")]
        )
        present_sections = list(self.state.sections.keys())

        objectives_content = ""
        questions_content = ""
        obj_count = 0
        q_count = 0
        if chapter_num == 1:
            objectives_content = self.state.sections.get("1.4.2", self.state.sections.get("1.4", SectionContent("", "", [], "pending", 0))).content
            questions_content = self.state.sections.get("1.5", SectionContent("", "", [], "pending", 0)).content
            obj_count = len([line for line in objectives_content.split('\n') if line.strip().startswith(('i.', 'ii.', 'iii.', 'iv.', '1.', '2.', '3.', '4.'))])
            q_count = len([line for line in questions_content.split('\n') if line.strip().startswith(('i.', 'ii.', 'iii.', 'iv.', '1.', '2.', '3.', '4.'))])

        coherence_score = 0
        if expected_sections:
            coherence_score = len(set(present_sections) & set(expected_sections)) / len(expected_sections)

        status = "‚úÖ" if coherence_score >= 0.8 else "‚ö†Ô∏è"
        objectives_label = str(obj_count) if chapter_num == 1 else "n/a"
        questions_label = str(q_count) if chapter_num == 1 else "n/a"
        await events.publish(
            self.state.job_id,
            "log",
            {"message": f"{status} Coherence Agent: {len(present_sections)}/{len(expected_sections)} sections, {objectives_label} objectives, {questions_label} questions"},
            session_id=self.state.session_id
        )
    
    def _combine_sections(self) -> str:
        """Combine all sections into final chapter."""
        # Dynamic chapter heading based on chapter_number
        chapter_num = getattr(self.state, 'chapter_number', 1)
        
        chapter_names = {
            1: "CHAPTER ONE\n# INTRODUCTION",
            2: "CHAPTER TWO\n# LITERATURE REVIEW",
            3: "CHAPTER THREE\n# RESEARCH METHODOLOGY",
            4: "CHAPTER FOUR\n# DATA PRESENTATION AND ANALYSIS",
            5: "CHAPTER FIVE\n# DISCUSSION OF FINDINGS",
            6: "CHAPTER SIX\n# CONCLUSION AND RECOMMENDATIONS"
        }
        
        chapter_heading = chapter_names.get(chapter_num, f"CHAPTER {chapter_num}\n# CHAPTER {chapter_num}")
        content = f"# {chapter_heading}\n\n"
        
        # Sort sections by ID - handle "2.10" format correctly
        def section_sort_key(item):
            section_id = item[0]
            try:
                parts = [int(p) for p in section_id.split(".")]
            except ValueError:
                return (999,)
            return tuple(parts)
        
        sorted_sections = sorted(self.state.sections.items(), key=section_sort_key)
        
        for section_id, section in sorted_sections:
            content += f"## {section_id} {section.title}\n\n"
            content += section.content + "\n\n"
        
        return content
    
    def _generate_references(self) -> str:
        """Generate references section with APA 7 formatting and anchor IDs for DOCX links."""
        refs = "\n\n---\n\n## References\n\n"
        
        # Collect all unique papers
        all_papers = []
        for papers in self.state.research.values():
            all_papers.extend(papers)
        
        # Remove duplicates by DOI
        seen_dois = set()
        unique_papers = []
        for paper in all_papers:
            key = paper.doi or paper.title
            if key not in seen_dois:
                seen_dois.add(key)
                unique_papers.append(paper)
        
        # FILTER: Only include papers that were actually cited in the content
        import re
        cited_papers = []
        full_content = " ".join([s.content for s in self.state.sections.values()])
        
        for paper in unique_papers:
            if not paper.authors: continue
            
            # Extract last names
            last_names = []
            for author in paper.authors:
                if isinstance(author, dict):
                    name = author.get("name", author.get("family", ""))
                else:
                    name = str(author)
                if name:
                    last_names.append(name.split()[-1] if ' ' in name.strip() else name.strip())
            
            if not last_names: continue
            
            # Check for citations strictly: Author...Year
            is_cited = False
            year_str = str(paper.year)
            
            for last_name in last_names:
                # Regex finds "Author...Year" within close proximity (up to 20 chars)
                # Accounts for: (Smith, 2020), Smith (2020), Smith & Jones (2020), Smith et al. (2020)
                pattern = re.compile(rf"{re.escape(last_name)}[^)]{{0,30}}{year_str}", re.IGNORECASE)
                if pattern.search(full_content):
                    is_cited = True
                    break
            
            if is_cited:
                cited_papers.append(paper)
        
        unique_papers = cited_papers
        
        # Sort alphabetically by first author (handle dict/str authors)
        def get_author_name(p):
            if not p.authors:
                return ""
            first = p.authors[0]
            if isinstance(first, dict):
                name = first.get("name", first.get("family", ""))
                return name if name else ""
            return str(first) if first else ""
        
        # Filter out papers without valid authors
        valid_papers = [p for p in unique_papers if get_author_name(p)]
        valid_papers.sort(key=get_author_name)
        
        # Generate references with anchor IDs for DOCX hyperlinks
        # Format: each reference as a separate paragraph (no bullets)
        for paper in valid_papers:
            author_name = get_author_name(paper)
            if not author_name:
                continue
            # Create anchor ID from first author last name and year
            first_author = author_name.split()[-1] if author_name else ""
            if not first_author:
                continue
            anchor_id = f"ref_{first_author}_{paper.year}".replace(" ", "_").replace(",", "")
            
            # APA 7 format with anchor - each reference on new paragraph
            apa_ref = paper.to_apa_full()
            if apa_ref:  # Only add if valid reference
                refs += f'<a id="{anchor_id}"></a>\n'
                refs += f"{apa_ref}\n\n"
        
        return refs


class ParallelChapterGenerator:
    """Main orchestrator for parallel chapter generation."""
    
    def __init__(self):
        self.state: Optional[ChapterState] = None

    def _normalize_objectives(self, objectives: Any) -> List[str]:
        """Normalize objectives to a clean list of strings."""
        if not objectives:
            return []
        if isinstance(objectives, dict):
            candidates = objectives.get("specific") or objectives.get("general") or []
            return [o for o in candidates if isinstance(o, str) and o.strip()]
        if isinstance(objectives, list):
            return [o for o in objectives if isinstance(o, str) and o.strip()]
        return []

    def _extract_objective_keywords(self, objective: str) -> List[str]:
        """Extract key terms for objective coverage checks."""
        stop_words = {
            "the", "and", "for", "with", "from", "that", "this", "which", "their", "of", "in",
            "on", "a", "an", "between", "among", "to", "assess", "examine", "analyze",
            "evaluate", "investigate", "determine", "study", "explore", "impact", "effect",
            "influence", "relationship", "role", "factors", "factors", "case", "study"
        }
        cleaned = re.sub(r"[^\w\s]", " ", objective.lower())
        tokens = [t for t in cleaned.split() if len(t) > 3 and t not in stop_words]
        # Keep first few unique tokens for stable matching
        seen = set()
        keywords = []
        for token in tokens:
            if token not in seen:
                seen.add(token)
                keywords.append(token)
            if len(keywords) >= 6:
                break
        return keywords

    def _audit_objective_coverage(self, content: str, objectives: List[str]) -> List[str]:
        """Return objectives that are not clearly covered in the content."""
        if not objectives:
            return []
        lower_content = content.lower()
        missing = []
        for obj in objectives:
            obj_clean = obj.strip()
            if not obj_clean:
                continue
            if obj_clean.lower() in lower_content:
                continue
            keywords = self._extract_objective_keywords(obj_clean)
            if not keywords:
                missing.append(obj_clean)
                continue
            hit_count = sum(1 for kw in keywords if kw in lower_content)
            if hit_count < max(1, min(2, len(keywords))):
                missing.append(obj_clean)
        return missing

    async def _include_uploaded_sources(self, unique_results: List[ResearchResult], seen_identifiers: set) -> None:
        """Fetch retrieval results for uploaded PDFs/data and add them to the research pool."""
        if not self.state:
            return
        try:
            user_results = await search_user_documents(
                workspace_id=self.state.workspace_id,
                query=self.state.topic,
                n_results=8
            )
        except Exception as upload_err:
            print(f"‚ö†Ô∏è Uploaded sources search failed: {upload_err}")
            return

        added = 0
        for entry in user_results.get("results", []):
            metadata = entry.get("metadata", {}) or {}
            doc_id = metadata.get("document_id") or metadata.get("filename")
            identifier = f"user_upload:{doc_id or entry.get('id')}"
            if not doc_id or identifier in seen_identifiers:
                continue

            title = metadata.get("title") or metadata.get("filename") or "User Uploaded Document"
            author = metadata.get("author")
            authors = [author] if author else ["User Upload"]
            year_val = metadata.get("year")
            try:
                year = int(year_val)
            except (TypeError, ValueError):
                year = datetime.now().year

            research = ResearchResult(
                title=title,
                authors=authors,
                year=year,
                doi="",
                url=metadata.get("file_path") or metadata.get("filename") or "",
                abstract=(entry.get("text") or "")[:500],
                source="user_upload",
                venue=metadata.get("filename", "")
            )

            unique_results.append(research)
            seen_identifiers.add(identifier)
            added += 1

        if added:
            await events.publish(
                self.state.job_id,
                "log",
                {"message": f"üìÑ Added {added} user-uploaded source{'s' if added != 1 else ''} to the research pool"},
                session_id=self.state.session_id
            )

    async def _enforce_quality_gates(
        self,
        content: str,
        chapter_number: int,
        job_id: str,
        session_id: str,
        sample_size: Optional[int] = None,
        objectives: Any = None
    ) -> None:
        """Enforce PhD quality thresholds and objective coverage."""
        from services.phd_quality_checker import PhDQualityChecker
        from core.config import settings

        metadata = {}
        if sample_size:
            metadata["sample_size"] = sample_size

        checker = PhDQualityChecker()
        report = checker.check_chapter(content, chapter_number=chapter_number, metadata=metadata)

        await events.publish(
            job_id,
            "log",
            {"message": f"QUALITY CHECK: score={report['overall_score']:.1f}/{settings.PHD_QUALITY_MIN_SCORE} "
                        f"level={report['quality_level']} critical={report['critical_issues']} major={report['major_issues']}"},
            session_id=session_id
        )

        objectives_list = self._normalize_objectives(objectives)
        missing_objectives = []
        if chapter_number in [2, 3, 4, 5] and objectives_list:
            missing_objectives = self._audit_objective_coverage(content, objectives_list)
            if missing_objectives:
                sample_missing = "; ".join(missing_objectives[:3])
                await events.publish(
                    job_id,
                    "log",
                    {"message": f"OBJECTIVE COVERAGE FAIL: {len(missing_objectives)} objectives not clearly covered (e.g., {sample_missing})"},
                    session_id=session_id
                )

        # Enforce minimum PhD standards
        quality_failed = report["overall_score"] < settings.PHD_QUALITY_MIN_SCORE or report["critical_issues"] > 0
        objectives_failed = bool(missing_objectives) and settings.PHD_OBJECTIVE_COVERAGE_STRICT
        failed = quality_failed or objectives_failed

        if failed:
            if settings.PHD_QUALITY_STRICT:
                raise ValueError(
                    f"Quality gate failed for Chapter {chapter_number}: "
                    f"score={report['overall_score']:.1f}, critical={report['critical_issues']}, "
                    f"missing_objectives={len(missing_objectives)}"
                )
            await events.publish(
                job_id,
                "log",
                {"message": f"QUALITY WARNING: Chapter {chapter_number} failed gates but strict mode is OFF (continuing)."},
                session_id=session_id
            )
    
    async def generate(
        self,
        topic: str,
        case_study: str,
        job_id: str,
        session_id: str,
        workspace_id: str = "default",
        background_style: str = "inverted_pyramid",
        thesis_type: str = "phd",
        sample_size: int = None,
        objectives: List[str] = None,
        allow_quality_failure: bool = False
    ) -> str:
        """Generate full chapter using parallel agents."""
        
        # CLEAN METADATA from topic
        import re
        topic = re.sub(r'n\s*=\s*\d+', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'topic\s*=\s*["\'].*?["\']', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'case[_\s]?study\s*=\s*["\'].*?["\']', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'design\s*=\s*\w+', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'/uoj_phd\s*\w*', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'\s+', ' ', topic).strip()

        start_time = datetime.now()
        
        # Validate background style
        if background_style not in BACKGROUND_STYLES:
            background_style = "inverted_pyramid"
        
        # Initialize state with selected background style
        self.state = ChapterState(
            topic=topic,
            case_study=case_study,
            job_id=job_id,
            session_id=session_id,
            workspace_id=workspace_id,
            background_style=background_style,
            thesis_type=thesis_type # Pass thesis_type to state
        )
        self.state.parameters["thesis_type"] = thesis_type # Also set in parameters
        if sample_size:
            self.state.parameters["sample_size"] = sample_size
        try:
            if objectives:
                normalized = normalize_objectives(objectives, topic, case_study)
                self.state.objectives = normalized
                specific_count = len(normalized.get("specific", []) or [])
                if specific_count:
                    self.state.parameters["objective_count"] = specific_count
            else:
                db = resolve_thesis_db(session_id, workspace_id)
                saved_objectives = db.get_objectives() if db else None
                if saved_objectives:
                    self.state.objectives = saved_objectives
                    specific_count = len(saved_objectives.get("specific", []) or [])
                    if specific_count:
                        self.state.parameters["objective_count"] = specific_count
        except Exception as e:
            print(f"‚ö†Ô∏è Could not load objectives for Chapter 1: {e}")
        
        # Try to load variables from thesis plan for consistency (Golden Thread)
        try:
            from services.workspace_service import WORKSPACES_DIR
            import json
            workspace_dir = WORKSPACES_DIR / (workspace_id or "default")
            plan_path = workspace_dir / "thesis_plan.json"
            if plan_path.exists():
                with open(plan_path, 'r') as f:
                    plan_data = json.load(f)
                    obj_vars = plan_data.get("objective_variables", {})
                    # Store variables in state so prompt builders can access them
                    self.state.objective_variables = obj_vars
        except Exception as e:
            print(f"Error loading thesis plan in Ch1: {e}")
        
        await events.connect()
        
        # BRANCH TO UOJ GENERAL (Bachelor's) ONLY
        # PhD theses use standard structure with "Setting the Scene" etc.
        if thesis_type == "general":
             try:
                 from services.outline_parser import outline_parser
                 from services.workspace_service import WORKSPACES_DIR
                 outline_path = WORKSPACES_DIR / workspace_id / "outline.json"
                 if outline_path.exists():
                     self.state.parameters["custom_outline"] = outline_parser.load_outline(workspace_id)
                 else:
                     # Retrieve country from entities or default
                     db = resolve_thesis_db(session_id, workspace_id)
                     country = "South Sudan"  # Default country for UoJ theses
                     saved_objectives = db.get_objectives() or {}
                     return await generate_chapter_one_uoj(
                         topic, case_study, country, job_id, session_id, workspace_id, saved_objectives, thesis_type=thesis_type
                     )
             except Exception as e:
                 print(f"‚ö†Ô∏è Could not load outline for UoJ Chapter 1: {e}")
                 db = resolve_thesis_db(session_id, workspace_id)
                 country = "South Sudan"
                 saved_objectives = db.get_objectives() or {}
                 return await generate_chapter_one_uoj(
                     topic, case_study, country, job_id, session_id, workspace_id, saved_objectives, thesis_type=thesis_type
                 )
        await events.publish(
            job_id,
            "stage_started",
            {"stage": "chapter_generation", "message": f"üöÄ Starting parallel chapter generation for: {topic}"},
            session_id=session_id
        )
        
        # Agent activity for preview panel
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "chapter_generator", "agent_name": "Chapter Generator", "status": "running", "action": f"Starting chapter generation for: {topic}", "icon": "üìñ"},
            session_id=session_id
        )
        
        await events.publish(
            job_id,
            "response_chunk",
            {"chunk": f"# üìñ Generating Chapter One\n\n**Topic:** {topic}\n**Case Study:** {case_study}\n\n---\n\n", "accumulated": "Starting..."},
            session_id=session_id
        )
        
        # Phase 1: Research Swarm (parallel searches)
        await events.publish(job_id, "log", {"message": "üì° PHASE 1: Launching Research Swarm..."}, session_id=session_id)
        await events.publish(job_id, "agent_activity", {"agent": "research_swarm", "agent_name": "Research Swarm", "status": "running", "action": "Searching 6 academic databases in parallel...", "icon": "üîç"}, session_id=session_id)
        
        research_swarm = ResearchSwarm(self.state)
        
        # Start initial search
        await research_swarm.search_all()
        
        await events.publish(job_id, "agent_activity", {"agent": "research_swarm", "agent_name": "Research Swarm", "status": "completed", "action": f"Found {sum(len(p) for p in self.state.research.values())} papers", "icon": "‚úÖ"}, session_id=session_id)
        
        # Start continuous background search (runs during writing)
        async def continuous_search():
            """Keep searching for more papers while writing happens."""
            await asyncio.sleep(5)  # Wait for writing to start
            for round_num in range(3):  # 3 additional search rounds
                await events.publish(job_id, "log", {"message": f"üîç Background search round {round_num + 1}..."}, session_id=session_id)
                try:
                    # Search with different queries
                    additional_queries = [
                        f"{topic} research findings",
                        f"{topic} {case_study} study",
                        f"{topic} impact assessment"
                    ]
                    for query in additional_queries[:1]:  # One query per round
                        results = await academic_search_service.search_academic_papers(query, max_results=3)
                        for paper in results:
                            try:
                                research = ResearchResult(
                                    title=paper.get("title", ""),
                                    authors=paper.get("authors", [])[:5],
                                    year=paper.get("year") or 2023,
                                    doi=paper.get("doi", ""),
                                    url=paper.get("url", ""),
                                    abstract=paper.get("abstract", "")[:500],
                                    source="continuous",
                                    venue=paper.get("venue", "")
                                )
                                accepted, _score = research_swarm._is_result_acceptable(research)
                                if not accepted:
                                    continue
                                # Add to state if not duplicate
                                if not any(p.doi == research.doi and research.doi for scope in self.state.research.values() for p in scope):
                                    if "continuous" not in self.state.research:
                                        self.state.research["continuous"] = []
                                    self.state.research["continuous"].append(research)
                                    
                                    # Save to sources
                                    normalized_authors = []
                                    for author in research.authors or []:
                                        if isinstance(author, dict):
                                            name = author.get("name") or author.get("family") or author.get("given") or ""
                                            if name:
                                                normalized_authors.append(str(name))
                                        else:
                                            name = str(author).strip()
                                            if name:
                                                normalized_authors.append(name)
                                    await sources_service.add_source(
                                        workspace_id=self.state.workspace_id,
                                        source_data={
                                            "title": research.title,
                                            "authors": normalized_authors,
                                            "year": research.year,
                                            "doi": research.doi,
                                            "url": research.url,
                                            "abstract": research.abstract,
                                            "venue": research.venue,
                                            "source_type": "continuous_research"
                                        },
                                        download_pdf=False,
                                        extract_text=False
                                    )
                            except:
                                pass
                except Exception as e:
                    print(f"Background search error: {e}")
                await asyncio.sleep(8)  # Wait between rounds
        
        # Start background search task
        background_search = asyncio.create_task(continuous_search())
        
        # Phase 2: Writer Swarm (parallel writing)
        await events.publish(job_id, "log", {"message": "‚úçÔ∏è PHASE 2: Launching Writer Swarm..."}, session_id=session_id)
        await events.publish(job_id, "agent_activity", {"agent": "writer_swarm", "agent_name": "Writer Swarm", "status": "running", "action": "5 writers generating 12 sections in parallel...", "icon": "‚úçÔ∏è"}, session_id=session_id)
        
        writer_swarm = WriterSwarm(self.state)
        await writer_swarm.write_all()
        
        await events.publish(job_id, "agent_activity", {"agent": "writer_swarm", "agent_name": "Writer Swarm", "status": "completed", "action": f"Wrote {len(self.state.sections)} sections", "icon": "‚úÖ"}, session_id=session_id)
        
        # Phase 3: Quality Control
        await events.publish(job_id, "log", {"message": "‚úì PHASE 3: Quality Control..."}, session_id=session_id)
        await events.publish(job_id, "agent_activity", {"agent": "quality_control", "agent_name": "Quality Control", "status": "running", "action": "Validating citations and combining sections...", "icon": "‚úì"}, session_id=session_id)
        
        quality_swarm = QualitySwarm(self.state)
        final_content = await quality_swarm.validate_and_combine()

        # Enforce PhD-quality gates before saving
        if thesis_type != "general":
            try:
                await self._enforce_quality_gates(
                    final_content,
                    chapter_number=self.state.chapter_number,
                    job_id=job_id,
                    session_id=session_id,
                    sample_size=sample_size,
                    objectives=None
                )
            except ValueError as quality_error:
                if not allow_quality_failure:
                    raise
                await events.publish(
                    job_id,
                    "log",
                    {"message": f"‚ö†Ô∏è Chapter 1 quality gate failed (continuing): {quality_error}"},
                    session_id=session_id
                )
        
        # Stop background search
        background_search.cancel()
        try:
            await background_search
        except asyncio.CancelledError:
            pass
        
        # Report additional papers found
        continuous_papers = len(self.state.research.get("continuous", []))
        if continuous_papers > 0:
            await events.publish(job_id, "log", {"message": f"üîç Background search discovered {continuous_papers} additional papers"}, session_id=session_id)
        
        # Calculate stats
        elapsed = (datetime.now() - start_time).total_seconds()
        word_count = len(final_content.split())
        citation_count = self.state.total_citations
        
        # Save final file - use WORKSPACES_DIR from workspace_service
        from services.workspace_service import WORKSPACES_DIR
        import os
        workspace_path = WORKSPACES_DIR / self.state.workspace_id
        os.makedirs(workspace_path, exist_ok=True)
        
        # Generate filename
        safe_topic = "".join(c if c.isalnum() or c in " -_" else "" for c in topic)[:50]
        filename = f"Chapter_1_{safe_topic.replace(' ', '_')}.md"
        filepath = os.path.join(workspace_path, filename)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(final_content)
        
        # Notify file created with auto_open flag
        await events.publish(
            job_id,
            "file_created",
            {
                "path": filepath, 
                "filename": filename, 
                "type": "markdown",
                "auto_open": True,  # Open in preview panel automatically
                "content_preview": final_content[:500]  # First 500 chars for preview
            },
            session_id=session_id
        )
        
        await events.publish(job_id, "agent_activity", {"agent": "quality_control", "agent_name": "Quality Control", "status": "completed", "action": f"Saved to {filename}", "icon": "‚úÖ"}, session_id=session_id)
        
        # Final summary
        await events.publish(
            job_id,
            "response_chunk",
            {"chunk": f"\n\n---\n\n‚úÖ **Chapter Complete!**\n- ‚è±Ô∏è Generated in {elapsed:.1f} seconds\n- üìÑ {word_count} words\n- üìö {citation_count} citations\n- üíæ Saved: `{filename}`\n", "accumulated": final_content},
            session_id=session_id
        )
        
        await events.publish(job_id, "agent_activity", {"agent": "chapter_generator", "agent_name": "Chapter Generator", "status": "completed", "action": f"Chapter generated! {word_count} words, {citation_count} citations", "icon": "üìñ"}, session_id=session_id)
        
        return final_content
    
    async def _generate_chapter_three_general(
        self, topic: str, case_study: str, job_id: str, session_id: str, workspace_id: str
    ) -> str:
        """Dedicated generator for General Thesis Chapter 3."""
        await events.publish(job_id, "log", {"message": "üìñ Entering General Thesis Chapter 3 Flow..."}, session_id=session_id)
        
        self.state = ChapterState(topic=topic, case_study=case_study, job_id=job_id, session_id=session_id, workspace_id=workspace_id, chapter_number=3)
        self.state.parameters["thesis_type"] = "general"
        await events.connect()
        
        # Research Phase
        research_swarm = ResearchSwarm(self.state)
        await research_swarm.search_all()

        # Configs mostly reuse existing styles or standard ones, but structure is specific:
        # 3.0 Intro, 3.1 Design, 3.2 Sources, 3.3 Pop, 3.4 Sample, 3.5 Data Coll (Quest/Interview), 3.6 Analysis, 3.7 Valid/Rel, 3.8 Ethical
        
        configs = []
        configs.append({"id": "3.0", "title": "Introduction", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "methodology_intro"})
        configs.append({"id": "3.1", "title": "Research Design", "paragraphs": 2, "sources": ["methodology"], "needs_citations": True, "style": "research_design"})
        configs.append({"id": "3.2", "title": "Sources of Data", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "standard"}) # Generic
        configs.append({"id": "3.2.1", "title": "Primary Data", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "standard"})
        configs.append({"id": "3.2.2", "title": "Secondary Data", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "standard"})
        configs.append({"id": "3.3", "title": "Target Population", "paragraphs": 2, "sources": ["local"], "needs_citations": True, "style": "target_population"})
        configs.append({"id": "3.4", "title": "Sample Size and Sampling Procedures", "paragraphs": 4, "sources": ["methodology"], "needs_citations": True, "style": "sampling_procedures"})
        configs.append({"id": "3.5", "title": "Data Collection Procedures", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "data_procedures"})
        configs.append({"id": "3.5.1", "title": "Questionnaires", "paragraphs": 2, "sources": ["methodology"], "needs_citations": True, "style": "data_instruments"})
        configs.append({"id": "3.5.2", "title": "Interviews", "paragraphs": 2, "sources": ["methodology"], "needs_citations": True, "style": "data_instruments"})
        configs.append({"id": "3.6", "title": "Description of Data Analysis Procedures", "paragraphs": 3, "sources": ["methodology"], "needs_citations": True, "style": "data_analysis"})
        configs.append({"id": "3.7", "title": "Measurement of Validity and Reliability of The Study Instruments", "paragraphs": 1, "sources": [], "needs_citations": False, "style": "standard"})
        configs.append({"id": "3.7.1", "title": "Validity", "paragraphs": 2, "sources": ["methodology"], "needs_citations": True, "style": "validity_reliability"})
        configs.append({"id": "3.7.2", "title": "Reliability", "paragraphs": 2, "sources": ["methodology"], "needs_citations": True, "style": "validity_reliability"})
        configs.append({"id": "3.8", "title": "Ethical Consideration", "paragraphs": 2, "sources": ["methodology"], "needs_citations": True, "style": "ethical_considerations"})
        
        # We need a new WriterSwarm instance/config
        # Since WriterSwarm logic is tightly coupled with self.SECTION_CONFIGS, and we can't easily override...
        # We will use the 'custom_sections_override' trick functionality if we implement it, 
        # OR simply define a temporary attribute that WriterSwarm checks.
        
        # Let's rely on the previous hack: WriterSwarm.GENERAL_SECTION_CONFIGS = ...
        # But this is risky if parallel jobs run (race condition on class attribute).
        # Better: create a list of sections passed to a CUSTOM writer function or modify WriterSwarm to accept sections in constructor.
        
        # Actually, WriterSwarm's 'write_all' iterates over 'self.SECTION_CONFIGS'.
        # I'll modify the WriterSwarm instance after creation?
        # writer_swarm = WriterSwarm(self.state)
        # writer_swarm.SECTION_CONFIGS = [{"id": "gen_ch3", "sections": configs}]
        
        await events.publish(job_id, "log", {"message": "‚úçÔ∏è PHASE 2: Writing General Methodology..."}, session_id=session_id)
        writer_swarm = WriterSwarm(self.state)
        writer_swarm.SECTION_CONFIGS = [{"id": "gen_ch3", "sections": configs}] # Override standard configs
        
        await writer_swarm.write_all()
        
        quality_swarm = QualitySwarm(self.state)
        final_content = await quality_swarm.validate_and_combine()
        
        return final_content

    async def generate_chapter_1(self, *args, **kwargs):
        """Standard wrapper for Chapter 1 full generation (alias)."""
        return await self.generate(*args, **kwargs)
    
    async def generate_creative_headings(self, objective: str, topic: str) -> List[str]:
        """Generate creative, academic sub-headings for an objective using LLM."""
        try:
            from services.deepseek_direct import deepseek_direct_service
            
            prompt = f"""Generate 4 distinct, engaging, and specific academic sub-headings for a literature review section that discusses the following objective:

TOPIC: {topic}
OBJECTIVE: {objective}

The sub-headings should break down the objective into specific thematic areas suitable for lengthy empirical review.
Avoid generic titles like "Introduction" or "Conclusion".
Avoid repetitive phrasing.
Do NOT use the phrase "Thematic Aspect of".

Return ONLY a valid JSON list of 4 clean strings.
Example: ["Institutional Challenges", "Resource Allocation Frameworks", "Stakeholder Engagement", "Governance Impact"]"""

            content = await deepseek_direct_service.generate_content(
                prompt=prompt,
                temperature=0.7,
                max_tokens=500
            )
            
            import json
            import re
            
            # Clean content to ensure valid JSON
            content = content.replace("```json", "").replace("```", "").strip()
            
            headings = json.loads(content)
            if isinstance(headings, list) and len(headings) >= 4:
                return headings[:4]
                
        except Exception as e:
            print(f"Error generating creative headings: {e}")
            
        # Fallback if LLM fails (Smart Regex construction)
        import re
        clean_obj = re.sub(r'^(to|To)\s+(assess|examine|analyze|evaluate|investigate|determine|study|explore)\s+', '', objective)
        clean_obj = re.sub(r'^(to|To)\s+', '', clean_obj)
        short_heading = ' '.join(clean_obj.split()[:10]).title()
            
        return [
            f"Key Themes in {short_heading}",
            f"Empirical Evidence on {short_heading}",
            f"Critical Analysis of {short_heading}",
            f"Comparative Perspectives on {short_heading}"
        ]

    async def generate_chapter_two(
        self,
        topic: str,
        case_study: str,
        job_id: str,
        session_id: str,
        workspace_id: str = "default",
        objectives: Dict[str, Any] = None,  # Can pass directly or load from DB
        research_questions: List[str] = None,
        thesis_type: str = "phd",
        sample_size: int = None,
        allow_quality_failure: bool = False,
        chapter2_paragraphs: int = None,
        chapter2_paragraph_plan: Dict[str, Any] = None
    ) -> str:
        """Generate Chapter Two - Literature Review with massive parallelization.
        
        Uses objectives from Chapter One to create:
        - Theoretical framework (2 theories)
        - 4 thematic sections aligned with objectives  
        - Research gap and literature matrix
        
        Target: 50,000 words in <1 minute via 20+ parallel agents
        """
        start_time = datetime.now()
        
        # CLEAN METADATA from topic
        import re
        topic = re.sub(r'n\s*=\s*\d+', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'topic\s*=\s*["\'].*?["\']', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'case[_\s]?study\s*=\s*["\'].*?["\']', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'design\s*=\s*\w+', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'/uoj_phd\s*\w*', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'\s+', ' ', topic).strip()
        
        custom_outline = None
        try:
            from services.outline_parser import outline_parser
            from services.workspace_service import WORKSPACES_DIR
            outline_path = WORKSPACES_DIR / (workspace_id or "default") / "outline.json"
            if outline_path.exists():
                custom_outline = outline_parser.load_outline(workspace_id)
        except Exception as outline_error:
            print(f"‚ö†Ô∏è Could not load outline for Chapter 2: {outline_error}")
        use_custom_outline = bool(custom_outline and custom_outline.get("chapters"))

        # STRICT BIFURCATION: Only General thesis uses UoJ-specific Chapter 2
        # unless a custom outline is provided (then follow that outline).
        if thesis_type == "general":
            if use_custom_outline:
                return await self._generate_chapter_two_general(
                    topic,
                    case_study,
                    job_id,
                    session_id,
                    workspace_id,
                    objectives,
                    research_questions,
                    custom_outline=custom_outline
                )
            return await self._generate_chapter_two_strict_uoj(
                topic,
                case_study,
                job_id,
                session_id,
                workspace_id,
                objectives,
                research_questions
            )

        # Try to use database for objectives, but fall back if DB unavailable
        db = None
        saved_objectives = None
        questions = None
        
        try:
            from services.thesis_session_db import ThesisSessionDB
            db = resolve_thesis_db(session_id, workspace_id)
            db.create_session(topic, case_study)
            
            # Load or use provided objectives
            if objectives:
                saved_objectives = normalize_objectives(objectives, topic, case_study)
            else:
                saved_objectives = db.get_objectives()
            
            # Load or use provided research questions
            if research_questions:
                questions = research_questions
            else:
                questions = db.get_questions()
        except Exception as db_error:
            print(f"‚ö†Ô∏è Database unavailable for Chapter 2, using defaults: {db_error}")
            # Continue without database - will use defaults below
            saved_objectives = normalize_objectives(objectives, topic, case_study) if objectives else None  # Use provided objectives if any
            questions = research_questions  # Use provided questions if any
        
        # Generate default objectives if not loaded from DB
        if not saved_objectives or not saved_objectives.get("specific"):
            # Generate default objectives based on topic
            saved_objectives = {
                "general": f"To investigate {topic} in the context of {case_study}",
                "specific": [
                    f"To examine the prevalence and characteristics of {topic}",
                    f"To assess the factors influencing {topic} in {case_study}",
                    f"To determine the relationship between {topic} and key outcomes",
                    f"To evaluate existing interventions addressing {topic}"
                ]
            }
        
        # Generate default questions if not loaded
        if not questions:
            questions = [
                f"What is the relationship between {topic} and key outcomes in {case_study}?",
                f"What factors influence {topic} in {case_study}?",
                f"What interventions exist for addressing {topic}?",
                f"What gaps exist in the current literature on {topic}?"
            ]
        
        # Create themes from objectives (each specific objective -> 1 theme)
        themes = []
        for i, obj in enumerate(saved_objectives.get("specific", [])[:4], 1):
            # Create a SHORT theme title from the objective
            obj_text = obj.replace("To ", "").replace("to ", "")
            # Capitalize first letter and clean up
            theme_title = obj_text[0].upper() + obj_text[1:] if obj_text else f"Aspect {i} of {topic}"
            theme_title = obj_text[0].upper() + obj_text[1:] if obj_text else f"Aspect {i} of {topic}"
            
            theme = {
                "number": i,
                "title": theme_title,
                "objective": obj,
                "queries": [
                    f"{topic} {' '.join(obj.split()[-3:])}".replace('[', '').replace(']', ''),
                    f"{case_study} {' '.join(obj.split()[2:5])}".replace('[', '').replace(']', ''),
                ]
            }
            themes.append(theme)
        
        # Save themes to DB if available
        if db:
            try:
                db.save_themes(themes)
            except Exception as e:
                print(f"‚ö†Ô∏è Could not save themes to DB: {e}")
        
        # Initialize state for Chapter 2
        self.state = ChapterState(
            topic=topic,
            case_study=case_study,
            job_id=job_id,
            session_id=session_id,
            workspace_id=workspace_id,
            chapter_number=2,
            objectives=saved_objectives,
            research_questions=questions,
            themes=themes,
            db=db,
            thesis_type=thesis_type # Propagate thesis_type
        )
        self.state.parameters["thesis_type"] = thesis_type
        if chapter2_paragraphs:
            self.state.parameters["chapter2_paragraphs"] = chapter2_paragraphs
        if chapter2_paragraph_plan:
            self.state.parameters["chapter2_paragraph_plan"] = chapter2_paragraph_plan

        paragraph_override = None
        if chapter2_paragraphs:
            try:
                paragraph_override = max(1, min(int(chapter2_paragraphs), 12))
            except (TypeError, ValueError):
                paragraph_override = None

        paragraph_plan = {}
        if isinstance(chapter2_paragraph_plan, dict):
            key_map = {
                "intro": "intro",
                "framework_intro": "framework_intro",
                "frameworkIntro": "framework_intro",
                "theory": "theory",
                "theory_per_objective": "theory",
                "theoryPerObjective": "theory",
                "conceptual": "conceptual",
                "conceptual_framework": "conceptual",
                "conceptualFramework": "conceptual",
                "empirical_intro": "empirical_intro",
                "empiricalIntro": "empirical_intro",
                "empirical_variable": "empirical_variable",
                "empiricalPerVariable": "empirical_variable",
                "empirical_per_variable": "empirical_variable",
                "gap": "gap",
                "research_gap": "gap",
                "gap_summary": "gap"
            }
            for key, value in chapter2_paragraph_plan.items():
                if key not in key_map:
                    continue
                try:
                    paragraph_plan[key_map[key]] = max(1, min(int(value), 12))
                except (TypeError, ValueError):
                    continue

        def _para(default_value: int, key: str = None) -> int:
            if key and key in paragraph_plan:
                return paragraph_plan[key]
            return paragraph_override if paragraph_override else default_value
        
        await events.connect()
        
        
        # Load uploaded sources context for RAG
        try:
            self.state.uploaded_sources_context = sources_service.get_all_sources_full_text(workspace_id, topic=topic)
            if self.state.uploaded_sources_context:
                print(f"‚úÖ Loaded {len(self.state.uploaded_sources_context)} chars of uploaded context for RAG")
        except Exception as e:
            print(f"‚ö†Ô∏è Error loading uploaded context: {e}")

        await events.publish(
            job_id,
            "stage_started",
            {"stage": "chapter_two_generation", "message": f"üìö Starting Chapter Two (Literature Review) generation for: {topic}"},
            session_id=session_id
        )
        
        await events.publish(
            job_id,
            "response_chunk",
            {"chunk": f"# üìö Generating Chapter Two - Literature Review\n\n**Topic:** {topic}\n**Objectives loaded:** {len(saved_objectives.get('specific', []))}\n**Themes:** {len(themes)}\n\n---\n\n", "accumulated": "Starting..."},
            session_id=session_id
        )

        # ============ PHASE 1: MASSIVE PARALLEL RESEARCH ============
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "research_swarm", "agent_name": "Research Swarm", "status": "running", "action": "Launching literature search for Chapter 2...", "icon": "üîç"},
            session_id=session_id
        )
        await events.publish(job_id, "log", {"message": "üîç PHASE 1: Launching 10+ parallel research agents..."}, session_id=session_id)
        
        # Search for theories
        theory_queries = [
            f"{topic} theoretical framework",
            f"{topic} theory model",
            f"{case_study} conceptual framework"
        ]
        
        # Search for each theme in parallel
        relevance_filter = ResearchSwarm(self.state)

        async def search_theme(theme_num: int, queries: List[str]) -> List[ResearchResult]:
            """Search for papers for a specific theme."""
            results = []
            for query in queries[:4]:  # Increased to 4 queries per theme for better coverage
                try:
                    # Increased max_results to 30 to support bulkier literature review
                    papers = await academic_search_service.search_academic_papers(query, max_results=30)
                    for paper in papers:
                        research_result = ResearchResult(
                            title=paper.get("title", ""),
                            authors=paper.get("authors", [])[:5],
                            year=paper.get("year") or 2023,
                            doi=paper.get("doi", ""),
                            url=paper.get("url", ""),
                            abstract=paper.get("abstract", "")[:500],
                            source=f"theme{theme_num}",
                            venue=paper.get("venue", "")
                        )
                        accepted, _score = relevance_filter._is_result_acceptable(research_result)
                        if accepted:
                            results.append(research_result)
                except Exception as e:
                    print(f"Theme {theme_num} search error: {e}")
            return results
        
        # Run ALL searches in parallel (theories + 4 themes = 5+ parallel searches)
        search_tasks = []
        
        # Theory search
        async def search_theories():
            results = []
            for query in theory_queries:
                try:
                    # Increased max_results for theories
                    papers = await academic_search_service.search_academic_papers(query, max_results=20)
                    for paper in papers:
                        research_result = ResearchResult(
                            title=paper.get("title", ""),
                            authors=paper.get("authors", [])[:5],
                            year=paper.get("year") or 2023,
                            doi=paper.get("doi", ""),
                            url=paper.get("url", ""),
                            abstract=paper.get("abstract", "")[:500],
                            source="theories",
                            venue=paper.get("venue", "")
                        )
                        accepted, _score = relevance_filter._is_result_acceptable(research_result)
                        if accepted:
                            results.append(research_result)
                except:
                    pass
            return results
        
        search_tasks.append(search_theories())
        
        # Theme searches
        for theme in themes:
            search_tasks.append(search_theme(theme["number"], theme["queries"]))
        
        # Execute all searches in parallel
        search_results = await asyncio.gather(*search_tasks, return_exceptions=True)
        
        # Aggregate results
        theory_papers = search_results[0] if not isinstance(search_results[0], Exception) else []
        self.state.research["theories"] = theory_papers
        
        for i, theme in enumerate(themes, 1):
            theme_results = search_results[i] if i < len(search_results) and not isinstance(search_results[i], Exception) else []
            self.state.research[f"theme{i}"] = theme_results
        
        total_papers = sum(len(p) for p in self.state.research.values())
        await events.publish(job_id, "log", {"message": f"‚úÖ Research complete: {total_papers} papers found across {len(themes) + 1} categories"}, session_id=session_id)
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "research_swarm", "agent_name": "Research Swarm", "status": "completed", "action": f"Found {total_papers} papers across {len(themes) + 1} categories", "icon": "‚úÖ"},
            session_id=session_id
        )

        # ============ PHASE 2: MASSIVE PARALLEL WRITING (20+ agents) ============
        await events.publish(job_id, "log", {"message": "‚úçÔ∏è PHASE 2: Launching parallel writer agents..."}, session_id=session_id)
        
        # Get objectives for structure
        specific_objectives = saved_objectives.get("specific", [])
        num_objectives = len(specific_objectives)
        
        # Extract variables for each objective to create sub-headings
        await events.publish(job_id, "log", {"message": "üîç Extracting 4-6 specific variables for deeper Objective -> Variable hierarchy..."}, session_id=session_id)
        
        extraction_prompt = f"""Identify 4-6 specific academic variables or themes for EACH of the following research objectives. 
Return the result as a raw JSON object (no markdown formatting) where keys are the objective numbers (1, 2, 3...) and values are lists of exactly 4-6 scholarly sub-heading titles.

TOPIC: {topic}
OBJECTIVES:
{chr(10).join([f"{i}. {obj}" for i, obj in enumerate(specific_objectives, 1)])}

Example format:
{{
  "1": ["Institutional Resource Allocation", "Policy Implementation Frameworks", "Organizational Efficiency", "Stakeholder Engagement"],
  "2": ["Human Capital Development", "Resource Adequacy", "Financial Sustainability", "Technological Integration"]
}}
"""
        obj_vars = {}
        try:
            from services.deepseek_direct import deepseek_direct_service
            raw_vars = await deepseek_direct_service.generate_content(extraction_prompt, temperature=0.3)
            # Clean possible markdown wrap
            clean_vars = raw_vars.strip()
            if "```" in clean_vars:
                clean_vars = clean_vars.split("```")[1]
                if clean_vars.startswith("json"):
                    clean_vars = clean_vars[4:].strip()
            
            import json
            obj_vars = json.loads(clean_vars.strip())
            await events.publish(job_id, "log", {"message": f"‚úÖ Extracted variables for {len(obj_vars)} objectives"}, session_id=session_id)
            
            # Save variables to workspace for consistency across chapters (The Golden Thread)
            try:
                from services.workspace_service import WORKSPACES_DIR
                workspace_dir = WORKSPACES_DIR / (workspace_id or "default")
                plan_path = workspace_dir / "thesis_plan.json"
                plan_data = {}
                if plan_path.exists():
                    try:
                        with open(plan_path, 'r') as f:
                            plan_data = json.load(f)
                    except:
                        plan_data = {}
                
                plan_data["objective_variables"] = obj_vars
                with open(plan_path, 'w') as f:
                    json.dump(plan_data, f, indent=2)
                await events.publish(job_id, "log", {"message": f"üóíÔ∏è Thesis plan updated with specific variables for Chapter 3, 4, and 5 consistency"}, session_id=session_id)
            except Exception as plan_e:
                print(f"Error saving thesis plan: {plan_e}")
        except Exception as e:
            print(f"Error extracting variables: {e}")
            # Fallback: Invoke LLM Heading Planner (Anti-Monotony)
            await events.publish(job_id, "log", {"message": "‚ö†Ô∏è Extraction failed, invoking LLM Heading Planner for creative titles..."}, session_id=session_id)
            obj_vars = {}
            for i, obj in enumerate(specific_objectives):
                # Call helper method to get 4 distinct headings
                headings = await self.generate_creative_headings(obj, topic)
                obj_vars[str(i+1)] = headings
                # Small delay to keep API happy
                if i < len(specific_objectives) - 1:
                    await asyncio.sleep(0.3)
        # Update theme titles in config
        chapter_two_configs = []
        
        # ========== 2.0 Introduction ==========
        chapter_two_configs.append({
            "id": "lit_intro_writer",
            "sections": [
                {"id": "2.0", "title": "Introduction", "paragraphs": _para(2, "intro"), "sources": [], "needs_citations": False, "style": "lit_intro"},
            ]
        })
        
        # ========== 2.1 Theoretical/Conceptual Framework ==========
        # Generate ONE theory per objective
        topic_lower = topic.lower()
        
        # Theory pool based on topic domain
        if any(word in topic_lower for word in ["military", "defense", "security", "conflict", "war"]):
            theory_pool = [
                "Realist Theory of International Relations",
                "Security Dilemma Theory", 
                "Revolution in Military Affairs (RMA) Theory",
                "Military Innovation Theory",
                "Deterrence Theory",
                "Civil-Military Relations Theory",
                "Security Sector Reform Theory",
                "Technological Determinism Theory"
            ]
        elif any(word in topic_lower for word in ["technology", "innovation", "digital", "ict"]):
            theory_pool = [
                "Technology Acceptance Model (TAM)",
                "Diffusion of Innovations Theory",
                "Unified Theory of Acceptance and Use of Technology (UTAUT)",
                "Technological Determinism Theory",
                "Social Construction of Technology (SCOT)",
                "Actor-Network Theory",
                "Digital Divide Theory",
                "Disruptive Innovation Theory"
            ]
        elif any(word in topic_lower for word in ["education", "learning", "school", "student"]):
            theory_pool = [
                "Social Constructivism Theory",
                "Experiential Learning Theory",
                "Behaviourist Learning Theory",
                "Cognitive Load Theory",
                "Self-Determination Theory",
                "Social Learning Theory",
                "Transformative Learning Theory",
                "Multiple Intelligences Theory"
            ]
        elif any(word in topic_lower for word in ["health", "medical", "disease", "hospital"]):
            theory_pool = [
                "Health Belief Model",
                "Social Ecological Model",
                "Theory of Planned Behaviour",
                "Social Cognitive Theory",
                "Diffusion of Innovations in Health",
                "Health Promotion Model",
                "Transtheoretical Model of Change",
                "Social Determinants of Health Framework"
            ]
        elif any(word in topic_lower for word in ["economic", "economy", "finance", "development"]):
            theory_pool = [
                "Human Capital Theory",
                "Institutional Economics Theory",
                "Modernisation Theory",
                "Dependency Theory",
                "Endogenous Growth Theory",
                "Sustainable Development Theory",
                "Capability Approach",
                "New Institutional Economics"
            ]
        elif any(word in topic_lower for word in ["governance", "policy", "government", "public"]):
            theory_pool = [
                "New Public Management Theory",
                "Institutional Theory",
                "Policy Implementation Theory",
                "Governance Network Theory",
                "Principal-Agent Theory",
                "Public Choice Theory",
                "Collaborative Governance Theory",
                "Punctuated Equilibrium Theory"
            ]
        else:
            theory_pool = [
                "Systems Theory",
                "Stakeholder Theory",
                "Institutional Theory",
                "Resource-Based View",
                "Contingency Theory",
                "Social Exchange Theory",
                "Structuration Theory",
                "Actor-Network Theory"
            ]
        
        # Select theories to match number of objectives
        selected_theories = theory_pool[:num_objectives] if num_objectives <= len(theory_pool) else theory_pool + theory_pool[:num_objectives - len(theory_pool)]
        
        framework_sections = [
            {"id": "2.1", "title": "Theoretical and Conceptual Framework", "paragraphs": _para(2, "framework_intro"), "sources": ["theories"], "needs_citations": True, "style": "framework_intro"},
        ]
        
        for i, theory in enumerate(selected_theories, 1):
            obj_text = specific_objectives[i-1] if i-1 < len(specific_objectives) else f"Objective {i}"
            framework_sections.append({
                "id": f"2.1.{i}", 
                "title": theory, 
                "paragraphs": _para(6, "theory"), 
                "sources": ["theories"], 
                "needs_citations": True, 
                "style": "theory_detailed", 
                "theory_name": theory,
                "guiding_objective": obj_text
            })
        
        # Aggregate all variables for the conceptual framework
        all_variables = []
        for vars_list in obj_vars.values():
            all_variables.extend(vars_list)
            
        # Add conceptual framework as last subsection
        framework_sections.append({
            "id": f"2.1.{num_objectives + 1}", 
            "title": "Conceptual Framework for the Study", 
            "paragraphs": _para(5, "conceptual"), 
            "sources": ["theories"], 
            "needs_citations": True, 
            "style": "conceptual_framework",
            "component_list": ", ".join(all_variables)
        })
        
        chapter_two_configs.append({
            "id": "framework_writer",
            "sections": framework_sections
        })
        
        # ========== 2.2, 2.3, ... Empirical Literature per Objective ==========
        for i, objective in enumerate(specific_objectives, 1):
            section_num = i + 1  # Start from 2.2
            
            # Create a SHORT, meaningful heading from the objective
            import re
            # Remove "To ", "to ", "assess", "examine", "analyze", etc. from start
            clean_obj = re.sub(r'^(to|To)\s+(assess|examine|analyze|evaluate|investigate|determine|study|explore)\s+', '', objective)
            clean_obj = re.sub(r'^(to|To)\s+', '', clean_obj)
            
            # CRITICAL CHECK FOR METADATA LEAKS (User Feedback Fix)
            # Remove n=..., topic=..., design=..., uoj_phd...
            clean_obj = re.sub(r'n\s*=\s*\d+', '', clean_obj, flags=re.IGNORECASE)
            clean_obj = re.sub(r'topic\s*=\s*["\'].*?["\']', '', clean_obj, flags=re.IGNORECASE)
            clean_obj = re.sub(r'case[_\s]?study\s*=\s*["\'].*?["\']', '', clean_obj, flags=re.IGNORECASE)
            clean_obj = re.sub(r'design\s*=\s*\w+', '', clean_obj, flags=re.IGNORECASE)
            clean_obj = re.sub(r'/uoj_phd\s*\w*', '', clean_obj, flags=re.IGNORECASE)
            clean_obj = clean_obj.replace('"', '').replace("'", "") # Remove quotes
            clean_obj = re.sub(r'\s+', ' ', clean_obj).strip() # Clean formatting
            
            # Extract key words (skip common words)
            skip_words = ['the', 'and', 'for', 'with', 'from', 'that', 'this', 'which', 'their', 'of', 'in', 'on', 'a', 'an', 'between', 'among']
            words = [w for w in clean_obj.split() if w.lower() not in skip_words and len(w) > 2]
            
            # Create concise heading (max 8 words, properly capitalized)
            short_heading = ' '.join(words[:8])
            # Capitalize first letter of each major word
            short_heading = ' '.join([word.capitalize() if word.lower() not in ['and', 'or', 'the', 'of', 'in', 'on', 'at'] else word.lower() 
                                      for word in short_heading.split()])
            
            # Section title: Use direct heading without redundant "Empirical Literature on" prefix
            # This makes headings cleaner and more professional
            section_title = short_heading
            
            # Get extracted variables for this objective
            vars_for_obj = obj_vars.get(str(i), obj_vars.get(i, []))
            if not vars_for_obj:
                # Late-stage fallback for individual missing objectives
                print(f"‚ö†Ô∏è Missing variables for Objective {i}, invoking creative planner...")
                vars_for_obj = await self._generate_creative_headings(objective, topic)
                
            empirical_sections = [
                {"id": f"2.{section_num}", "title": section_title, "paragraphs": _para(2, "empirical_intro"), "sources": [f"theme{i}"], "needs_citations": True, "style": "theme_intro", "objective_text": objective},
            ]
            
            for j, var in enumerate(vars_for_obj, 1):
                empirical_sections.append({
                    "id": f"2.{section_num}.{j}", 
                    "title": var, 
                    "paragraphs": _para(10, "empirical_variable"), 
                    "sources": [f"theme{i}"], 
                    "needs_citations": True, 
                    "style": "lit_synthesis", 
                    "objective_text": f"Objective {i}: {objective} (Specific Focus: {var})"
                })
            
            chapter_two_configs.append({
                "id": f"empirical{i}_writer",
                "sections": empirical_sections
            })
        
        # ========== 2.N Research Gap ==========
        gap_section_num = num_objectives + 2  # After all empirical sections
        
        chapter_two_configs.append({
            "id": "gap_writer",
            "sections": [
                {"id": f"2.{gap_section_num}", "title": "Research Gap and Summary of Literature", "paragraphs": _para(4, "gap"), "sources": ["all"], "needs_citations": True, "style": "literature_gap"},
            ]
        })
        
        used_custom_outline = False
        outline_configs = None
        try:
            outline_writer = WriterSwarm(self.state)
            custom_outline = outline_writer._load_custom_outline()
            outline_configs = outline_writer._build_outline_section_configs(custom_outline)
        except Exception as outline_error:
            print(f"‚ö†Ô∏è Could not build outline configs for Chapter 2: {outline_error}")
        if outline_configs:
            chapter_two_configs = outline_configs
            themes = []
            used_custom_outline = True
            await events.publish(
                job_id,
                "log",
                {"message": "üß≠ Using custom outline sections for Chapter 2"},
                session_id=session_id
            )

        # Create writer swarm with Chapter 2 configs
        class ChapterTwoWriterSwarm(WriterSwarm):
            SECTION_CONFIGS = chapter_two_configs
        
        writer_swarm = ChapterTwoWriterSwarm(self.state)

        # Override to use Chapter 2 configs
        writer_swarm.SECTION_CONFIGS = chapter_two_configs

        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "writer_swarm", "agent_name": "Writer Swarm", "status": "running", "action": "Writing Chapter 2 sections in parallel...", "icon": "‚úçÔ∏è"},
            session_id=session_id
        )

        await writer_swarm.write_all()
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "writer_swarm", "agent_name": "Writer Swarm", "status": "completed", "action": f"Wrote {len(self.state.sections)} sections", "icon": "‚úÖ"},
            session_id=session_id
        )

        expected_sections = [sec["id"] for cfg in chapter_two_configs for sec in cfg.get("sections", [])]
        missing_sections = [sec_id for sec_id in expected_sections if sec_id not in self.state.sections]
        if missing_sections:
            section_lookup = {
                section["id"]: section
                for config in chapter_two_configs
                for section in config.get("sections", [])
            }
            await events.publish(
                job_id,
                "log",
                {"message": f"‚ö†Ô∏è Chapter 2 missing sections detected: {', '.join(missing_sections)}. Retrying generation for missing sections."},
                session_id=session_id
            )
            missing_configs = [section_lookup[sec_id] for sec_id in missing_sections if sec_id in section_lookup]
            try:
                fallback_results = await writer_swarm._writer_agent("chapter2_fallback_writer", missing_configs)
                for sec_id, content in fallback_results.items():
                    self.state.sections[sec_id] = content
            except Exception as fallback_error:
                await events.publish(
                    job_id,
                    "log",
                    {"message": f"‚ö†Ô∏è Chapter 2 fallback generation failed: {fallback_error}. Inserting minimal placeholders."},
                    session_id=session_id
                )
                for sec_id in missing_sections:
                    section_title = section_lookup.get(sec_id, {}).get("title", "Section")
                    self.state.sections[sec_id] = SectionContent(
                        title=section_title,
                        content=f"{section_title} could not be generated automatically. Please regenerate this section.",
                        citations=[],
                        word_count=0,
                        status="completed"
                    )
        
        # ============ DEBUG: VALIDATE SECTIONS WERE CREATED ============
        sections_written = len(self.state.sections)
        await events.publish(job_id, "log", {"message": f"‚úÖ Writing complete: {sections_written} sections generated"}, session_id=session_id)
        
        # Log each section for debugging
        if sections_written == 0:
            await events.publish(job_id, "log", {"message": "‚ö†Ô∏è WARNING: No sections were generated! WriterSwarm returned empty results."}, session_id=session_id)
        else:
            # Log first few section IDs and word counts
            sample_sections = list(self.state.sections.items())[:5]
            for sec_id, sec in sample_sections:
                word_count = len(sec.content.split()) if sec.content else 0
                await events.publish(job_id, "log", {"message": f"  - Section {sec_id}: {sec.title} ({word_count} words)"}, session_id=session_id)
            if sections_written > 5:
                await events.publish(job_id, "log", {"message": f"  ... and {sections_written - 5} more sections"}, session_id=session_id)
        
        # ============ PHASE 3: QUALITY CONTROL ============
        await events.publish(job_id, "log", {"message": "‚úì PHASE 3: Running 4-agent quality control..."}, session_id=session_id)

        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "quality_control", "agent_name": "Quality Control", "status": "running", "action": "Validating citations and combining sections...", "icon": "‚úì"},
            session_id=session_id
        )
        quality_swarm = QualitySwarm(self.state)
        final_content = await quality_swarm.validate_and_combine()
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "quality_control", "agent_name": "Quality Control", "status": "completed", "action": "Quality checks completed", "icon": "‚úÖ"},
            session_id=session_id
        )
        
        # Fix chapter heading
        final_content = final_content.replace("# CHAPTER ONE\n# INTRODUCTION", "# CHAPTER TWO\n# LITERATURE REVIEW")

        if thesis_type != "general":
            try:
                await self._enforce_quality_gates(
                    final_content,
                    chapter_number=2,
                    job_id=job_id,
                    session_id=session_id,
                    objectives=specific_objectives
                )
            except ValueError as quality_error:
                if not allow_quality_failure:
                    raise
                await events.publish(
                    job_id,
                    "log",
                    {"message": f"‚ö†Ô∏è Chapter 2 quality gate failed (continuing): {quality_error}"},
                    session_id=session_id
                )
        
        # Calculate stats
        elapsed = (datetime.now() - start_time).total_seconds()
        word_count = len(final_content.split())
        citation_count = self.state.total_citations
        
        # Save to DB
        for section_id, section in self.state.sections.items():
            db.save_section(2, section_id, section.title, section.content, "complete")
        
        # Save final file
        from services.workspace_service import WORKSPACES_DIR
        import os
        workspace_path = WORKSPACES_DIR / self.state.workspace_id
        os.makedirs(workspace_path, exist_ok=True)
        
        safe_topic = "".join(c if c.isalnum() or c in " -_" else "" for c in topic)[:50]
        filename = f"Chapter_2_Literature_Review_{safe_topic.replace(' ', '_')}.md"
        filepath = os.path.join(workspace_path, filename)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(final_content)
        
        await events.publish(
            job_id,
            "file_created",
            {"path": filepath, "filename": filename, "type": "markdown", "auto_open": True},
            session_id=session_id
        )
        
        theme_line = f"- üéØ {len(themes)} themes from objectives"
        if used_custom_outline:
            theme_line = "- üß≠ Sections aligned to custom outline"
        # Final summary
        await events.publish(
            job_id,
            "response_chunk",
            {"chunk": f"\n\n---\n\n‚úÖ **Chapter Two Complete!**\n- ‚è±Ô∏è Generated in {elapsed:.1f} seconds\n- üìÑ {word_count} words\n- üìö {citation_count} citations\n{theme_line}\n- üíæ Saved: `{filename}`\n", "accumulated": final_content},
            session_id=session_id
        )
        
        return final_content

    async def generate_chapter_three(
        self,
        topic: str,
        case_study: str,
        job_id: str,
        session_id: str,
        workspace_id: str = "default",
        objectives: Dict[str, Any] = None,
        research_questions: List[str] = None,
        thesis_type: str = "phd",
        sample_size: int = None,
        allow_quality_failure: bool = False
    ) -> str:
        """Generate Chapter Three - Research Methodology.
        
        Uses topic and objectives to create:
        - Research Philosophy (with Research Onion diagram)
        - Research Design
        - Target Population and Sampling
        - Data Collection Instruments
        - Validity and Reliability
        - Data Analysis Procedures
        - Ethical Considerations
        
        Includes automatic formula generation (Yamane, Cronbach) and tables.
        """
        start_time = datetime.now()
        
        # CLEAN METADATA from topic
        import re
        topic = re.sub(r'n\s*=\s*\d+', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'topic\s*=\s*["\'].*?["\']', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'case[_\s]?study\s*=\s*["\'].*?["\']', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'design\s*=\s*\w+', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'/uoj_phd\s*\w*', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'\s+', ' ', topic).strip()
        
        # Notify start
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "chapter_generator", "agent_name": "Chapter Generator", "status": "starting", "action": "Generating Chapter Three: Research Methodology", "icon": "üìñ"},
            session_id=session_id
        )
        
        await events.publish(
            job_id,
            "response_chunk",
            {"chunk": f"# üìñ Generating Chapter Three: Research Methodology\n\n**Topic:** {topic}\n**Case Study:** {case_study or 'Not specified'}\n\n", "accumulated": ""},
            session_id=session_id
        )
        
        
        custom_outline = None
        try:
            from services.outline_parser import outline_parser
            from services.workspace_service import WORKSPACES_DIR
            outline_path = WORKSPACES_DIR / (workspace_id or "default") / "outline.json"
            if outline_path.exists():
                custom_outline = outline_parser.load_outline(workspace_id)
        except Exception as outline_error:
            print(f"‚ö†Ô∏è Could not load outline for Chapter 3: {outline_error}")
        use_custom_outline = bool(custom_outline and custom_outline.get("chapters"))

        # STRICT BIFURCATION: General theses use the UoJ method only if no custom outline
        if thesis_type == "general" and not use_custom_outline:
             return await self._generate_chapter_three_general(topic, case_study, job_id, session_id, workspace_id)
        
        state = ChapterState(
            topic=topic,
            case_study=case_study or "",
            chapter_number=3,
            job_id=job_id,
            session_id=session_id,
            workspace_id=workspace_id,
            thesis_type=thesis_type # Pass thesis_type to state
        )
        state.parameters["thesis_type"] = thesis_type # Also set in parameters
        if sample_size:
            state.parameters["sample_size"] = sample_size
        
        if objectives:
            state.objectives = objectives
        
        # ============================================================
        # NEW: Get methodology context from research configuration
        # ============================================================
        methodology_context = None
        try:
            from services.thesis_config_integration import get_chapter_generation_context
            chapter_ctx = get_chapter_generation_context(workspace_id, chapter_number=3)
            methodology_context = chapter_ctx.get('methodology')
            
            if methodology_context:
                await events.publish(job_id, "log", {
                    "message": f"üìä Research Configuration Loaded: n={methodology_context['sampling']['sample_size']}, "
                               f"Population={methodology_context['population']['target_size']:,}, "
                               f"Sampling={methodology_context['sampling']['technique']}"
                }, session_id=session_id)
                
                # Store in state for access by prompt builders
                state.parameters['methodology_context'] = methodology_context
        except Exception as e:
            print(f"‚ö†Ô∏è Could not load methodology context (using defaults): {e}")
        # ============================================================
            
        # Try to load variables from thesis plan for consistency (Golden Thread)
        try:
            from services.workspace_service import WORKSPACES_DIR
            import json
            workspace_dir = WORKSPACES_DIR / (workspace_id or "default")
            plan_path = workspace_dir / "thesis_plan.json"
            if plan_path.exists():
                with open(plan_path, 'r') as f:
                    plan_data = json.load(f)
                    obj_vars = plan_data.get("objective_variables", {})
                    # Store variables in state so prompt builders can access them
                    state.objective_variables = obj_vars
                    await events.publish(job_id, "log", {"message": f"üóíÔ∏è Loaded objectives with specific variables from Chapter 2 for Golden Thread consistency."}, session_id=session_id)
        except Exception as e:
            print(f"Error loading thesis plan in Ch3: {e}")
        
        # Phase 1: Research Swarm for Methodology
        await events.publish(
            job_id,
            "log",
            {"message": "üîç Phase 1: Researching methodology sources (Saunders, Creswell, Kothari...)"},
            session_id=session_id
        )
        
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "research_swarm", "agent_name": "Research Swarm", "status": "running", "action": "Searching methodology sources in parallel...", "icon": "üîç"},
            session_id=session_id
        )
        research_swarm = ResearchSwarm(state)
        # Add methodology-specific configs
        research_swarm.SEARCH_CONFIGS = [
            {"id": "methodology", "scope": "research methodology textbooks saunders creswell kothari mugenda", "quota": 10},
            {"id": "local", "scope": f"{case_study} map area location history geography population", "quota": 5},
            {"id": "data_analysis", "scope": "data analysis procedures SPSS thematic analysis qualitative quantitative triangulation", "quota": 5},
        ]
        await research_swarm.search_all()
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "research_swarm", "agent_name": "Research Swarm", "status": "completed", "action": f"Found {sum(len(p) for p in state.research.values())} methodology sources", "icon": "‚úÖ"},
            session_id=session_id
        )
        
        # Create a Chapter 3 writer swarm with explicit SECTION_CONFIGS
        class ChapterThreeWriterSwarm(WriterSwarm):
            SECTION_CONFIGS = WriterSwarm.CHAPTER_THREE_CONFIGS
        
        writer_swarm = ChapterThreeWriterSwarm(state)
        used_custom_outline = False
        expected_sections = None
        section_titles = {}
        outline_configs = None
        try:
            outline_writer = WriterSwarm(state)
            custom_outline = outline_writer._load_custom_outline()
            outline_configs = outline_writer._build_outline_section_configs(custom_outline)
        except Exception as outline_error:
            print(f"‚ö†Ô∏è Could not build outline configs for Chapter 3: {outline_error}")
        if outline_configs:
            writer_swarm.SECTION_CONFIGS = outline_configs
            used_custom_outline = True
            expected_sections = [
                sec["id"] for cfg in outline_configs for sec in cfg.get("sections", [])
            ]
            section_titles = {
                sec["id"]: sec["title"]
                for cfg in outline_configs
                for sec in cfg.get("sections", [])
            }
            await events.publish(
                job_id,
                "log",
                {"message": "üß≠ Using custom outline sections for Chapter 3"},
                session_id=session_id
            )
        
        # Run parallel writers for methodology sections
        await events.publish(
            job_id,
            "log",
            {"message": "‚úçÔ∏è Phase 2: Launching Methodology Writers..."},
            session_id=session_id
        )
        
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "writer_swarm", "agent_name": "Methodology Writers", "status": "running", "action": "Writing 12 methodology sections in parallel"},
            session_id=session_id
        )
        
        # write_all() uses SECTION_CONFIGS from the ChapterThreeWriterSwarm instance
        results = await writer_swarm.write_all()
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "writer_swarm", "agent_name": "Methodology Writers", "status": "completed", "action": f"Wrote {len(state.sections)} sections", "icon": "‚úÖ"},
            session_id=session_id
        )

        # Ensure all expected sections are present (avoid skipped subsections)
        if expected_sections is None:
            expected_sections = [f"3.{i}" for i in range(1, 13)]
            for config in WriterSwarm.CHAPTER_THREE_CONFIGS:
                for sec in config.get("sections", []):
                    section_titles[sec["id"]] = sec["title"]

        missing_sections = [sec_id for sec_id in expected_sections if sec_id not in state.sections]
        if missing_sections:
            await events.publish(
                job_id,
                "log",
                {"message": f"‚ö†Ô∏è Chapter 3 missing sections detected: {', '.join(missing_sections)}. Retrying generation for missing sections."},
                session_id=session_id
            )
            section_lookup = {}
            fallback_configs = outline_configs if used_custom_outline and outline_configs else WriterSwarm.CHAPTER_THREE_CONFIGS
            for config in fallback_configs:
                for sec in config.get("sections", []):
                    section_lookup[sec["id"]] = sec

            missing_configs = [section_lookup[sec_id] for sec_id in missing_sections if sec_id in section_lookup]
            try:
                fallback_results = await writer_swarm._writer_agent("chapter3_fallback_writer", missing_configs)
                for sec_id, content in fallback_results.items():
                    state.sections[sec_id] = content
            except Exception as fallback_error:
                await events.publish(
                    job_id,
                    "log",
                    {"message": f"‚ö†Ô∏è Chapter 3 fallback generation failed: {fallback_error}. Inserting minimal placeholders."},
                    session_id=session_id
                )

            still_missing = [sec_id for sec_id in expected_sections if sec_id not in state.sections]
            for sec_id in still_missing:
                title = section_titles.get(sec_id, "Section")
                if sec_id == "3.8":
                    fallback = (
                        "Data collection instruments are the tools used to gather information from respondents in line "
                        "with the study objectives. For this study, a structured questionnaire with a 5-point Likert scale "
                        "and a semi-structured interview guide were adopted to capture both quantitative perceptions and "
                        "qualitative insights from stakeholders across the case study countries. The questionnaire covered "
                        "demographic characteristics and objective-based items, while interviews elicited contextual narratives "
                        "on security sector reform dynamics. The instruments were designed to ensure comparability across sites "
                        "and to support both statistical analysis and thematic interpretation."
                    )
                elif sec_id == "3.9":
                    fallback = (
                        "Validity and reliability ensured that the research instruments measured the intended constructs "
                        "consistently and accurately. Content validity was established through expert review of the instruments, "
                        "aligning each item with the study objectives. Reliability was assessed through a pilot study and internal "
                        "consistency testing using Cronbach‚Äôs alpha, with coefficients exceeding the acceptable threshold of 0.70. "
                        "These procedures strengthened the credibility of the collected data and supported robust analysis."
                    )
                elif sec_id == "3.10":
                    fallback = (
                        "Data collection followed a structured, stepwise procedure beginning with institutional permissions and "
                        "participant consent. Questionnaires were administered in person to the sampled respondents, with follow-up "
                        "visits to maximise response rates. Interviews were scheduled with key informants to deepen understanding of "
                        "institutional reform practices. Completed instruments were securely stored, coded, and prepared for analysis "
                        "to ensure data integrity and confidentiality."
                    )
                elif sec_id == "3.11":
                    fallback = (
                        "Data analysis combined descriptive statistics for survey responses with inferential techniques to test "
                        "relationships between key variables. Quantitative data were coded and analysed using statistical software, "
                        "while qualitative interview notes were thematically analysed to identify recurring patterns. The mixed-methods "
                        "approach ensured that statistical trends were contextualised with explanatory narratives."
                    )
                elif sec_id == "3.12":
                    fallback = (
                        "Ethical considerations included informed consent, confidentiality, and the protection of participants from "
                        "harm. The study obtained relevant approvals, ensured voluntary participation, and anonymised all responses. "
                        "Data were stored securely and used solely for academic purposes."
                    )
                else:
                    fallback = (
                        f"This section presents the {title.lower()} for the study on {topic} in {case_study}. "
                        "It outlines the key methodological considerations necessary to address the research objectives."
                    )

                state.sections[sec_id] = SectionContent(
                    title=title,
                    content=fallback,
                    citations=[],
                    word_count=len(fallback.split()),
                    status="completed"
                )
        
        # Phase 3: Quality Control (This adds the reference list)
        await events.publish(
            job_id,
            "log",
            {"message": "‚úì Phase 3: Quality Control and Reference List Generation..."},
            session_id=session_id
        )
        
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "quality_control", "agent_name": "Quality Control", "status": "running", "action": "Validating citations and combining sections...", "icon": "‚úì"},
            session_id=session_id
        )
        quality_swarm = QualitySwarm(state)
        final_content = await quality_swarm.validate_and_combine()
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "quality_control", "agent_name": "Quality Control", "status": "completed", "action": "Quality checks completed", "icon": "‚úÖ"},
            session_id=session_id
        )

        if thesis_type != "general":
            try:
                await self._enforce_quality_gates(
                    final_content,
                    chapter_number=3,
                    job_id=job_id,
                    session_id=session_id,
                    sample_size=sample_size,
                    objectives=objectives
                )
            except ValueError as quality_error:
                if not allow_quality_failure:
                    raise
                await events.publish(
                    job_id,
                    "log",
                    {"message": f"‚ö†Ô∏è Chapter 3 quality gate failed (continuing): {quality_error}"},
                    session_id=session_id
                )
        
        # Calculate stats
        elapsed = (datetime.now() - start_time).total_seconds()
        word_count = len(final_content.split())
        
        # Save file
        from services.workspace_service import WORKSPACES_DIR
        import os
        workspace_path = WORKSPACES_DIR / state.workspace_id
        os.makedirs(workspace_path, exist_ok=True)
        
        safe_topic = "".join(c if c.isalnum() or c in " -_" else "" for c in topic)[:50]
        filename = f"Chapter_3_Research_Methodology_{safe_topic.replace(' ', '_')}.md"
        filepath = os.path.join(workspace_path, filename)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(final_content)
        
        await events.publish(
            job_id,
            "file_created",
            {"path": filepath, "filename": filename, "type": "markdown", "auto_open": True},
            session_id=session_id
        )
        
        # NEW: Generate and save future tense version for proposal
        try:
            from services.tense_converter import convert_to_future_tense_llm
            
            await events.publish(
                job_id,
                "log",
                {"message": "üîÑ Generating proposal version (future tense)..."},
                session_id=session_id
            )
            
            # Use async LLM converter directly since we are in async context
            proposal_content = await convert_to_future_tense_llm(final_content, chapter_number=3)
            
            proposal_filename = filename.replace('.md', '_PROPOSAL.md')
            proposal_filepath = workspace_path / proposal_filename
            
            with open(proposal_filepath, 'w', encoding='utf-8') as f:
                # Add proposal header
                proposal_header = "# PROPOSAL VERSION (Future Tense)\n\n> **Note:** This is the proposal version of Chapter 3 with future tense for research proposals.\n> For the final thesis version (past tense), see the main Chapter 3 file.\n\n---\n\n"
                f.write(proposal_header + proposal_content)
            
            await events.publish(
                job_id,
                "file_created",
                {"path": str(proposal_filepath), "filename": proposal_filename, "type": "markdown"},
                session_id=session_id
            )
            
            await events.publish(
                job_id,
                "log",
                {"message": f"‚úÖ Saved both versions: {filename} (thesis) and {proposal_filename} (proposal)"},
                session_id=session_id
            )
        except Exception as e:
            print(f"‚ö†Ô∏è Proposal generation error: {e}")
            # Fallback to simple copy if conversion fails
            await events.publish(job_id, "log", {"message": f"‚ö†Ô∏è Could not generate proposal version: {e}"}, session_id=session_id)
        
        # Final summary
        await events.publish(
            job_id,
            "response_chunk",
            {"chunk": f"\n\n---\n\n‚úÖ **Chapter Three Complete!**\n\n"
                     f"üìÑ **Thesis Version (Past Tense):** `{filename}`\n"
                     f"üìÑ **Proposal Version (Future Tense):** `{proposal_filename}`\n\n"
                     f"**Stats:**\n"
                     f"- ‚è±Ô∏è Generated in {elapsed:.1f} seconds\n"
                     f"- üìù {word_count:,} words\n"
                     f"- üìê Includes formulas, tables, diagrams\n\n", 
             "accumulated": final_content},
            session_id=session_id
        )
        
        return final_content
        
    async def generate_chapter_four(
        self,
        job_id: str,
        session_id: str,
        workspace_id: str,
        thesis_type: str = "phd",
        sample_size: int = None,
        allow_quality_failure: bool = False
    ) -> str:
        """Generate Chapter 4 (Data Analysis) using the dedicated generator."""
        await events.publish(job_id, "log", {"message": "üìä Starting Chapter 4: Data Analysis & Presentation..."}, session_id=session_id)
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "analysis_swarm", "agent_name": "Analysis Swarm", "status": "running", "action": "Generating Chapter 4 tables, figures, and analysis...", "icon": "üìä"},
            session_id=session_id
        )
        
        # 1. Get objectives and details from DB
        db = resolve_thesis_db(session_id, workspace_id)
        topic = db.get_topic() or "Research Study"
        case_study = db.get_case_study() or "General Context"
        objectives_data = db.get_objectives()
        objectives = objectives_data.get('specific', []) if objectives_data else []
        
        # CLEAN METADATA: Regex strip of leaks (n=120, topic=...) from OBJECTIVES and TOPIC
        import re
        
        # Clean Topic
        topic = re.sub(r'n\s*=\s*\d+', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'topic\s*=\s*["\'].*?["\']', '', topic, flags=re.IGNORECASE)  # Remove explicit topic="..." if inside topic
        topic = re.sub(r'case[_\s]?study\s*=\s*["\'].*?["\']', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'design\s*=\s*\w+', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'/uoj_phd\s*\w*', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'\s+', ' ', topic).strip()

        # STRICT BIFURCATION: If General Thesis, use separate logic TOTALLY
        if thesis_type == "general":
             return await self._generate_chapter_four_general(topic, case_study, job_id, session_id, workspace_id, objectives, sample_size=sample_size)

        clean_objs = []
        for obj in objectives:
            # Remove n=..., topic=..., design=..., uoj_phd...
            cleaned = re.sub(r'n\s*=\s*\d+', '', obj, flags=re.IGNORECASE)
            cleaned = re.sub(r'topic\s*=\s*["\'].*?["\']', '', cleaned, flags=re.IGNORECASE)
            cleaned = re.sub(r'case[_\s]?study\s*=\s*["\'].*?["\']', '', cleaned, flags=re.IGNORECASE)
            cleaned = re.sub(r'design\s*=\s*\w+', '', cleaned, flags=re.IGNORECASE)
            cleaned = re.sub(r'/uoj_phd\s*\w*', '', cleaned, flags=re.IGNORECASE)
            # Remove any trailing/multiple spaces
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()
            if cleaned:
                clean_objs.append(cleaned)
        objectives = clean_objs
        
        # 2. Invoke Generator
        result_map = await generate_chapter4(
            topic=topic,
            case_study=case_study,
            objectives=objectives,
            workspace_id=workspace_id,
            job_id=job_id,
            session_id=session_id,
            sample_size=sample_size
        )

        content = result_map.get("content", "")
        if thesis_type != "general" and content:
            try:
                await self._enforce_quality_gates(
                    content,
                    chapter_number=4,
                    job_id=job_id,
                    session_id=session_id,
                    sample_size=sample_size,
                    objectives=objectives
                )
            except ValueError as quality_error:
                if not allow_quality_failure:
                    raise
                await events.publish(
                    job_id,
                    "log",
                    {"message": f"‚ö†Ô∏è Chapter 4 quality gate failed (continuing): {quality_error}"},
                    session_id=session_id
                )

        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "analysis_swarm", "agent_name": "Analysis Swarm", "status": "completed", "action": "Chapter 4 analysis completed", "icon": "‚úÖ"},
            session_id=session_id
        )
        # 3. Return content (it returns a dict, extract content)
        # Note: generate_chapter4 returns a Dict with 'content' key
        return content

    async def _generate_chapter_four_general(
        self, topic: str, case_study: str, job_id: str, session_id: str, workspace_id: str, objectives: List[str], sample_size: int = 100
    ) -> str:
        """Dedicated generator for General Thesis Chapter 4 (Data Analysis)."""
        await events.publish(job_id, "log", {"message": "üìä Entering General Thesis Chapter 4 Analysis..."}, session_id=session_id)
        from services.chapter4_generator import generate_chapter4
        from services.workspace_service import WORKSPACES_DIR
        from pathlib import Path

        datasets_dir = str(WORKSPACES_DIR / (workspace_id or "default") / "datasets")
        output_dir = str(WORKSPACES_DIR / (workspace_id or "default") / "chapters")
        os.makedirs(datasets_dir, exist_ok=True)
        os.makedirs(output_dir, exist_ok=True)

        result_map = await generate_chapter4(
            topic=topic,
            case_study=case_study,
            objectives=objectives,
            datasets_dir=datasets_dir,
            output_dir=output_dir,
            sample_size=sample_size,
            job_id=job_id,
            session_id=session_id,
            workspace_id=workspace_id
        )

        content = result_map.get("content", "") or result_map.get("markdown", "")
        if not content:
            filepath = result_map.get("filepath")
            if filepath and os.path.exists(filepath):
                with open(filepath, "r", encoding="utf-8") as f:
                    content = f.read()

        if not content:
            await events.publish(
                job_id,
                "log",
                {"message": "‚ö†Ô∏è Chapter 4 generation returned empty content. Please retry after dataset generation completes."},
                session_id=session_id
            )
            content = "# CHAPTER FOUR\n\nData analysis could not be generated. Please retry after dataset generation completes."

        filepath = result_map.get("filepath")
        if not filepath:
            try:
                candidates = list(Path(output_dir).glob("Chapter_4*.md"))
                if candidates:
                    latest = max(candidates, key=lambda p: p.stat().st_mtime)
                    filepath = str(latest)
            except Exception:
                filepath = None

        if not filepath:
            safe_topic = re.sub(r"[^\w\s-]", "", topic)[:50].replace(" ", "_")
            filename = f"Chapter_4_Data_Analysis_{safe_topic}.md"
            os.makedirs(output_dir, exist_ok=True)
            filepath = os.path.join(output_dir, filename)
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(content)

        if filepath:
            await events.publish(
                job_id,
                "file_created",
                {"path": filepath, "filename": os.path.basename(filepath), "type": "markdown", "auto_open": True},
                session_id=session_id
            )

        return content

    async def generate_chapter_five(
        self,
        job_id: str,
        session_id: str,
        workspace_id: str,
        thesis_type: str = "phd",
        sample_size: int = None,
        allow_quality_failure: bool = False
    ) -> str:
        """Generate Chapter 5 (Results & Discussion) using the dedicated generator."""
        await events.publish(job_id, "log", {"message": "üó£Ô∏è Starting Chapter 5: Discussion of Results..."}, session_id=session_id)
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "discussion_swarm", "agent_name": "Discussion Swarm", "status": "running", "action": "Writing Chapter 5 discussions in parallel...", "icon": "üó£Ô∏è"},
            session_id=session_id
        )
        
        # 1. Get objectives and details from DB
        db = resolve_thesis_db(session_id, workspace_id)
        topic = db.get_topic() or "Research Study"
        case_study = db.get_case_study() or "General Context"
        objectives_data = db.get_objectives()
        objectives = objectives_data.get('specific', []) if objectives_data else []

        # STRICT BIFURCATION: If General Thesis, use separate logic TOTALLY
        if thesis_type == "general":
             return await self._generate_chapter_five_general(topic, case_study, job_id, session_id, workspace_id, objectives)

        # CLEAN METADATA: Regex strip of leaks from TOPIC and OBJECTIVES
        import re
        
        # Clean Topic
        topic = re.sub(r'n\s*=\s*\d+', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'topic\s*=\s*["\'].*?["\']', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'case[_\s]?study\s*=\s*["\'].*?["\']', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'design\s*=\s*\w+', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'/uoj_phd\s*\w*', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'\s+', ' ', topic).strip()

        clean_objs = []
        for obj in objectives:
            # Remove n=..., topic=..., design=..., uoj_phd...
            cleaned = re.sub(r'n\s*=\s*\d+', '', obj, flags=re.IGNORECASE)
            cleaned = re.sub(r'topic\s*=\s*["\'].*?["\']', '', cleaned, flags=re.IGNORECASE)
            cleaned = re.sub(r'case[_\s]?study\s*=\s*["\'].*?["\']', '', cleaned, flags=re.IGNORECASE)
            cleaned = re.sub(r'design\s*=\s*\w+', '', cleaned, flags=re.IGNORECASE)
            cleaned = re.sub(r'/uoj_phd\s*\w*', '', cleaned, flags=re.IGNORECASE)
            # Remove any trailing/multiple spaces
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()
            if cleaned:
                clean_objs.append(cleaned)
        objectives = clean_objs
        
        # 2. Invoke Generator (it auto-finds previous chapters if not passed)
        result_map = await generate_chapter5(
            topic=topic,
            case_study=case_study,
            objectives=objectives,
            job_id=job_id,
            session_id=session_id,
            output_dir=None,
            sample_size=sample_size
        )

        content = result_map.get("content", "")
        if not content and result_map.get("filepath") and os.path.exists(result_map["filepath"]):
            with open(result_map["filepath"], "r", encoding="utf-8") as f:
                content = f.read()

        if thesis_type != "general" and content:
            try:
                await self._enforce_quality_gates(
                    content,
                    chapter_number=5,
                    job_id=job_id,
                    session_id=session_id,
                    sample_size=sample_size,
                    objectives=objectives
                )
            except ValueError as quality_error:
                if not allow_quality_failure:
                    raise
                await events.publish(
                    job_id,
                    "log",
                    {"message": f"‚ö†Ô∏è Chapter 5 quality gate failed (continuing): {quality_error}"},
                    session_id=session_id
                )
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "discussion_swarm", "agent_name": "Discussion Swarm", "status": "completed", "action": "Chapter 5 discussion completed", "icon": "‚úÖ"},
            session_id=session_id
        )
        return content



    async def _generate_chapter_five_general(
        self, topic: str, case_study: str, job_id: str, session_id: str, workspace_id: str, objectives: List[str], sample_size: int = None
    ) -> str:
        """Dedicated generator for General Thesis Chapter 5 (Discussion, Conclusion, Recommendations)."""
        await events.publish(job_id, "log", {"message": "üó£Ô∏è Entering General Thesis Chapter 5 (Merged)..."}, session_id=session_id)
        from services.workspace_service import WORKSPACES_DIR
        workspace_dir = WORKSPACES_DIR / (workspace_id or "default")

        def load_latest_chapter(prefix: str) -> str:
            paths = sorted(list((workspace_dir / "chapters").glob(f"{prefix}*.md")) + list(workspace_dir.glob(f"{prefix}*.md")))
            if not paths:
                return ""
            latest = max(paths, key=lambda p: p.stat().st_mtime)
            try:
                with open(latest, "r", encoding="utf-8") as f:
                    return f.read()
            except Exception:
                return ""

        chapter2_content = load_latest_chapter("Chapter_2") or ""
        chapter4_content = load_latest_chapter("Chapter_4") or ""

        citation_pattern = re.compile(r"\[([^\]]+)\]\((https?://[^)]+)\)")
        citations = []
        seen_citations = set()
        for match in citation_pattern.finditer(chapter2_content):
            text = match.group(1).strip()
            url = match.group(2).strip()
            if not text or not url:
                continue
            if not re.search(r"\(\d{4}\)", text):
                continue
            key = f"{text}|{url}".lower()
            if key in seen_citations:
                continue
            seen_citations.add(key)
            citations.append({"text": text, "url": url})
        if not citations:
            try:
                from services.sources_service import SourcesService
                sources_service = SourcesService()
                sources_index = sources_service._load_index(workspace_id or "default")
                sources = sources_index.get("sources", []) if isinstance(sources_index, dict) else []
                for source in sources[:12]:
                    authors = source.get("authors") or []
                    year = source.get("year")
                    url = source.get("url") or ""
                    doi = source.get("doi") or ""
                    if not url and doi:
                        url = doi if doi.startswith("http") else f"https://doi.org/{doi}"
                    if not year:
                        continue
                    author_text = "Unknown"
                    if authors:
                        if isinstance(authors[0], dict):
                            author_name = authors[0].get("name", "").strip()
                        else:
                            author_name = str(authors[0]).strip()
                        author_parts = author_name.split()
                        author_last = author_parts[-1] if author_parts else "Unknown"
                        if len(authors) > 2:
                            author_text = f"{author_last} et al."
                        elif len(authors) == 2:
                            if isinstance(authors[1], dict):
                                second_name = authors[1].get("name", "").strip()
                            else:
                                second_name = str(authors[1]).strip()
                            second_last = second_name.split()[-1] if second_name else "Unknown"
                            author_text = f"{author_last} & {second_last}"
                        else:
                            author_text = author_last
                    citation_text = f"{author_text} ({year})"
                    if not url:
                        url = ""
                    key = f"{citation_text}|{url}".lower()
                    if key in seen_citations:
                        continue
                    seen_citations.add(key)
                    citations.append({"text": citation_text, "url": url})
            except Exception as exc:
                print(f"‚ö†Ô∏è Could not load fallback citations: {exc}")

        if not citations:
            await events.publish(
                job_id,
                "log",
                {"message": "‚ö†Ô∏è Chapter 5: No linked citations found in Chapter 2. Discussion will be generated without citations."},
                session_id=session_id
            )

        def take_citations(count: int) -> str:
            if not citations:
                return ""
            selected = []
            for _ in range(count):
                idx = (take_citations.counter) % len(citations)
                take_citations.counter += 1
                selected.append(citations[idx])
            rendered = []
            for c in selected:
                if c.get("url"):
                    rendered.append(f"[{c['text']}]({c['url']})")
                else:
                    rendered.append(c["text"])
            return " ".join(rendered)

        take_citations.counter = 0

        def extract_objective_sections(text: str) -> Dict[int, str]:
            sections = {}
            pattern = re.compile(r"^##\\s+4\\.(\\d+)\\s+Findings on Objective\\s+(\\d+)\\s*:\\s*(.+)$", re.MULTILINE)
            matches = list(pattern.finditer(text))
            for idx, match in enumerate(matches):
                obj_num = int(match.group(2))
                start = match.end()
                end = matches[idx + 1].start() if idx + 1 < len(matches) else len(text)
                sections[obj_num] = text[start:end].strip()
            return sections

        def first_paragraphs(text: str, count: int = 2) -> str:
            if not text:
                return ""
            parts = [p.strip() for p in re.split(r"\n\\s*\n", text) if p.strip()]
            filtered = []
            for part in parts:
                if part.startswith("|") or "\n|" in part:
                    continue
                if part.lower().startswith("table ") or part.lower().startswith("figure "):
                    continue
                filtered.append(part)
                if len(filtered) >= count:
                    break
            return "\n\n".join(filtered)

        objective_sections = extract_objective_sections(chapter4_content)

        content = "# CHAPTER FIVE\n\n## DISCUSSION, CONCLUSIONS, AND RECOMMENDATIONS\n\n"
        content += "### 5.0 Introduction\n"
        content += (
            f"This chapter interprets the findings from Chapter Four and discusses them in relation to the literature reviewed in Chapter Two. "
            f"The discussion is organized around the study objectives for {topic} in {case_study}. "
            f"Where relevant, the discussion compares empirical findings with prior studies from the reviewed literature.\n\n"
        )

        content += "### 5.1 Summary of Findings\n"
        content += (
            f"The purpose of the study was to {topic.lower()} in {case_study}. "
            "The summary below highlights the main findings for each objective, grounded in the empirical evidence.\n\n"
        )

        for idx, obj in enumerate(objectives, 1):
            content += f"#### 5.1.{idx} Summary on {obj}\n"
            section_text = objective_sections.get(idx, "")
            summary = first_paragraphs(section_text, count=2)
            if not summary:
                summary = f"The findings on {obj.lower()} indicated observable patterns in the data gathered from the study sample."
            citations_text = take_citations(2)
            if citations_text:
                summary = f"{summary}\n\nThese findings align with prior studies in the reviewed literature {citations_text}."
            content += f"{summary}\n\n"

        content += "### 5.2 Conclusions\n"
        content += (
            "Based on the findings, the following conclusions are drawn. "
            f"Overall, the study concludes that {topic.lower()} in {case_study} is shaped by multiple institutional and contextual factors.\n\n"
        )

        for idx, obj in enumerate(objectives, 1):
            conclusion = f"It is concluded that {obj.lower()} is a critical dimension of the study outcomes and requires sustained attention from key stakeholders."
            citations_text = take_citations(1)
            if citations_text:
                conclusion = f"{conclusion} {citations_text}."
            content += f"#### 5.2.{idx} Conclusion on {obj}\n{conclusion}\n\n"

        content += "### 5.3 Recommendations\n"
        content += "Based on the conclusions, the study recommends the following actions to improve practice and policy.\n\n"

        for idx, obj in enumerate(objectives, 1):
            recommendation = (
                f"Institutions involved in {obj.lower()} should strengthen capacity, monitoring, and accountability mechanisms "
                "to sustain the observed gains and address gaps identified in the data."
            )
            content += f"#### 5.3.{idx} Recommendation on {obj}\n{recommendation}\n\n"

        content += "### 5.4 Suggestions for Future Studies\n"
        content += (
            f"This study focused on {topic.lower()} in {case_study}. Future research should:\n"
            "1. Replicate the study in different contexts to enable comparative insights.\n"
            "2. Explore additional variables that were not captured in the present dataset.\n"
            "3. Examine longitudinal outcomes to assess the durability of the observed patterns.\n"
        )

        safe_topic = re.sub(r"[^\w\s-]", "", topic)[:50].replace(" ", "_")
        filename = f"Chapter_5_Discussion_{safe_topic}.md"
        os.makedirs(workspace_dir, exist_ok=True)
        filepath = workspace_dir / filename
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)

        await events.publish(
            job_id,
            "file_created",
            {"path": str(filepath), "filename": filename, "type": "markdown", "auto_open": True},
            session_id=session_id
        )

        return content

    async def generate_chapter_six(self, job_id: str, session_id: str, workspace_id: str, thesis_type: str = "phd", sample_size: int = None) -> str:
        """Generate Chapter 6 (Conclusions & Recommendations) using the dedicated generator."""
        await events.publish(job_id, "log", {"message": "üèÅ Starting Chapter 6: Summary, Conclusions & Recommendations..."}, session_id=session_id)
        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "conclusion_swarm", "agent_name": "Conclusion Swarm", "status": "running", "action": "Drafting conclusions and recommendations...", "icon": "üèÅ"},
            session_id=session_id
        )
        
        # 1. Get objectives and details from DB
        db = resolve_thesis_db(session_id, workspace_id)
        topic = db.get_topic() or "Research Study"
        case_study = db.get_case_study() or "General Context"
        objectives_data = db.get_objectives()
        objectives = objectives_data.get('specific', []) if objectives_data else []

        # CLEAN METADATA: Regex strip of leaks from TOPIC and OBJECTIVES
        import re
        
        # Clean Topic
        topic = re.sub(r'n\s*=\s*\d+', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'topic\s*=\s*["\'].*?["\']', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'case[_\s]?study\s*=\s*["\'].*?["\']', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'design\s*=\s*\w+', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'/uoj_phd\s*\w*', '', topic, flags=re.IGNORECASE)
        topic = re.sub(r'\s+', ' ', topic).strip()

        clean_objs = []
        for obj in objectives:
            # Remove n=..., topic=..., design=..., uoj_phd...
            cleaned = re.sub(r'n\s*=\s*\d+', '', obj, flags=re.IGNORECASE)
            cleaned = re.sub(r'topic\s*=\s*["\'].*?["\']', '', cleaned, flags=re.IGNORECASE)
            cleaned = re.sub(r'case[_\s]?study\s*=\s*["\'].*?["\']', '', cleaned, flags=re.IGNORECASE)
            cleaned = re.sub(r'design\s*=\s*\w+', '', cleaned, flags=re.IGNORECASE)
            cleaned = re.sub(r'/uoj_phd\s*\w*', '', cleaned, flags=re.IGNORECASE)
            # Remove any trailing/multiple spaces
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()
            if cleaned:
                clean_objs.append(cleaned)
        objectives = clean_objs
        
        # 2. Load previous content from files (Best effort)
        # Assuming files are in workspace/default or similar
        from services.workspace_service import WORKSPACES_DIR
        import os
        base_dir = WORKSPACES_DIR / (workspace_id or "default")
        
        def load_chapter(num):
            try:
                # Naive pattern match
                for f in os.listdir(base_dir):
                    if f.lower().startswith(f"chapter_{num}") and f.endswith(".md"):
                        return (base_dir / f).read_text()
            except:
                pass
            return ""

        c1 = load_chapter(1)
        c2 = load_chapter(2)
        c3 = load_chapter(3)
        c4 = load_chapter(4)
        c5 = load_chapter(5)

        # 3. Invoke Generator (Synchronous!)
        content = generate_chapter6(
            topic=topic,
            case_study=case_study,
            objectives=objectives,
            chapter_one_content=c1,
            chapter_two_content=c2,
            chapter_three_content=c3,
            chapter_four_content=c4,
            chapter_five_content=c5,
            output_dir=str(base_dir),
            sample_size=sample_size
        )
        
        # Save file (Ch6 generator returns string but doesn't auto-save?)
        # Checking Ch6 generator code, it calls generate_full_chapter().
        # It does NOT seem to save automatically in the Wrapper?
        # So we must save it here.
        
        filename = f"Chapter_6_Conclusions_{topic[:20].replace(' ', '_')}.md"
        filepath = base_dir / filename
        with open(filepath, "w") as f:
            f.write(content)
            
        await events.publish(
            job_id,
            "file_created",
            {"path": str(filepath), "filename": filename, "type": "markdown", "auto_open": True},
            session_id=session_id
        )

        await events.publish(
            job_id,
            "agent_activity",
            {"agent": "conclusion_swarm", "agent_name": "Conclusion Swarm", "status": "completed", "action": "Chapter 6 completed", "icon": "‚úÖ"},
            session_id=session_id
        )
        
        return content

    async def generate_full_thesis_sequence(
        self,
        topic: str,
        case_study: str,
        job_id: str,
        session_id: str,
        workspace_id: str = "default",
        sample_size: int = 385,
        thesis_type: str = "phd",
        objectives: List[str] = None,
        research_design: str = None,
        preferred_analyses: List[str] = None,
        custom_instructions: str = "",
        chapter2_paragraphs: int = None,
        chapter2_paragraph_plan: Dict[str, Any] = None,
        allow_quality_failure: bool = False
    ) -> Dict[int, str]:
        """Generate all chapters in sequence (1 through 6)."""
        
        start_time = datetime.now()
        results = {}
        try:
            sample_size = int(float(sample_size))
        except (TypeError, ValueError):
            sample_size = 385
        if sample_size <= 0:
            sample_size = 385
        
        # Ensure DB has session set up if not already
        db = resolve_thesis_db(session_id, workspace_id)
        if not db.get_topic():
            db.create_session(topic, case_study)

        from services.plan_tracker import ensure_plan_file, get_plan_chapter_labels, mark_plan_item
        from services.outline_parser import outline_parser
        from services.workspace_service import WORKSPACES_DIR

        outline_path = WORKSPACES_DIR / (workspace_id or "default") / "outline.json"
        outline = None
        if thesis_type == "general" and outline_path.exists():
            outline = outline_parser.load_outline(workspace_id)
        outline_defaults = outline.get("defaults") if isinstance(outline, dict) else {}
        use_custom_outline = bool(outline and outline.get("chapters"))
        objective_target_count = None
        if isinstance(outline_defaults, dict):
            try:
                objective_target_count = int(outline_defaults.get("specific_objectives") or 0) or None
            except (TypeError, ValueError):
                objective_target_count = None
        plan_path, plan_created = ensure_plan_file(workspace_id or "default", outline, thesis_type)
        plan_chapter_labels = get_plan_chapter_labels(outline, thesis_type)
        plan_label_map = {num: label for num, label in plan_chapter_labels}

        async def _update_plan(label: str, cascade: bool = False):
            if not label:
                return
            if mark_plan_item(workspace_id or "default", label, cascade=cascade):
                await events.publish(
                    job_id,
                    "file_updated",
                    {
                        "path": str(plan_path.relative_to(WORKSPACES_DIR / (workspace_id or "default"))),
                        "full_path": str(plan_path),
                        "filename": plan_path.name,
                        "workspace_id": workspace_id or "default",
                        "type": "markdown"
                    },
                    session_id=session_id
                )

        if plan_created:
            await events.publish(
                job_id,
                "file_created",
                {
                    "path": str(plan_path),
                    "filename": plan_path.name,
                    "workspace_id": workspace_id or "default",
                    "type": "markdown"
                },
                session_id=session_id
            )
            
        research_config = {
            "sample_size": sample_size,
            "research_design": research_design or ("survey" if "survey" in topic.lower() or "quantitative" in topic.lower() else "mixed_methods"),
            "preferred_analyses": preferred_analyses or [],
            "custom_instructions": custom_instructions
        }

        # Save Research Config with Sample Size
        db.save_research_config(research_config)
        
        # Save custom objectives if provided
        normalized_objectives = None
        if objectives:
            normalized_objectives = normalize_objectives(objectives, topic, case_study)
            db.save_objectives(normalized_objectives["general"], normalized_objectives["specific"])
        else:
            # Trigger objective generation if none exist and not provided
            existing_objs = db.get_objectives()
            if not existing_objs or not existing_objs.get('specific'):
                objectives = generate_smart_objectives(topic, objective_target_count or 6)
                normalized_objectives = normalize_objectives(objectives, topic, case_study)
                db.save_objectives(normalized_objectives["general"], normalized_objectives["specific"])
            else:
                normalized_objectives = normalize_objectives(existing_objs, topic, case_study)
                objectives = normalized_objectives.get('specific', [])

        # Mirror config/objectives to workspace-scoped DB for cross-chapter consistency
        if workspace_id and workspace_id != session_id and normalized_objectives:
            try:
                ws_db = ThesisSessionDB(workspace_id)
                ws_db.create_session(topic, case_study)
                ws_db.save_research_config(research_config)
                ws_db.save_objectives(normalized_objectives["general"], normalized_objectives["specific"])
            except Exception as e:
                print(f"‚ö†Ô∏è Could not mirror config/objectives to workspace DB: {e}")
        
        # Refresh planner once objectives are stored to show sections/subsections.
        try:
            from services.plan_tracker import ensure_plan_file
            ensure_plan_file(workspace_id or "default", outline if thesis_type == "general" else None, thesis_type)
        except Exception as e:
            print(f"‚ö†Ô∏è Could not refresh planner after objectives: {e}")
        
        await events.publish(
            job_id, 
            "stage_started", 
            {"stage": "full_thesis_generation", "message": f"üöÄ Starting Complete {'PhD' if thesis_type == 'phd' else 'General'} Thesis Generation for: {topic} (n={sample_size})"}, 
            session_id=session_id
        )

        try:
            if thesis_type == "general":
                # Run General thesis flow with parallel tasks and clear dependencies.
                await events.publish(job_id, "stage_started", {"stage": "prelims", "message": "üìë Generating Preliminary Pages..."}, session_id=session_id)
                prelims_task = asyncio.create_task(
                    generate_preliminary_pages_uoj(
                        topic,
                        case_study,
                        job_id=job_id,
                        session_id=session_id,
                        workspace_id=workspace_id
                    )
                )

                await events.publish(job_id, "stage_started", {"stage": "chapter_1", "message": "üìñ Generating Chapter 1: Introduction"}, session_id=session_id)
                if use_custom_outline:
                    ch1_gen = ParallelChapterGenerator()
                    c1_content = await ch1_gen.generate(
                        topic=topic,
                        case_study=case_study,
                        job_id=job_id,
                        session_id=session_id,
                        workspace_id=workspace_id,
                        thesis_type=thesis_type,
                        objectives=normalized_objectives or objectives,
                        sample_size=sample_size
                    )
                else:
                    country = "South Sudan"
                    c1_content = await generate_chapter_one_uoj(
                        topic, case_study, country, job_id, session_id, workspace_id, normalized_objectives or objectives, thesis_type=thesis_type
                    )

                await events.publish(job_id, "stage_started", {"stage": "chapter_2", "message": "üìö Generating Chapter 2: Literature Review"}, session_id=session_id)
                ch2_gen = ParallelChapterGenerator()
                c2_task = asyncio.create_task(
                    ch2_gen.generate_chapter_two(
                        topic,
                        case_study,
                        job_id,
                        session_id,
                        workspace_id,
                        objectives=normalized_objectives or objectives,
                        thesis_type=thesis_type,
                        sample_size=sample_size,
                        chapter2_paragraphs=chapter2_paragraphs,
                        chapter2_paragraph_plan=chapter2_paragraph_plan,
                        allow_quality_failure=allow_quality_failure
                    )
                )

                await events.publish(job_id, "stage_started", {"stage": "chapter_3", "message": "üß™ Generating Chapter 3: Research Methodology"}, session_id=session_id)
                ch3_gen = ParallelChapterGenerator()
                c3_task = asyncio.create_task(
                    ch3_gen.generate_chapter_three(
                        topic,
                        case_study,
                        job_id,
                        session_id,
                        workspace_id,
                        objectives=normalized_objectives or objectives,
                        thesis_type=thesis_type,
                        sample_size=sample_size,
                        allow_quality_failure=allow_quality_failure
                    )
                )

                c2_content, c3_content = await asyncio.gather(c2_task, c3_task)

                await events.publish(job_id, "stage_started", {"stage": "study_tools", "message": "üìã Generating Study Tools (Questionnaire, Interview Guide)..."}, session_id=session_id)
                from services.workspace_service import WORKSPACES_DIR
                from services.data_collection_worker import generate_study_tools, generate_research_dataset
                tools_dir = str(WORKSPACES_DIR / (workspace_id or "default") / "study_tools")
                os.makedirs(tools_dir, exist_ok=True)
                tools_task = asyncio.create_task(
                    generate_study_tools(
                        topic=topic,
                        objectives=normalized_objectives or objectives,
                        output_dir=tools_dir,
                        job_id=job_id,
                        session_id=session_id,
                        sample_size=sample_size
                    )
                )

                await events.publish(job_id, "stage_started", {"stage": "dataset", "message": f"üé≤ Generating Synthetic Research Dataset (n={sample_size})..."}, session_id=session_id)
                datasets_dir = str(WORKSPACES_DIR / (workspace_id or "default") / "datasets")
                os.makedirs(datasets_dir, exist_ok=True)
                dataset_task = asyncio.create_task(
                    generate_research_dataset(
                        topic=topic,
                        case_study=case_study,
                        objectives=normalized_objectives or objectives,
                        sample_size=sample_size,
                        output_dir=datasets_dir,
                        job_id=job_id,
                        session_id=session_id
                    )
                )

                await asyncio.gather(tools_task, dataset_task)

                await events.publish(job_id, "stage_started", {"stage": "chapter_4", "message": "üìä Generating Chapter 4: Data Analysis"}, session_id=session_id)
                ch4_gen = ParallelChapterGenerator()
                c4_content = await ch4_gen.generate_chapter_four(
                    job_id,
                    session_id,
                    workspace_id,
                    thesis_type=thesis_type,
                    sample_size=sample_size,
                    allow_quality_failure=allow_quality_failure
                )

                await events.publish(job_id, "stage_started", {"stage": "chapter_5", "message": "üèÅ Generating Chapter 5: Discussion, Conclusions & Recommendations"}, session_id=session_id)
                ch5_gen = ParallelChapterGenerator()
                c5_content = await ch5_gen.generate_chapter_five(
                    job_id,
                    session_id,
                    workspace_id,
                    thesis_type=thesis_type,
                    sample_size=sample_size,
                    allow_quality_failure=allow_quality_failure
                )

                prelims = await prelims_task

                results[0] = prelims
                results[1] = c1_content
                await _update_plan(plan_label_map.get(1), cascade=True)
                results[2] = c2_content
                await _update_plan(plan_label_map.get(2), cascade=True)
                results[3] = c3_content
                await _update_plan(plan_label_map.get(3), cascade=True)
                results[4] = c4_content
                await _update_plan(plan_label_map.get(4), cascade=True)
                results[5] = c5_content
                await _update_plan(plan_label_map.get(5), cascade=True)

                await events.publish(job_id, "stage_started", {"stage": "appendices", "message": "üìé Generating Appendices..."}, session_id=session_id)
                try:
                    appendices = await generate_appendices_uoj(topic, objectives)
                    results[10] = appendices
                except Exception as e:
                    print(f"Error generating appendices: {e}")

                await events.publish(job_id, "stage_started", {"stage": "combining", "message": "üìë Combining chapters into final thesis document..."}, session_id=session_id)
                try:
                    from services.thesis_combiner import ThesisCombiner
                    from services.outline_parser import outline_parser
                    combiner_outline = outline if thesis_type == "general" else None
                    if thesis_type == "general" and not combiner_outline:
                        combiner_outline = outline_parser.get_default_outline("uoj_bsc_accounting_finance")
                    combiner = ThesisCombiner(
                        workspace_id=workspace_id,
                        topic=topic,
                        case_study=case_study,
                        objectives=objectives,
                        output_dir=None,
                        custom_outline=combiner_outline
                    )
                    combiner.load_chapters_from_files()
                    combined_content, combined_path = combiner.combine_thesis()
                    await events.publish(job_id, "file_created", {"path": combined_path, "filename": os.path.basename(combined_path), "type": "markdown", "auto_open": True}, session_id=session_id)
                    await events.publish(job_id, "stage_completed", {"stage": "combining", "message": f"‚úÖ Final Thesis Combined: {os.path.basename(combined_path)}"}, session_id=session_id)
                    results["combined_thesis"] = combined_path
                except Exception as e:
                    print(f"‚ùå Error combining thesis: {e}")
                    await events.publish(job_id, "error", {"message": f"Failed to combine thesis: {str(e)}"}, session_id=session_id)

                return results

            # 0. Preliminary Pages (General Only)
            if thesis_type == "general":
                await events.publish(job_id, "stage_started", {"stage": "prelims", "message": "üìë Generating Preliminary Pages..."}, session_id=session_id)
                prelims = await generate_preliminary_pages_uoj(
                    topic,
                    case_study,
                    job_id=job_id,
                    session_id=session_id,
                    workspace_id=workspace_id
                )
                results[0] = prelims
            
            # Chapter 1 - Introduction
            await events.publish(job_id, "stage_started", {"stage": "chapter_1", "message": "üìñ Generating Chapter 1: Introduction"}, session_id=session_id)
            
            if thesis_type == "general":
                # Retrieve country from entities or default
                country = "South Sudan"  # Default country for UoJ theses
                
                c1_content = await generate_chapter_one_uoj(
                    topic, case_study, country, job_id, session_id, workspace_id, objectives, thesis_type=thesis_type
                )
            else:
                c1_content = await self.generate(
                    topic,
                    case_study,
                    job_id,
                    session_id,
                    workspace_id,
                    thesis_type=thesis_type,
                    objectives=objectives,
                    sample_size=sample_size,
                    allow_quality_failure=allow_quality_failure
                )
                
            results[1] = c1_content
            await _update_plan(plan_label_map.get(1), cascade=True)
            
            # Chapter 2 - Literature Review
            await events.publish(job_id, "stage_started", {"stage": "chapter_2", "message": "üìö Generating Chapter 2: Literature Review"}, session_id=session_id)
            c2_content = await self.generate_chapter_two(
                topic,
                case_study,
                job_id,
                session_id,
                workspace_id,
                objectives=objectives,
                thesis_type=thesis_type,
                sample_size=sample_size,
                chapter2_paragraphs=chapter2_paragraphs,
                chapter2_paragraph_plan=chapter2_paragraph_plan,
                allow_quality_failure=allow_quality_failure
            )
            results[2] = c2_content
            await _update_plan(plan_label_map.get(2), cascade=True)

            # Chapter 3 - Methodology
            await events.publish(job_id, "stage_started", {"stage": "chapter_3", "message": "üß™ Generating Chapter 3: Research Methodology"}, session_id=session_id)
            c3_content = await self.generate_chapter_three(
                topic,
                case_study,
                job_id,
                session_id,
                workspace_id,
                objectives=objectives,
                thesis_type=thesis_type,
                sample_size=sample_size,
                allow_quality_failure=allow_quality_failure
            )
            results[3] = c3_content
            await _update_plan(plan_label_map.get(3), cascade=True)
            
            # Retrieve objectives for tools generation
            objectives_data = db.get_objectives()
            objectives = objectives_data.get('specific', []) if objectives_data else []

            # Step 4 & 5: Tools & Dataset (For BOTH PhD and General)
            # Step 4: Study Tools
            await events.publish(job_id, "stage_started", {"stage": "study_tools", "message": "üìã Generating Study Tools (Questionnaire, Interview Guide)..."}, session_id=session_id)
            from services.workspace_service import WORKSPACES_DIR
            from services.data_collection_worker import generate_study_tools, generate_research_dataset
            tools_dir = str(WORKSPACES_DIR / (workspace_id or "default") / "study_tools")
            os.makedirs(tools_dir, exist_ok=True)

            # Step 5: Synthetic Dataset (run in parallel with tools to save time)
            await events.publish(job_id, "stage_started", {"stage": "dataset", "message": f"üé≤ Generating Synthetic Research Dataset (n={sample_size})..."}, session_id=session_id)
            datasets_dir = str(WORKSPACES_DIR / (workspace_id or "default") / "datasets")
            os.makedirs(datasets_dir, exist_ok=True)

            await asyncio.gather(
                generate_study_tools(
                    topic=topic,
                    objectives=objectives,
                    output_dir=tools_dir,
                    job_id=job_id,
                    session_id=session_id,
                    sample_size=sample_size
                ),
                generate_research_dataset(
                    topic=topic,
                    case_study=case_study,
                    objectives=objectives,
                    sample_size=sample_size,
                    output_dir=datasets_dir,
                    job_id=job_id,
                    session_id=session_id
                ),
            )

            # Chapter 4 - Data Analysis
            await events.publish(job_id, "stage_started", {"stage": "chapter_4", "message": "üìä Generating Chapter 4: Data Analysis"}, session_id=session_id)
            # Ch4 wrapper needs objectives passed explicitly or it fetches from DB.
            # We updated generate_chapter_four to fetch from DB, so invoking it is safe.
            c4_content = await self.generate_chapter_four(
                job_id,
                session_id,
                workspace_id,
                thesis_type=thesis_type,
                sample_size=sample_size,
                allow_quality_failure=allow_quality_failure
            )
            results[4] = c4_content
            await _update_plan(plan_label_map.get(4), cascade=True)

            # Chapter 5 - Findings & Discussion (General: Findings, Discussion & Conclusion)
            msg = "üó£Ô∏è Generating Chapter 5: Discussion" if thesis_type == "phd" else "üèÅ Generating Chapter 5: Discussion, Conclusions & Recommendations"
            await events.publish(job_id, "stage_started", {"stage": "chapter_5", "message": msg}, session_id=session_id)
            c5_content = await self.generate_chapter_five(
                job_id,
                session_id,
                workspace_id,
                thesis_type=thesis_type,
                sample_size=sample_size,
                allow_quality_failure=allow_quality_failure
            )
            results[5] = c5_content
            await _update_plan(plan_label_map.get(5), cascade=True)

            # Appendices (General Only)
            if thesis_type == "general":
                await events.publish(job_id, "stage_started", {"stage": "appendices", "message": "üìé Generating Appendices..."}, session_id=session_id)
                try:
                    appendices = await generate_appendices_uoj(topic, objectives)
                    results[10] = appendices
                except Exception as e:
                    print(f"Error generating appendices: {e}")

            # Chapter 6 - Conclusions & Recommendations (PhD ONLY)
            if thesis_type == "phd":
                await events.publish(job_id, "stage_started", {"stage": "chapter_6", "message": "üèÅ Generating Chapter 6: Conclusions"}, session_id=session_id)
                c6_content = await self.generate_chapter_six(job_id, session_id, workspace_id, thesis_type=thesis_type, sample_size=sample_size)
                results[6] = c6_content
                await _update_plan(plan_label_map.get(6), cascade=True)
            
            # Step 8: Apply custom outline if provided
            try:
                from services.outline_parser import outline_parser
                from services.workspace_service import WORKSPACES_DIR
                outline_path = WORKSPACES_DIR / (workspace_id or "default") / "outline.json"
                outline = outline_parser.load_outline(workspace_id) if outline_path.exists() else None
                if outline and outline.get("chapters"):
                    await events.publish(job_id, "stage_started", {"stage": "outline_rewrite", "message": "üß≠ Reformatting chapters to custom outline..."}, session_id=session_id)
                    from services.outline_rewriter import rewrite_thesis_to_outline

                    source_chapters = {
                        key: value for key, value in results.items()
                        if isinstance(key, int) and isinstance(value, str)
                    }
                    if not source_chapters:
                        for ch_num in range(1, 7):
                            chapter_files = list((WORKSPACES_DIR / (workspace_id or "default")).glob(f"Chapter_{ch_num}*.md"))
                            if chapter_files:
                                with open(chapter_files[0], "r", encoding="utf-8") as f:
                                    source_chapters[ch_num] = f.read()

                    chapter_titles = {}
                    for idx, chapter in enumerate(outline.get("chapters", []), 1):
                        number = chapter.get("number") or idx
                        try:
                            number = int(number)
                        except (TypeError, ValueError):
                            number = idx
                        chapter_titles[number] = chapter.get("title") or f"Chapter {number}"

                    rewritten = await rewrite_thesis_to_outline(
                        outline=outline,
                        source_chapters=source_chapters,
                        topic=topic,
                        case_study=case_study,
                        thesis_type=thesis_type
                    )
                    for ch_num, content in rewritten.items():
                        raw_title = chapter_titles.get(ch_num, f"Chapter {ch_num}")
                        safe_title = re.sub(r"[^\w\s-]", "", raw_title).strip().replace(" ", "_")
                        chapter_filename = f"Chapter_{ch_num}_{safe_title}.md" if safe_title else f"Chapter_{ch_num}.md"
                        chapter_path = WORKSPACES_DIR / (workspace_id or "default") / chapter_filename
                        with open(chapter_path, "w", encoding="utf-8") as f:
                            f.write(content)
                        results[ch_num] = content
            except Exception as e:
                print(f"‚ö†Ô∏è Outline rewrite failed: {e}")

            # Step 9: Combine Thesis (For both PhD and General)
            await events.publish(job_id, "stage_started", {"stage": "combining", "message": "üìë Combining chapters into final thesis document..."}, session_id=session_id)
            
            try:
                from services.thesis_combiner import ThesisCombiner
                from services.outline_parser import outline_parser
                from services.workspace_service import WORKSPACES_DIR
                outline_path = WORKSPACES_DIR / (workspace_id or "default") / "outline.json"
                custom_outline = outline_parser.load_outline(workspace_id) if outline_path.exists() else None
                if thesis_type == "general" and not custom_outline:
                    custom_outline = outline_parser.get_default_outline("uoj_bsc_accounting_finance")
                
                # Instantiate combiner
                combiner = ThesisCombiner(
                    workspace_id=workspace_id,
                    topic=topic,
                    case_study=case_study,
                    objectives=objectives,
                    output_dir=None, # Defaults to workspace_dir
                    custom_outline=custom_outline
                )
                
                # Load all generated chapters
                combiner.load_chapters_from_files()
                
                # Generate combined thesis
                combined_content, combined_path = combiner.combine_thesis()
                
                await events.publish(job_id, "file_created", {"path": combined_path, "filename": os.path.basename(combined_path), "type": "markdown", "auto_open": True}, session_id=session_id)
                await events.publish(job_id, "stage_completed", {"stage": "combining", "message": f"‚úÖ Final Thesis Combined: {os.path.basename(combined_path)}"}, session_id=session_id)
                
                results['combined_thesis'] = combined_path
            
            except Exception as e:
                print(f"‚ùå Error combining thesis: {e}")
                await events.publish(job_id, "error", {"message": f"Failed to combine thesis: {str(e)}"}, session_id=session_id)

            # Final Completion
            elapsed = (datetime.now() - start_time).total_seconds()
            await events.publish(job_id, "stage_started", {"stage": "complete", "message": f"‚úÖ All Chapters Generated & Combined in {elapsed:.1f}s!"}, session_id=session_id)

        except Exception as e:
            await events.publish(job_id, "error", {"message": f"Thesis generation failed: {str(e)}"}, session_id=session_id)
            print(f"Thesis generation failed: {str(e)}")
            raise e
            
        return results


# Singleton instance
    async def _generate_chapter_two_general(
        self,
        topic: str,
        case_study: str,
        job_id: str,
        session_id: str,
        workspace_id: str,
        objectives: Dict,
        research_questions: List[str],
        custom_outline: Dict[str, Any] = None
    ) -> str:
        """Generate Chapter 2 (General Thesis) with REAL search integration."""
        
        # 1. Setup State & Logging
        await events.publish(job_id, "stage_started", {"stage": "chapter_two", "message": "üìö Starting General Chapter 2 Literature Review (Authentic Source Search)..."}, session_id=session_id)
        
        if objectives and not isinstance(objectives, dict):
            objectives = normalize_objectives(objectives, topic, case_study)
        saved_objectives = objectives or {"general": "", "specific": []}
        specific_objs = saved_objectives.get("specific", [])
        
        self.state = ChapterState(
            topic=topic,
            case_study=case_study,
            job_id=job_id,
            session_id=session_id,
            workspace_id=workspace_id,
            chapter_number=2,
            thesis_type="general"
        )
        self.state.parameters["thesis_type"] = "general"
        self.state.objectives = saved_objectives
        if specific_objs:
            self.state.parameters["objective_count"] = len(specific_objs)
        
        from core.config import settings
        use_external_search = settings.GENERAL_LIT_SEARCH_ENABLED
        all_papers = []

        if use_external_search:
            # 2. PHASE 1: REAL API SEARCH (Prevent Hallucinations)
            await events.publish(job_id, "log", {"message": "üîç Launching Academic Search Agents (Semantic Scholar/Crossref)..."}, session_id=session_id)

            # Define Search Queries (Theories + Empirical)
            search_tasks = []

            # A. Theory Search (3 queries)
            theory_queries = [
                f"{topic} theoretical framework",
                f"{topic} theory model",
                f"{case_study} conceptual framework"
            ]

            async def search_theories():
                results = []
                for query in theory_queries:
                    try:
                        papers = await academic_search_service.search_academic_papers(query, max_results=15)
                        for paper in papers:
                            results.append(ResearchResult(
                                title=paper.get("title", ""),
                                authors=paper.get("authors", [])[:5],
                                year=paper.get("year") or 2023,
                                doi=paper.get("doi", ""),
                                url=paper.get("url", ""),
                                abstract=paper.get("abstract", "")[:500],
                                source="theories",
                                venue=paper.get("venue", "")
                            ))
                    except:
                        pass
                return results

            search_tasks.append(search_theories())

            # B. Empirical Search (Per Objective)
            async def search_objective(obj_idx, obj_text):
                results = []
                # Extract keywords
                clean_obj = obj_text.lower().replace("to ", "").replace("assess ", "").replace("determine ", "")
                query = f"{clean_obj} {topic} {case_study}"[:100]
                try:
                    # Targeted search for this objective
                    papers = await academic_search_service.search_academic_papers(query, max_results=20)
                    for paper in papers:
                        results.append(ResearchResult(
                            title=paper.get("title", ""),
                            authors=paper.get("authors", [])[:5],
                            year=paper.get("year") or 2023,
                            doi=paper.get("doi", ""),
                            url=paper.get("url", ""),
                            abstract=paper.get("abstract", "")[:500],
                            source=f"theme{obj_idx+1}", # Align with WriterSwarm expecting theme sources
                            venue=paper.get("venue", "")
                        ))
                except:
                    pass
                return results

            for i, obj in enumerate(specific_objs[:4]): # Limit to 4 objectives
                search_tasks.append(search_objective(i, obj))

            # Execute Parallel Search
            search_results_lists = await asyncio.gather(*search_tasks)

            # Flatten and Populate Citation Pool
            all_papers = [p for sublist in search_results_lists for p in sublist]
            await events.publish(job_id, "log", {"message": f"‚úÖ Search Complete: Found {len(all_papers)} citable peer-reviewed papers."}, session_id=session_id)
        else:
            await events.publish(
                job_id,
                "log",
                {"message": "üìù Skipping external academic search for General flow; using uploaded sources only."},
                session_id=session_id
            )
            seen_identifiers = set()
            await self._include_uploaded_sources(all_papers, seen_identifiers)

        self.state.chapter2_citation_pool = all_papers  # Enables citation injection

        # If a custom outline is provided, use it to drive the section structure.
        if custom_outline and custom_outline.get("chapters"):
            self.state.parameters["custom_outline"] = custom_outline
            await events.publish(
                job_id,
                "log",
                {"message": "üß≠ Using custom outline for Chapter 2 sections"},
                session_id=session_id
            )

            writer_swarm = WriterSwarm(self.state)
            await writer_swarm.write_all()

            quality_swarm = QualitySwarm(self.state)
            final_content = await quality_swarm.validate_and_combine()

            filename = "Chapter_2_Literature_Review.md"
            from services.workspace_service import WORKSPACES_DIR
            path = WORKSPACES_DIR / workspace_id / filename
            path.parent.mkdir(parents=True, exist_ok=True)
            with open(path, "w", encoding="utf-8") as f:
                f.write(final_content)

            return final_content

        # 3. Build Write Configurations (General Structure)
        configs = []
        
        # Intro
        configs.append({
            "id": "intro",
            "sections": [{"id": "2.0", "title": "Introduction", "paragraphs": 2, "sources": [], "needs_citations": False, "style": "intro"}]
        })
        
        # Theoretical Framework (2.1)
        configs.append({
            "id": "theoretical",
            "sections": [{"id": "2.1", "title": "Theoretical Framework", "paragraphs": 6, "sources": ["theories"], "needs_citations": True, "style": "theory_detailed"}]
        })
        
        # Empirical Review (2.2, 2.3...) Per Objective
        for i, obj in enumerate(specific_objs[:4], 1):
            obj_clean = obj.replace("To ", "").strip()
            title = obj_clean[0].upper() + obj_clean[1:]
            configs.append({
                "id": f"emp_{i}",
                "sections": [{"id": f"2.{i+1}", "title": title, "paragraphs": 8, "sources": [f"theme{i}"], "needs_citations": True, "style": "lit_synthesis"}]
            })
            
        # Summary/Gap
        configs.append({
            "id": "gap",
            "sections": [{"id": f"2.{len(specific_objs)+2}", "title": "Research Gap", "paragraphs": 3, "sources": ["all"], "needs_citations": True, "style": "literature_gap"}]
        })
        
        # 4. Run Writers
        class GeneralWriterSwarm(WriterSwarm):
            SECTION_CONFIGS = configs
            
        writer = GeneralWriterSwarm(self.state)
        writer.SECTION_CONFIGS = configs # Ensure override
        
        sections = await writer._writer_agent("general_swarm", [s for c in configs for s in c["sections"]])
        
        # 5. Compile
        sorted_sections = sorted(sections.values(), key=lambda s: [int(x) for x in s.section_id.split('.') if x.isdigit()])
        final_content = "\n\n".join([f"## {s.section_id} {s.title}\n\n{s.content}" for s in sorted_sections])
        
        # Save file logic... (Reusing common save logic if possible or minimal save)
        filename = f"Chapter_2_Literature_Review.md"
        from services.workspace_service import WORKSPACES_DIR
        path = WORKSPACES_DIR / workspace_id / filename
        with open(path, "w", encoding="utf-8") as f:
            f.write(final_content)
            
        return final_content

    async def _generate_chapter_two_strict_uoj(self, topic: str, case_study: str, job_id: str, session_id: str, workspace_id: str, objectives: Dict, research_questions: List[str]) -> str:
        """Generate Chapter 2 (General Thesis) with strict UoJ structure and verified citations."""
        
        # 1. Setup State & Logging
        await events.publish(job_id, "stage_started", {"stage": "chapter_two", "message": "üìö Starting UoJ Chapter 2: Literature Review (Region-Targeted Search)..."}, session_id=session_id)
        if objectives and not isinstance(objectives, dict):
            objectives = normalize_objectives(objectives, topic, case_study)
        saved_objectives = objectives or {"general": "", "specific": []}
        specific_objs = saved_objectives.get("specific", [])
        
        self.state = ChapterState(
            topic=topic,
            case_study=case_study,
            job_id=job_id,
            session_id=session_id,
            workspace_id=workspace_id,
            chapter_number=2,
            thesis_type="general"
        )
        
        async def announce(action: str):
            await events.publish(
                job_id,
                "agent_activity",
                {
                    "agent": "uoj_ch2_writer",
                    "agent_name": "UoJ Chapter 2",
                    "status": "running",
                    "action": action,
                    "icon": "‚úçÔ∏è",
                    "type": "chapter_generator"
                },
                session_id=session_id
            )

        # Retrieve country from DB or default
        db = resolve_thesis_db(session_id, workspace_id)
        country = "South Sudan"  # Default country for UoJ theses
        regions = ["Asia", "South America", "West Africa", "South Africa", "East Africa", country]

        from core.config import settings
        use_external_search = settings.GENERAL_LIT_SEARCH_ENABLED
        all_papers = []

        if use_external_search:
            # 2. PHASE 1: TARGETED REGIONAL SEARCH
            await events.publish(job_id, "log", {"message": "üåç Launching Multi-Region Academic Search Agents..."}, session_id=session_id)
            await announce("Launching academic search for Chapter 2 sources")
            
            search_tasks = []
            
            # A. Theory Search
            theory_queries = [
                f"{topic} theoretical framework",
                f"{topic} theory model",
                f"{case_study} conceptual framework"
            ]
            
            async def search_theories():
                results = []
                for query in theory_queries:
                    try:
                        papers = await academic_search_service.search_academic_papers(query, max_results=10)
                        for p in papers:
                            p['source_type'] = 'theory'
                            results.append(p)
                    except:
                        pass
                return results
            search_tasks.append(search_theories())

            # B. Empirical Search (Region-Specific for EACH objective)
            # Regions: Asia, South America, West Africa, Central/South Africa, East Africa, Local
            async def search_objective_regions(obj_text, obj_idx):
                results = []
                clean_obj = obj_text.lower().replace("to ", "").replace("assess ", "").replace("determine ", "").replace("examine ", "")
                base_query = f"{clean_obj} {topic}"[:60]
                
                for region in regions:
                    query = f"{base_query} {region}"
                    try:
                        papers = await academic_search_service.search_academic_papers(query, max_results=3)
                        for p in papers:
                            p['source_type'] = f"obj_{obj_idx}_{region}"
                            results.append(p)
                    except:
                        pass
                return results

            # Limit to first 3 objectives for deep search to avoid rate limits/timeouts
            for i, obj in enumerate(specific_objs[:3]):
                search_tasks.append(search_objective_regions(obj, i))

            # Execute Search
            search_results_lists = await asyncio.gather(*search_tasks)
            
            # Flatten and deduplicate
            seen_dois = set()
            for sublist in search_results_lists:
                for p in sublist:
                    # Normalize paper object
                    paper_obj = ResearchResult(
                        title=p.get("title", ""),
                        authors=p.get("authors", [])[:5],
                        year=p.get("year") or 2023,
                        doi=p.get("doi", ""),
                        url=p.get("url", ""),
                        abstract=p.get("abstract", "")[:500],
                        source=p.get('source_type', 'general'),
                        venue=p.get("venue", "")
                    )
                    if paper_obj.title and paper_obj.title not in seen_dois: # Simple dedup by title/doi
                        all_papers.append(paper_obj)
                        seen_dois.add(paper_obj.title)

            await events.publish(job_id, "log", {"message": f"‚úÖ Found {len(all_papers)} region-specific papers."}, session_id=session_id)
        else:
            await events.publish(
                job_id,
                "log",
                {"message": "üìù Skipping external academic search for UoJ General; using uploaded sources only."},
                session_id=session_id
            )
            seen_identifiers = set()
            await self._include_uploaded_sources(all_papers, seen_identifiers)

        self.state.chapter2_citation_pool = all_papers

        # 3. GENERATE CONTENT (Parallel Writing)
        write_tasks = []

        # 3.1 Introduction
        async def write_intro():
            await announce("Writing Chapter 2 introduction")
            prompt = f"""Write Introduction of chapter two about literature reviews for {topic}.
            Say: "Chapter two of this study will be about literature reviews using previous information from former scholars... study gaps in accordance to {case_study}, {country} will be identified."
            One detailed paragraph."""
            return await deepseek_direct_service.generate_content(prompt, max_tokens=400)
        write_tasks.append(("intro", write_intro()))
        
        # 3.2 Theoretical Reviews
        async def write_theory_intro():
            await announce("Writing theoretical review introduction")
            return await deepseek_direct_service.generate_content(f"""Write one paragraph introduction for Theoretical review section: "The study about {topic} will be guided by three theories...".""", max_tokens=300)
        write_tasks.append(("theory_intro", write_theory_intro()))
        
        # Theories (1 General + 2 Objective-based)
        theory_targets = ["General Theory"] + [f"Theory for Objective {i+1}" for i in range(min(2, len(specific_objs)))]
        
        async def write_theory(idx, target):
            await announce(f"Writing theoretical framework: {target}")
            relevant_papers = [p for p in all_papers if p.source == 'theory'] or all_papers[:5]
            citations = "\n".join([f"- {p.title} by {p.authors} ({p.year}) DOI: {p.doi}" for p in relevant_papers[:5]])
            prompt = f"""Write a Theoretical Framework for {target} regarding {topic}.
            1. State theory name, author(year).
            2. Detailed explanation with 4 real citations from: 
            {citations}
            3. Two authors who oppose (paragraph).
            4. Two authors who agree (paragraph).
            5. Importance to study and {case_study}.
            6. Gaps.
            **CRITICAL**: Use clickable markdown links: [Author, Year](url/doi).
            """
            content = await deepseek_direct_service.generate_content(prompt, max_tokens=1000)
            return f"### {target}\n{content}"
            
        for i, target in enumerate(theory_targets):
            write_tasks.append((f"theory_{i}", write_theory(i, target)))

        # 3.3 Empirical Reviews
        async def write_emp_intro():
             await announce("Writing empirical review introduction")
             return await deepseek_direct_service.generate_content("Write one paragraph introduction to empirical review section.", max_tokens=300)
        write_tasks.append(("emp_intro", write_emp_intro()))
        
        async def write_empirical_obj(i, obj):
            await announce(f"Writing empirical review for objective {i + 1}")
            # Generate content for 6 regions (Parallelized)
            region_tasks = []
            for region in regions:
                async def write_region(r):
                    region_papers = [p for p in all_papers if p.source == f"obj_{i}_{r}"]
                    if not region_papers: region_papers = all_papers[:3] # Fallback
                    citations_list = "\n".join([f"- {p.title} ({p.year}) DOI: {p.doi}" for p in region_papers[:3]])
                    
                    prompt = f"""Write Empirical Review for Objective: "{obj}" focusing on {r} perspective.
                    Cite studies from:
                    {citations_list}
                    Structure: "Author (Year) conducted a study about... method... findings... conclusion... gap."
                    **CRITICAL**: Use clickable markdown links: [Author, Year](url/doi).
                    One detailed paragraph."""
                    return f"#### {r} Perspective\n" + await deepseek_direct_service.generate_content(prompt, max_tokens=400)
                
                region_tasks.append(write_region(region))
            
            region_contents = await asyncio.gather(*region_tasks)
            return f"### 2.2.{i+1} Empirical Review: {obj}\n" + "\n\n".join(region_contents)

        for i, obj in enumerate(specific_objs[:4]):
            write_tasks.append((f"emp_obj_{i}", write_empirical_obj(i, obj)))

        # 3.4 Summary Gap
        async def write_gap():
            await announce("Writing literature summary and gap")
            return await deepseek_direct_service.generate_content(f"""Write literature summary and knowledge gap based on the reviews in context of {case_study}, {country}.""", max_tokens=500)
        write_tasks.append(("gap", write_gap()))
        
        # EXECUTE WRITING
        await events.publish(job_id, "log", {"message": "‚úçÔ∏è Writing all sections in parallel..."}, session_id=session_id)
        write_results = await asyncio.gather(*[t[1] for t in write_tasks])
        
        # Map results
        result_map = {task[0]: content for task, content in zip(write_tasks, write_results)}
        
        # Assemble
        theories_text = "\n\n".join([result_map[f"theory_{i}"] for i in range(len(theory_targets))])
        empirical_text = "\n\n".join([result_map[f"emp_obj_{i}"] for i in range(len(specific_objs[:4]))])
        
        full_content = f"""# CHAPTER TWO: LITERATURE REVIEWS

## 2.0 Introduction
{result_map['intro']}

## Theoretical Reviews
{result_map['theory_intro']}

{theories_text}

## Empirical Reviews
{result_map['emp_intro']}

{empirical_text}

## Summary and Knowledge Gap
{result_map['gap']}
"""
        return full_content

parallel_chapter_generator = ParallelChapterGenerator()
